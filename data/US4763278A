US	O
4763278	O
A	O
19880809	O

US	O
06484820	O
19830413	O

eng	O
eng	O

19880809	O

19880809	O

4G	O
10L	O
5/00	O
A	O
4	O
G	O
10	O
L	O
5	O
00	O
A	O

G10L	O
11/00	O
20060101C	O
I20051008RMEP	O

20060101	O

C	O
G	O
10	O
L	O
11	O
00	O
I	O

20051008	O

EP	O

R	O
M	O

G10L	O
11/00	O
20060101A	O
I20051008RMEP	O

20060101	O

A	O
G	O
10	O
L	O
11	O
00	O
I	O

20051008	O

EP	O

R	O
M	O

G10L	O
15/00	O
20060101C	O
I20051008RMEP	O

20060101	O

C	O
G	O
10	O
L	O
15	O
00	O
I	O

20051008	O

EP	O

R	O
M	O

G10L	O
15/00	O
20060101A	O
I20051008RMEP	O

20060101	O

A	O
G	O
10	O
L	O
15	O
00	O
I	O

20051008	O

EP	O

R	O
M	O

US	O

704/251	O
704	O
251	O

704/238	O
704	O
238	O

704/241	O
704	O
241	O

704/243	O
704	O
243	O

704/253	O
704	O
253	O

G10L	O
11/00	O
+	O
IDT	O
G	O
10	O
L	O
11	O
00	O
+	O
IDT	O

G10L	O
15/00	O
+	O
IDT	O
G	O
10	O
L	O
15	O
00	O
+	O
IDT	O

S10L700:023	O
S	O
10	O
L	O
700	O
023	O

S10L700	O
:	O
08	O
S	O
10	O
L	O
700	O
08	O

US	O

381/41	O
381	O
41	O

US	O

381/42	O
381	O
42	O

US	O

381/43	O
381	O
43	O

US	O

381/44	O
381	O
44	O

US	O

381/45	O
381	O
45	O

US	O

381/46	O
381	O
46	O

US	O

381/47	O
381	O
47	O

US	O

381/48	O
381	O
48	O

US	O

381/49	O
381	O
49	O

US	O

381/50	O
381	O
50	O

US	O

364/513	O
364	O
513	O

US	O

364/513	O
.	O
5	O
364	O
513	O
.	O
5	O

18	O
Speaker-independent	O
word	O
recognizer	O

US	O
3553372	O
A	O
Wright	O
et_al.	O

19710105	O

19661018	O

US	O

381/43	O
381	O
43	O

US	O
4256924	O
A	O
Sakoe	O
19810317	O

19791119	O

US	O

381/43	O
381	O
43	O

US	O
4363102	O
A	O
Holmgren	O
et_al.	O

19821207	O

19810327	O

US	O

364/513	O
364	O
513	O

US	O
4477925	O
A	O
Avery	O
et_al.	O

19841016	O

19811211	O

US	O

381/43	O
381	O
43	O

US	O
4528688	O
A	O
Ichikawa	O
et_al.	O

19850709	O

19840419	O

US	O

381/43	O
381	O
43	O

Flanagan	B-Citation
,	I-Citation
Speech	I-Citation
Analysis	I-Citation
,	I-Citation
Synthesis	I-Citation
and	I-Citation
Perception	I-Citation
Springer	I-Citation
Verlag	I-Citation
,	I-Citation
New	I-Citation
York	I-Citation
,	I-Citation
1972	I-Citation
,	I-Citation
pp.	I-Citation
192	I-Citation
204	I-Citation
.	O

EP	O
800698	O
B1	O
20020123	O

19951025	O

US	O
5475798	O
A	O
19951212	O

19920106	O

US	O
5794204	O
A	O
19980811	O

19950929	O

US	O
5347612	O
A	O
19940913	O

19900716	O

US	O
4947436	O
A	O
19900807	O

19881007	O

US	O
5668780	O
A	O
19970916	O

19921030	O

US	O
4896358	O
A	O
19900123	O

19870317	O

US	O
4817154	O
A	O
19890328	O

19861209	O

US	O
5577162	O
A	O
19961119	O

19941011	O

US	O
5581650	O
A	O
19961203	O

19940707	O

US	O
5091949	O
A	O
19920225	O

19890125	O

US	O
5101434	O
A	O
19920331	O

19900104	O

US	O
5165008	O
A	O
19921117	O

19910918	O

US	O
5915001	O
A	O
19990622	O

19961114	O

US	O
7191130	O
B1	O
20070313	O

20020927	O

EP	O
800698	O
A3	O

DE	O
19948366	O
A1	O
20001228	O

19991006	O

US	O
7618323	O
B2	O
20091117	O

20030226	O

US	O
7016835	O
B2	O
20060321	O

20021219	O

US	O
6885736	O
B2	O
20050426	O

20020125	O

US	O
6801893	O
B1	O
20041005	O

20000622	O

US	O
6754629	O
B1	O
20040622	O

20000908	O

US	O
6761131	O
B2	O
20040713	O

20030620	O

US	O
6490561	O
B1	O
20021203	O

19970625	O

US	O
6400806	O
B1	O
20020604	O

19990405	O

US	O
7753796	O
B2	O
20100713	O

20050309	O

EP	O
800698	O
A2	O
19971015	O

19951025	O

Texas	O
Instruments	O
Incorporated	O

Dallas	O
TX	O
US	O

Rajasekaran	O
Periagaram	O
K.	O

Richardson	O
US	O

Doddington	O
George	O
R.	O

Richardson	O
US	O

Hiller	O
William	O
E.	O

Merrett	O
N.	O
Rhys	O

Sharp	O
Melvin	O

Kemeny	O
;	O
Emanuel	O
S.	O

US	O
4763278	O
A	O
19880809	O

19830413	O

JP	O
60035798	O
A	O
19850223	O

19840412	O

EP	O
125422	O
A1	O
19841121	O

19840315	O

US	O
4763278	O
A	O
19880809	O

19830413	O

US	O
4712242	O
A	O
19871208	O

19830413	O

Speaker-independent	O
word	O
recognition	O
is	O
performed	O
,	O
based	O
on	O
a	O
small	O
acoustically	O
distinct	O
vocabulary	O
,	O
with	O
minimal	O
hardware	O
requirements	O
.	O
After	O
a	O
simple	O
preconditioning	O
filter	O
,	O
the	O
zero	O
crossing	O
intervals	O
of	O
the	O
input	O
speech	O
are	O
measured	O
and	O
sorted	O
by	O
duration	O
,	O
to	O
provide	O
a	O
rough	O
measure	O
of	O
the	O
frequency	O
distribution	O
within	O
each	O
input	O
frame	O
.	O
The	O
distribution	O
of	O
zero	O
crossing	O
intervals	O
is	O
transformed	O
into	O
a	O
binary	O
feature	O
vector	O
,	O
which	O
is	O
compared	O
with	O
each	O
reference	O
template	O
using	O
a	O
modified	O
Hamming	O
distance	O
measure	O
.	O
A	O
dynamic	O
time	O
warping	O
algorithm	O
is	O
used	O
to	O
permit	O
recognition	O
of	O
various	O
speaker	O
rate	O
,	O
and	O
to	O
economize	O
on	O
the	O
reference	O
template	O
storage	O
requirements	O
.	O
A	O
mask	O
vector	O
for	O
each	O
reference	O
template	O
is	O
used	O
to	O
ignore	O
insignificant	O
(	O
or	O
speaker-dependent	O
)	O
features	O
of	O
the	O
words	O
detected	O
.	O

19830413	O

AS	O
ASSIGNMENT	O
N	O
US	O
4763278A	O
TEXAS	O
INSTRUMENTS	O
INCORPORATED	O
;	O
13500	O
NORTH	O
CENTRA	O
ASSIGNMENT	O
OF	O
ASSIGNORS	O
INTEREST.;ASSIGNORS:RAJASEKARAN	O
,	O
PERIAGARAM	O
K.;DODDINGTON	O
,	O
GEORGE	O
R.;REEL/FRAME:004118/0734	O

19830413	O

19911213	O

FPAY	O
+	O
FEE	O
PAYMENT	O
N	O
US	O
4763278A	O
4	O

19960122	O

FPAY	O
+	O
FEE	O
PAYMENT	O
N	O
US	O
4763278A	O
8	O

20000229	O

REMI	O
MAINTENANCE	O
FEE	O
REMINDER	O
MAILED	O
N	O
US	O
4763278A	O

20000806	O

LAPS	O
-	O
LAPSE	O
FOR	O
FAILURE	O
TO	O
PAY	O
MAINTENANCE	O
FEES	O
N	O
US	O
4763278A	O

20001010	O

FP	O
-	O
EXPIRED	O
DUE	O
TO	O
FAILURE	O
TO	O
PAY	O
MAINTENANCE	O
FEE	O
C	O
US	O
4763278A	O

20000809	O

BACKGROUND	O
AND	O
SUMMARY	O
OF	O
THE	O
INVENTION	O
The	O
present	O
invention	O
relates	O
to	O
a	O
speaker-independent	O
speech	O
recognizer	O
,	O
that	O
is	O
to	O
a	O
machine	O
capable	O
of	O
automatically	O
recognizing	O
and	O
decoding	O
speech	O
from	O
an	O
unknown	O
human	O
speaker	O
.	O

There	O
are	O
many	O
applications	O
where	O
it	O
would	O
be	O
highly	O
desirable	O
to	O
have	O
such	O
a	O
speaker-independent	O
speech	O
recognizer	O
configured	O
for	O
a	O
small	O
vocabulary	O
.	O
For	O
example	O
,	O
such	O
a	O
word	O
recognizer	O
would	O
be	O
extremely	O
useful	O
for	O
automotive	O
controls	O
and	O
video	O
games	O
.	O
If	O
even	O
a	O
very	O
small	O
control	O
vocabulary	O
were	O
available	O
,	O
many	O
non-critical	O
automotive	O
control	O
functions	O
which	O
frequently	O
require	O
the	O
driver	O
to	O
remove	O
his	O
eyes	O
from	O
the	O
road	O
could	O
be	O
done	O
by	O
direct	O
voice	O
inputs	O
.	O
Control	O
of	O
a	O
car	O
's	O
radio	O
or	O
sound	O
system	O
could	O
be	O
usefully	O
accomplished	O
in	O
this	O
matter	O
.	O
The	O
more	O
sophisticated	O
monitoring	O
and	O
computational	O
functions	O
available	O
in	O
some	O
cars	O
could	O
also	O
be	O
more	O
efficiently	O
met	O
with	O
a	O
voice	O
query/voice	O
output	O
system	O
.	O
For	O
example	O
,	O
if	O
a	O
driver	O
could	O
say	O
"	O
fuel	O
"	O
,	O
and	O
have	O
his	O
dashboard	O
reply	O
verbally	O
"	O
seven	O
gallons--refuel	O
within	O
160	O
miles	O
,	O
"	O
this	O
would	O
be	O
very	O
convenient	O
in	O
automotive	O
control	O
design	O
.	O
Similarly	O
,	O
an	O
arcade	O
video	O
game	O
could	O
be	O
designed	O
to	O
accept	O
a	O
limited	O
set	O
of	O
verbal	O
inputs	O
such	O
as	O
"	O
shoot	O
"	O
,	O
"	O
pull	O
up	O
"	O
,	O
"	O
dive	O
"	O
,	O
"	O
left	O
"	O
,	O
and	O
"	O
right	O
"	O
.	O
These	O
applications	O
,	O
like	O
many	O
others	O
,	O
are	O
extremely	O
cost	O
sensitive	O
.	O

Thus	O
,	O
to	O
provide	O
a	O
word	O
recognizer	O
for	O
the	O
large	O
body	O
of	O
applications	O
of	O
this	O
type	O
,	O
it	O
is	O
not	O
necessary	O
that	O
the	O
recognizer	O
be	O
able	O
to	O
recognize	O
a	O
very	O
large	O
vocabulary	O
.	O
A	O
small	O
vocabulary	O
,	O
e.g.	O
6	O
to	O
20	O
words	O
,	O
can	O
be	O
extremely	O
useful	O
for	O
many	O
applications	O
.	O
Secondly	O
,	O
it	O
is	O
not	O
necessary	O
that	O
a	O
word	O
recognizer	O
for	O
such	O
applications	O
be	O
able	O
to	O
recognize	O
a	O
word	O
embedded	O
in	O
connected	O
speech	O
.	O
Recognition	O
of	O
isolated	O
words	O
is	O
quite	O
sufficient	O
for	O
many	O
simple	O
command	O
applications	O
.	O
Third	O
,	O
in	O
many	O
such	O
applications	O
,	O
substitution	O
errors	O
are	O
much	O
more	O
undesirable	O
than	O
rejection	O
errors	O
.	O
For	O
example	O
,	O
if	O
a	O
consumer	O
is	O
making	O
purchases	O
from	O
a	O
voice-selected	O
vending	O
machine	O
,	O
it	O
is	O
much	O
more	O
desirable	O
to	O
have	O
the	O
machine	O
reply	O
"	O
input	O
not	O
understood	O
"	O
than	O
to	O
have	O
the	O
machine	O
issue	O
the	O
wrong	O
item	O
.	O

Thus	O
,	O
it	O
is	O
an	O
object	O
of	O
the	O
present	O
invention	O
to	O
provide	O
a	O
low	O
cost	O
word	O
recognizer	O
system	O
which	O
has	O
a	O
very	O
low	O
rate	O
of	O
substitution	O
errors	O
.	O

It	O
is	O
highly	O
desirable	O
to	O
have	O
such	O
word	O
recognizer	O
systems	O
operate	O
with	O
a	O
low	O
computational	O
load	O
.	O
In	O
many	O
attractive	O
applications	O
,	O
a	O
modest	O
error	O
rate	O
can	O
easily	O
be	O
tolerated	O
(	O
e.g.	O
85	O
%	O
accurate	O
recognition	O
)	O
,	O
but	O
the	O
cost	O
requirements	O
are	O
stringent	O
.	O
Thus	O
,	O
it	O
would	O
be	O
highly	O
desirable	O
to	O
have	O
a	O
word	O
recognizer	O
which	O
could	O
be	O
implemented	O
with	O
an	O
ordinary	O
cheap	O
8	O
bit	O
microcomputer	O
,	O
together	O
with	O
cheap	O
analog	O
chips	O
,	O
but	O
without	O
requiring	O
any	O
high	O
speed	O
chips	O
or	O
dedicated	O
processors	O
.	O
Of	O
course	O
,	O
it	O
is	O
always	O
possible	O
to	O
do	O
speaker-independent	O
word	O
recognition	O
using	O
a	O
minicomputer	O
or	O
a	O
main	O
frame	O
,	O
but	O
such	O
an	O
implementation	O
has	O
no	O
practical	O
relevance	O
to	O
most	O
of	O
the	O
desirable	O
applications	O
,	O
since	O
most	O
of	O
the	O
applications	O
are	O
cost-sensitive	O
.	O

Thus	O
,	O
it	O
is	O
an	O
object	O
of	O
the	O
present	O
invention	O
to	O
provide	O
a	O
speaker-independent	O
word	O
recognizer	O
which	O
can	O
be	O
implemented	O
with	O
an	O
ordinary	O
8-bit	O
microcomputer	O
,	O
and	O
does	O
not	O
require	O
any	O
high-speed	O
or	O
special-function	O
processing	O
chips	O
.	O

It	O
is	O
a	O
further	O
object	O
of	O
the	O
present	O
invention	O
to	O
provide	O
a	O
speaker-independent	O
word	O
recognizer	O
for	O
a	O
limited	O
vocabulary	O
which	O
can	O
be	O
implemented	O
using	O
an	O
8-bit	O
microcomputer	O
and	O
analog	O
chips	O
.	O

A	O
further	O
problem	O
in	O
speaker-independent	O
recognition	O
has	O
been	O
the	O
preparation	O
of	O
an	O
appropriate	O
set	O
of	O
templates	O
.	O
Any	O
one	O
speaker	O
,	O
or	O
any	O
set	O
of	O
speakers	O
with	O
a	O
common	O
regional	O
accent	O
,	O
may	O
pronounce	O
a	O
certain	O
word	O
consistently	O
with	O
certain	O
features	O
which	O
will	O
not	O
be	O
replicated	O
in	O
the	O
general	O
population	O
.	O
That	O
is	O
,	O
the	O
reference	O
templates	O
for	O
speaker-independent	O
vocabulary	O
must	O
not	O
specify	O
any	O
feature	O
of	O
a	O
word	O
which	O
is	O
not	O
a	O
strictly	O
necessary	O
feature	O
.	O
It	O
is	O
always	O
possible	O
to	O
prepare	O
a	O
set	O
of	O
reference	O
templates	O
using	O
empirical	O
optimization	O
,	O
but	O
this	O
can	O
be	O
immensely	O
time	O
consuming	O
,	O
and	O
also	O
precludes	O
the	O
possibility	O
of	O
user-generation	O
of	O
reference	O
templates	O
in	O
the	O
field	O
.	O

Thus	O
,	O
it	O
is	O
a	O
further	O
object	O
of	O
the	O
present	O
invention	O
to	O
provide	O
a	O
speech	O
recognizer	O
,	O
for	O
which	O
the	O
preparation	O
of	O
reference	O
templates	O
requires	O
minimal	O
empirical	O
input	O
from	O
trained	O
researchers	O
.	O

It	O
is	O
a	O
further	O
object	O
of	O
the	O
present	O
invention	O
to	O
provide	O
a	O
method	O
for	O
preparing	O
vocabulary	O
templates	O
for	O
a	O
speaker-independent	O
word	O
recognizer	O
which	O
can	O
be	O
implemented	O
by	O
minimally	O
skilled	O
users	O
.	O

A	O
further	O
difficulty	O
in	O
preparing	O
a	O
speaker-independent	O
word	O
recognizer	O
for	O
cost-sensitive	O
systems	O
is	O
memory	O
requirements	O
.	O
That	O
is	O
,	O
it	O
is	O
highly	O
desirable	O
in	O
many	O
systems	O
where	O
small	O
microcomputers	O
are	O
to	O
be	O
used	O
not	O
to	O
tie	O
up	O
too	O
much	O
program	O
memory	O
with	O
the	O
word	O
recognition	O
algorithm	O
and	O
templates	O
.	O
In	O
particular	O
,	O
in	O
many	O
applications	O
for	O
portable	O
devices	O
(	O
e.g.	O
a	O
calculator	O
or	O
watch	O
which	O
can	O
receive	O
spoken	O
commands	O
)	O
,	O
the	O
power	O
requirements	O
of	O
unswitched	O
memory	O
impose	O
a	O
critical	O
constraint	O
.	O
Since	O
speech	O
vocabulary	O
templates	O
must	O
be	O
saved	O
during	O
power-off	O
periods	O
,	O
the	O
amount	O
of	O
memory	O
(	O
CMOS	O
or	O
nonvolatile	O
)	O
required	O
for	O
speech	O
reference	O
templates	O
is	O
a	O
very	O
important	O
cost	O
parameter	O
.	O

Thus	O
,	O
it	O
is	O
a	O
further	O
object	O
of	O
the	O
present	O
invention	O
to	O
provide	O
a	O
speaker-independent	O
word	O
recognizer	O
which	O
has	O
absolutely	O
minimal	O
memory	O
requirements	O
for	O
storing	O
reference	O
templates	O
.	O

A	O
further	O
problem	O
in	O
any	O
word	O
recognizer	O
,	O
which	O
is	O
most	O
particularly	O
important	O
in	O
a	O
speaker-independent	O
word	O
recognizer	O
,	O
is	O
that	O
speakers	O
will	O
typically	O
vary	O
,	O
not	O
only	O
in	O
their	O
average	O
rate	O
of	O
speech	O
,	O
but	O
in	O
their	O
timing	O
of	O
the	O
syllable	O
within	O
a	O
given	O
word	O
.	O
Since	O
this	O
information	O
is	O
not	O
normally	O
used	O
by	O
human	O
listeners	O
in	O
making	O
a	O
word	O
recognition	O
decision	O
,	O
it	O
will	O
typically	O
vary	O
substantially	O
among	O
the	O
speech	O
patterns	O
of	O
different	O
speakers	O
.	O
It	O
is	O
therefore	O
necessary	O
that	O
a	O
speaker-independent	O
word	O
recognizer	O
be	O
insensitive	O
to	O
a	O
reasonable	O
range	O
of	O
variation	O
in	O
the	O
average	O
rate	O
and	O
localized	O
timing	O
of	O
human	O
speech	O
.	O

It	O
is	O
therefore	O
a	O
further	O
object	O
of	O
the	O
present	O
invention	O
to	O
provide	O
a	O
speaker-independent	O
word	O
recognizer	O
which	O
is	O
reasonably	O
insensitive	O
both	O
to	O
average	O
rate	O
and	O
to	O
localized	O
variations	O
in	O
timing	O
of	O
human	O
speech	O
.	O

It	O
is	O
a	O
further	O
object	O
of	O
the	O
present	O
invention	O
to	O
provide	O
a	O
speech	O
recognition	O
system	O
which	O
is	O
reasonably	O
insensitive	O
both	O
to	O
average	O
rate	O
and	O
to	O
localized	O
variations	O
in	O
timing	O
of	O
human	O
speech	O
,	O
which	O
can	O
be	O
implemented	O
using	O
a	O
simple	O
microcomputer	O
with	O
no	O
expensive	O
custom	O
parts	O
required	O
.	O

A	O
further	O
characteristic	O
which	O
it	O
would	O
be	O
desirable	O
to	O
implement	O
in	O
a	O
speaker-independent	O
word	O
recognition	O
system	O
is	O
the	O
capability	O
for	O
vocabulary	O
change	O
.	O
Thus	O
,	O
for	O
example	O
,	O
in	O
a	O
calculator	O
which	O
can	O
be	O
addressed	O
by	O
spoken	O
commands	O
,	O
it	O
would	O
be	O
desirable	O
to	O
have	O
the	O
set	O
of	O
spoken	O
commands	O
be	O
variable	O
with	O
different	O
modules	O
(	O
for	O
example	O
)	O
,	O
or	O
to	O
be	O
user	O
variable	O
as	O
user-customized	O
software	O
is	O
loaded	O
into	O
the	O
calculator	O
.	O

However	O
,	O
to	O
accomplish	O
this	O
,	O
it	O
is	O
desirable	O
that	O
the	O
reference	O
template	O
set	O
preparation	O
be	O
based	O
on	O
reasonably	O
simple	O
exclusion	O
algorithms	O
,	O
so	O
that	O
a	O
reasonably	O
unskilled	O
user	O
can	O
prepare	O
a	O
new	O
template	O
set	O
.	O
It	O
is	O
also	O
necessary	O
that	O
the	O
template	O
set	O
be	O
addressable	O
,	O
so	O
that	O
templates	O
can	O
be	O
downloaded	O
and	O
substituted	O
.	O

It	O
should	O
also	O
be	O
noted	O
that	O
the	O
capability	O
to	O
change	O
templates	O
is	O
sensitive	O
to	O
the	O
memory	O
space	O
required	O
for	O
each	O
template	O
.	O
That	O
is	O
,	O
if	O
the	O
memory	O
templates	O
can	O
be	O
stored	O
reasonably	O
compactly	O
,	O
then	O
a	O
mask	O
location	O
can	O
be	O
used	O
to	O
indicate	O
which	O
subset	O
of	O
all	O
possible	O
stored	O
templates	O
corresponds	O
to	O
the	O
currently	O
active	O
vocabulary	O
.	O
Thus	O
,	O
for	O
example	O
,	O
in	O
an	O
automotive	O
control	O
system	O
,	O
a	O
master	O
vocabulary	O
might	O
contain	O
only	O
a	O
set	O
of	O
words	O
indicating	O
various	O
areas	O
of	O
control	O
functions	O
,	O
such	O
as	O
"	O
radio	O
"	O
,	O
"	O
wipers	O
"	O
,	O
"	O
engine	O
"	O
,	O
"	O
computer	O
"	O
,	O
etc	O
.	O
After	O
any	O
one	O
of	O
these	O
function	O
areas	O
have	O
been	O
selected	O
,	O
a	O
new	O
localized	O
set	O
of	O
reference	O
templates	O
would	O
then	O
be	O
used	O
for	O
each	O
particular	O
function	O
area	O
.	O
Each	O
localized	O
set	O
of	O
reference	O
templates	O
would	O
have	O
to	O
include	O
one	O
command	O
to	O
return	O
to	O
the	O
master	O
template	O
set	O
,	O
but	O
otherwise	O
could	O
be	O
fully	O
customized	O
.	O
Thus	O
,	O
a	O
localized	O
set	O
of	O
commands	O
for	O
radio	O
control	O
could	O
include	O
such	O
commands	O
as	O
"	O
FM	O
"	O
,	O
"	O
AM	O
"	O
,	O
"	O
higher	O
"	O
,	O
"	O
lower	O
"	O
,	O
"	O
frequency	O
"	O
,	O
"	O
volume	O
"	O
,	O
etc	O
.	O

Thus	O
,	O
it	O
is	O
a	O
further	O
object	O
of	O
the	O
present	O
invention	O
to	O
provide	O
a	O
speaker-independent	O
recognizer	O
which	O
functions	O
on	O
a	O
limited	O
vocabulary	O
,	O
but	O
in	O
which	O
the	O
vocabulary	O
set	O
can	O
be	O
easily	O
changed	O
.	O

It	O
is	O
a	O
further	O
object	O
of	O
the	O
present	O
invention	O
to	O
provide	O
a	O
speaker-independent	O
recognizer	O
which	O
functions	O
on	O
a	O
limited	O
vocabulary	O
,	O
but	O
in	O
which	O
the	O
vocabulary	O
set	O
can	O
be	O
easily	O
changed	O
,	O
which	O
can	O
be	O
implemented	O
using	O
simple	O
commercially	O
available	O
microcomputer	O
parts	O
.	O

A	O
further	O
desirable	O
option	O
in	O
speaker-independent	O
word	O
recognizer	O
systems	O
is	O
the	O
capability	O
to	O
function	O
in	O
a	O
speaker	O
dependent	O
mode	O
.	O
That	O
is	O
,	O
in	O
such	O
applications	O
as	O
automobile	O
controls	O
or	O
speech-controlled	O
calculators	O
,	O
it	O
is	O
necessary	O
that	O
the	O
systems	O
be	O
shipped	O
from	O
the	O
factory	O
with	O
a	O
capability	O
to	O
immediately	O
receive	O
speech	O
input	O
.	O
However	O
,	O
many	O
such	O
devices	O
will	O
typically	O
be	O
used	O
only	O
by	O
a	O
limited	O
set	O
of	O
users	O
.	O
Thus	O
,	O
it	O
is	O
desirable	O
to	O
be	O
able	O
to	O
adapt	O
the	O
template	O
set	O
of	O
speaker-independent	O
device	O
to	O
be	O
optimized	O
for	O
a	O
particular	O
user	O
or	O
group	O
of	O
users	O
.	O
Such	O
re-optimization	O
could	O
be	O
used	O
to	O
increase	O
the	O
vocabulary	O
size	O
or	O
lower	O
the	O
error	O
rate	O
in	O
service	O
,	O
but	O
requires	O
that	O
the	O
process	O
of	O
modifying	O
templates	O
be	O
reasonably	O
simple	O
.	O

Thus	O
,	O
it	O
is	O
a	O
further	O
object	O
of	O
the	O
present	O
invention	O
to	O
provide	O
a	O
speaker-independent	O
word	O
recognizer	O
which	O
can	O
be	O
re-optimized	O
easily	O
to	O
operate	O
in	O
a	O
speaker	O
dependent	O
mode	O
,	O
for	O
a	O
specific	O
speaker	O
or	O
for	O
a	O
limited	O
group	O
of	O
speakers	O
.	O

Thus	O
,	O
it	O
is	O
a	O
further	O
object	O
of	O
the	O
present	O
invention	O
to	O
provide	O
a	O
speaker-independent	O
word	O
recognizer	O
,	O
which	O
can	O
be	O
easily	O
re-optimized	O
to	O
operate	O
in	O
a	O
speaker	O
dependent	O
mode	O
for	O
a	O
specific	O
speaker	O
or	O
for	O
a	O
limited	O
group	O
of	O
speakers	O
,	O
and	O
which	O
can	O
be	O
economically	O
configured	O
using	O
a	O
simple	O
microcomputer	O
and	O
simple	O
analog	O
parts	O
.	O

Speaker-independent	O
word	O
recognition	O
is	O
performed	O
,	O
based	O
on	O
a	O
small	O
acoustically	O
distinct	O
vocabulary	O
,	O
with	O
minimal	O
hardware	O
requirements	O
.	O
After	O
a	O
simple	O
preconditioning	O
filter	O
,	O
the	O
zero	O
crossing	O
intervals	O
of	O
the	O
input	O
speech	O
are	O
measured	O
and	O
sorted	O
by	O
duration	O
,	O
to	O
provide	O
a	O
rough	O
measure	O
of	O
the	O
frequency	O
distribution	O
within	O
each	O
input	O
frame	O
.	O
The	O
distribution	O
of	O
zero	O
crossing	O
intervals	O
is	O
transformed	O
into	O
a	O
binary	O
feature	O
vector	O
,	O
which	O
is	O
compared	O
with	O
each	O
reference	O
template	O
using	O
a	O
modified	O
Hamming	O
distance	O
measure	O
.	O
A	O
dynamic	O
time	O
warping	O
algorithm	O
is	O
used	O
to	O
permit	O
recognition	O
of	O
various	O
speaker	O
rates	O
,	O
and	O
to	O
economize	O
on	O
the	O
reference	O
template	O
storage	O
requirements	O
.	O
A	O
mask	O
vector	O
for	O
each	O
reference	O
template	O
is	O
used	O
to	O
ignore	O
insignificant	O
(	O
speaker-dependent	O
)	O
features	O
of	O
the	O
words	O
detected	O
.	O

To	O
achieve	O
these	O
and	O
other	O
objects	O
of	O
the	O
invention	O
,	O
the	O
present	O
invention	O
comprises	O
:	O
A	O
word	O
recognizer	O
,	O
comprising	O
:	O
input	O
means	O
for	O
receiving	O
an	O
analog	O
input	O
signal	O
corresponding	O
to	O
speech	O
;	O
a	O
signal	O
processor	O
,	O
said	O
processor	O
conditioning	O
said	O
input	O
signal	O
according	O
to	O
a	O
predetermined	O
characteristic	O
and	O
measuring	O
zero	O
crossing	O
intervals	O
of	O
said	O
conditioned	O
signal	O
to	O
provide	O
a	O
binary	O
feature	O
vector	O
;	O
distance	O
measurement	O
means	O
,	O
said	O
distance	O
measurement	O
means	O
comparing	O
said	O
binary	O
feature	O
vector	O
with	O
each	O
of	O
a	O
plurality	O
of	O
binary	O
reference	O
vectors	O
(	O
said	O
reference	O
vectors	O
being	O
organized	O
in	O
sequences	O
corresponding	O
to	O
words	O
)	O
to	O
provide	O
a	O
distance	O
measure	O
at	O
least	O
partially	O
corresponding	O
to	O
a	O
Hamming	O
distance	O
measure	O
with	O
one	O
of	O
said	O
feature	O
vectors	O
;	O
and	O
recognition	O
means	O
for	O
recognizing	O
words	O
in	O
accordance	O
with	O
the	O
sequence	O
of	O
said	O
distance	O
measures	O
between	O
each	O
said	O
sequence	O
of	O
said	O
reference	O
vectors	O
and	O
successively	O
received	O
ones	O
of	O
said	O
feature	O
vectors	O
.	O

According	O
to	O
a	O
further	O
embodiment	O
of	O
the	O
present	O
invention	O
,	O
the	O
present	O
invention	O
comprises	O
:	O
A	O
word	O
recognizer	O
,	O
comprising	O
:	O
input	O
means	O
for	O
receiving	O
an	O
analog	O
input	O
signal	O
corresponding	O
to	O
speech	O
;	O
a	O
signal	O
processor	O
,	O
said	O
processor	O
conditioning	O
said	O
input	O
signal	O
according	O
to	O
a	O
predetermined	O
characteristic	O
and	O
measuring	O
zero	O
crossing	O
intervals	O
of	O
said	O
conditioned	O
signal	O
to	O
provide	O
a	O
feature	O
vector	O
;	O
distance	O
measurement	O
means	O
,	O
said	O
distance	O
measurement	O
means	O
comparing	O
said	O
feature	O
vector	O
with	O
each	O
of	O
a	O
plurality	O
of	O
reference	O
vectors	O
(	O
said	O
reference	O
vectors	O
being	O
organized	O
in	O
sequences	O
corresponding	O
to	O
words	O
)	O
to	O
provide	O
a	O
distance	O
measure	O
at	O
least	O
partially	O
corresponding	O
to	O
a	O
Hamming	O
distance	O
measure	O
with	O
respect	O
to	O
said	O
reference	O
vectors	O
for	O
each	O
successive	O
one	O
of	O
said	O
feature	O
vectors	O
;	O
recognition	O
means	O
for	O
recognizing	O
words	O
in	O
accordance	O
with	O
the	O
sequence	O
of	O
said	O
distance	O
measures	O
between	O
each	O
said	O
sequence	O
of	O
said	O
reference	O
vectors	O
and	O
successively	O
received	O
ones	O
of	O
said	O
reference	O
vectors	O
and	O
successively	O
received	O
ones	O
of	O
said	O
feature	O
vectors	O
,	O
said	O
recognizer	O
also	O
performing	O
a	O
dynamic	O
programming	O
step	O
to	O
provide	O
an	O
optimal	O
subsequence	O
match	O
between	O
successively	O
received	O
ones	O
of	O
said	O
feature	O
vectors	O
and	O
said	O
sequences	O
of	O
reference	O
vectors	O
.	O

BRIEF	O
DESCRIPTION	O
OF	O
THE	O
DRAWINGS	O
The	O
present	O
invention	O
will	O
be	O
described	O
with	O
reference	O
to	O
the	O
accompanying	O
drawings	O
,	O
wherein	O
:	O
FIG	O
.	O
1a	O
shows	O
a	O
block	O
diagram	O
of	O
the	O
word	O
recognizer	O
of	O
the	O
present	O
invention	O
;	O
FIG	O
.	O
1b	O
is	O
a	O
graphical	O
representation	O
of	O
an	O
analog	O
speech	O
signal	O
with	O
respect	O
to	O
time	O
after	O
initial	O
conditioning	O
thereof	O
,	O
but	O
prior	O
to	O
zero-crossing	O
detection	O
,	O
in	O
the	O
word	O
recognizer	O
of	O
FIG	O
.	O
1a	O
;	O
FIG	O
.	O
1c	O
is	O
a	O
schematic	O
representation	O
of	O
the	O
speech	O
signal	O
of	O
FIG	O
.	O
1b	O
,	O
following	O
its	O
subjection	O
to	O
zero-crossing	O
detection	O
,	O
in	O
the	O
word	O
recognizer	O
of	O
FIG	O
.	O
1a	O
;	O
FIG	O
.	O
2	O
shows	O
a	O
block	O
diagram	O
of	O
the	O
preferred	O
hardware	O
implementation	O
of	O
the	O
word	O
recognizer	O
according	O
to	O
the	O
present	O
invention	O
;	O
FIG	O
.	O
3	O
is	O
a	O
schematic	O
diagram	O
indicative	O
of	O
the	O
end	O
of	O
word	O
window	O
operation	O
used	O
to	O
identify	O
word	O
endings	O
in	O
the	O
preferred	O
embodiment	O
of	O
the	O
present	O
invention	O
;	O
FIG	O
.	O
4	O
shows	O
a	O
schematic	O
indication	O
of	O
the	O
processing	O
of	O
raw	O
speaker	O
inputs	O
to	O
achieve	O
the	O
mask	O
vector	O
for	O
a	O
reference	O
template	O
set	O
,	O
according	O
to	O
an	O
empirical	O
unanimity	O
factor	O
;	O
and	O
FIG	O
.	O
5	O
shows	O
an	O
example	O
of	O
the	O
classification	O
of	O
a	O
speech	O
input	O
according	O
to	O
its	O
acoustic	O
segmentation	O
.	O

DESCRIPTION	O
OF	O
THE	O
PREFERRED	O
EMBODIMENTS	O
The	O
present	O
invention	O
includes	O
several	O
points	O
of	O
novelty	O
,	O
and	O
also	O
can	O
be	O
implemented	O
in	O
numerous	O
different	O
ways	O
.	O
Thus	O
,	O
the	O
following	O
description	O
will	O
suggest	O
a	O
number	O
of	O
modifications	O
and	O
variations	O
of	O
the	O
present	O
invention	O
,	O
without	O
thereby	O
implying	O
that	O
the	O
present	O
invention	O
is	O
limited	O
to	O
any	O
specific	O
embodiments	O
thereof	O
.	O

FIG	O
.	O
1a	O
shows	O
generally	O
the	O
organization	O
of	O
the	O
operations	O
used	O
in	O
the	O
word	O
recognizer	O
of	O
the	O
present	O
invention	O
.	O
That	O
is	O
,	O
a	O
raw	O
speech	O
waveform	O
10	O
in	O
the	O
form	O
of	O
an	O
analog	O
speech	O
signal	O
is	O
first	O
subjected	O
to	O
signal	O
conditioning	O
including	O
extremely	O
simple	O
prefiltering	O
operations	O
,	O
e.g.	O
to	O
reject	O
out	O
of	O
band	O
signals	O
,	O
and	O
wherein	O
a	O
pre-amplifier	O
and	O
an	O
analog	O
differentiator	O
12	O
may	O
further	O
act	O
upon	O
the	O
analog	O
speech	O
signal	O
10	O
.	O
The	O
speech	O
signal	O
may	O
then	O
generally	O
take	O
the	O
form	O
of	O
the	O
waveform	O
illustrated	O
in	O
FIG	O
.	O
1b	O
.	O
In	O
the	O
latter	O
respect	O
,	O
it	O
will	O
be	O
observed	O
from	O
FIG	O
.	O
1b	O
that	O
the	O
analog	O
signal	O
is	O
generally	O
sinusoidal	O
and	O
traces	O
an	O
undulating	O
path	O
above	O
and	O
below	O
a	O
"	O
zero	O
"	O
polarity	O
axis	O
during	O
the	O
entire	O
time	O
duration	O
including	O
the	O
respective	O
time	O
instants	O
t	O
.	O
sub	O
.	O
1	O
,	O
t	O
.	O
sub	O
.	O
2	O
,	O
t	O
.	O
sub	O
.	O
3	O
,	O
and	O
t	O
.	O
sub	O
.	O
4	O
.	O
The	O
time	O
instants	O
t	O
.	O
sub	O
.	O
2	O
,	O
t	O
.	O
sub	O
.	O
3	O
,	O
and	O
t	O
.	O
sub	O
.	O
4	O
identify	O
the	O
zero-crossings	O
of	O
the	O
waveform	O
illustrated	O
in	O
FIG	O
.	O
1b	O
in	O
which	O
a	O
transition	O
occurs	O
in	O
the	O
polarity	O
sign	O
of	O
the	O
waveform	O
.	O
Thus	O
,	O
the	O
time	O
instant	O
t	O
.	O
sub	O
.	O
2	O
identifies	O
the	O
zero-crossing	O
of	O
the	O
waveform	O
as	O
it	O
moves	O
from	O
a	O
"	O
plus	O
"	O
polarity	O
to	O
a	O
"	O
minus	O
"	O
polarity	O
;	O
t	O
.	O
sub	O
.	O
3	O
identifies	O
the	O
zero-crossing	O
of	O
the	O
waveform	O
as	O
it	O
moves	O
from	O
a	O
"	O
minus	O
"	O
polarity	O
to	O
a	O
"	O
plus	O
"	O
polarity	O
;	O
and	O
t	O
.	O
sub	O
.	O
4	O
identifies	O
the	O
zero-crossing	O
of	O
the	O
waveform	O
as	O
it	O
moves	O
from	O
a	O
"	O
plus	O
"	O
polarity	O
to	O
a	O
"	O
minus	O
"	O
polarity	O
.	O

Signal	O
conditioning	O
of	O
the	O
analog	O
speech	O
signal	O
continues	O
by	O
monitoring	O
the	O
pre-amplified	O
and	O
differentiated	O
speech	O
signal	O
with	O
a	O
zero-crossing	O
detector	O
13	O
to	O
sense	O
each	O
zero-crossing	O
of	O
the	O
speech	O
signal	O
.	O
The	O
zero-crossing	O
detector	O
13	O
duly	O
counts	O
each	O
polarity	O
transition	O
in	O
the	O
speech	O
signal	O
and	O
assigns	O
a	O
time	O
instant	O
when	O
each	O
such	O
zero-crossing	O
occurs	O
.	O
FIG	O
.	O
1c	O
schematically	O
represents	O
the	O
speech	O
signal	O
of	O
FIG	O
.	O
1b	O
,	O
by	O
indicating	O
the	O
signal	O
polarity	O
at	O
each	O
of	O
the	O
time	O
instants	O
t	O
.	O
sub	O
.	O
1	O
,	O
t	O
.	O
sub	O
.	O
2	O
,	O
t	O
.	O
sub	O
.	O
3	O
,	O
and	O
t	O
.	O
sub	O
.	O
4	O
,	O
as	O
sensed	O
by	O
the	O
zero-crossing	O
detector	O
13	O
.	O

After	O
the	O
signal	O
conditioning	O
effected	O
by	O
the	O
pre-amplifier	O
and	O
analog	O
differentiator	O
12	O
,	O
and	O
the	O
zero-crossing	O
detector	O
13	O
,	O
the	O
conditioned	O
speech	O
signal	O
is	O
exposed	O
to	O
a	O
signal	O
processing	O
unit	O
15	O
,	O
which	O
may	O
take	O
the	O
form	O
of	O
a	O
microcomputer	O
,	O
for	O
further	O
signal	O
processing	O
to	O
enable	O
electronic	O
word	O
recognition	O
of	O
the	O
analog	O
input	O
speech	O
signal	O
10	O
to	O
take	O
place	O
.	O
Word	O
recognition	O
is	O
generally	O
indicated	O
by	O
the	O
declaration	O
output	O
25	O
from	O
the	O
microcomputer	O
15	O
as	O
determined	O
by	O
the	O
decision	O
logic	O
thereof	O
.	O
In	O
the	O
latter	O
respect	O
,	O
referring	O
to	O
FIG	O
.	O
2	O
,	O
the	O
signal	O
processing	O
unit	O
15	O
is	O
illustrated	O
with	O
dashed	O
lines	O
and	O
includes	O
a	O
feature	O
extractor	O
14	O
which	O
receives	O
the	O
conditioned	O
speech	O
signal	O
as	O
an	O
input	O
.	O
The	O
feature	O
extractor	O
14	O
,	O
in	O
the	O
presently	O
preferred	O
embodiment	O
,	O
simply	O
measures	O
the	O
intervals	O
between	O
zero	O
crossings	O
of	O
the	O
digital	O
wave	O
form	O
received	O
from	O
the	O
signal	O
conditioner	O
12	O
,	O
13	O
,	O
and	O
then	O
simply	O
sorts	O
the	O
various	O
zero	O
crossing	O
interval	O
measurements	O
received	O
during	O
any	O
one	O
frame	O
into	O
bins	O
,	O
to	O
provide	O
an	O
integer	O
feature	O
vector	O
which	O
gives	O
a	O
rough	O
measurement	O
of	O
frequency	O
distribution	O
during	O
that	O
frame	O
.	O
The	O
elements	O
of	O
the	O
integer	O
feature	O
vector	O
are	O
then	O
compared	O
with	O
various	O
thresholds	O
,	O
to	O
provide	O
a	O
binary	O
feature	O
vector	O
.	O
This	O
provides	O
the	O
basic	O
feature	O
measurement	O
.	O
Note	O
that	O
no	O
digital-to-analog	O
conversion	O
is	O
required	O
.	O

The	O
distance	O
measurement	O
16	O
then	O
compares	O
the	O
feature	O
vector	O
provided	O
by	O
the	O
feature	O
extractor	O
14	O
as	O
an	O
output	O
along	O
the	O
line	O
19	O
with	O
the	O
feature	O
vector	O
received	O
from	O
a	O
template	O
storage	O
portion	O
18	O
.	O
It	O
is	O
important	O
to	O
note	O
two	O
key	O
features	O
of	O
the	O
invention	O
at	O
this	O
time	O
.	O
First	O
,	O
the	O
storage	O
18	O
contains	O
not	O
only	O
a	O
feature	O
vector	O
for	O
each	O
template	O
but	O
also	O
a	O
mask	O
vector	O
.	O
The	O
mask	O
vector	O
is	O
used	O
to	O
introduce	O
don	O
'	O
t	O
care	O
weightings	O
into	O
the	O
feature	O
vector	O
stored	O
with	O
each	O
reference	O
template	O
,	O
as	O
will	O
be	O
discussed	O
below	O
.	O
Thus	O
,	O
the	O
set	O
of	O
features	O
of	O
an	O
input	O
frame	O
on	O
which	O
comparison	O
for	O
recognition	O
is	O
performed	O
is	O
selected	O
,	O
and	O
can	O
vary	O
for	O
each	O
frame	O
of	O
each	O
word	O
template	O
.	O
Note	O
that	O
the	O
various	O
word	O
templates	O
stored	O
in	O
storage	O
18	O
each	O
comprise	O
a	O
sequence	O
of	O
frames	O
.	O
That	O
is	O
,	O
in	O
a	O
typical	O
case	O
each	O
word	O
template	O
might	O
comprise	O
a	O
sequence	O
of	O
8	O
-	O
12	O
frames	O
.	O
(	O
Each	O
of	O
the	O
reference	O
frames	O
is	O
expected	O
to	O
correspond	O
to	O
2	O
of	O
the	O
20	O
millisecond	O
input	O
frames	O
,	O
but	O
can	O
be	O
warped	O
to	O
correspond	O
to	O
only	O
one	O
of	O
the	O
frames	O
or	O
to	O
as	O
many	O
as	O
4	O
of	O
the	O
input	O
frames	O
,	O
as	O
described	O
below	O
.	O
)	O
The	O
time	O
alignment	O
operation	O
20	O
selects	O
the	O
best	O
match	O
of	O
each	O
of	O
the	O
reference	O
templates	O
to	O
the	O
current	O
input	O
frame	O
sequence	O
,	O
and	O
provides	O
running	O
measurements	O
of	O
the	O
raw	O
match	O
as	O
output	O
.	O
a	O
word	O
end	O
detector	O
22	O
also	O
provides	O
along	O
line	O
23	O
the	O
input	O
to	O
high	O
level	O
decision	O
logic	O
24	O
,	O
and	O
the	O
word	O
end	O
measurement	O
,	O
together	O
with	O
the	O
running	O
cumulative	O
word	O
fit	O
provided	O
by	O
the	O
time	O
alignment	O
block	O
20	O
,	O
provide	O
the	O
basis	O
for	O
the	O
high	O
level	O
decision	O
logic	O
24	O
to	O
make	O
the	O
word	O
recognition	O
decision	O
which	O
is	O
provided	O
as	O
a	O
declaration	O
output	O
25	O
.	O

The	O
operation	O
of	O
these	O
various	O
components	O
of	O
the	O
invention	O
will	O
now	O
be	O
discussed	O
in	O
greater	O
detail	O
.	O
The	O
speech	O
signal	O
10	O
,	O
which	O
is	O
typically	O
raw	O
analog	O
input	O
from	O
a	O
microphone	O
(	O
and	O
typically	O
a	O
preamplifier	O
)	O
is	O
provided	O
to	O
a	O
signal	O
conditioner	O
12	O
,	O
13	O
.	O

The	O
filter	O
functions	O
preferably	O
performed	O
by	O
the	O
signal	O
conditioner	O
12	O
,	O
13	O
include	O
only	O
an	O
extremely	O
simple	O
filtering	O
operation	O
.	O
In	O
the	O
presently	O
preferred	O
embodiment	O
,	O
the	O
signal	O
conditioner	O
12	O
,	O
13	O
comprises	O
a	O
low	O
pass	O
filter	O
with	O
a	O
corner	O
frequency	O
of	O
6	O
.	O
25	O
KHz	O
to	O
reject	O
out	O
of	O
band	O
signals	O
an	O
analog	O
differentiator	O
,	O
and	O
a	O
Schmitt	O
trigger	O
.	O
The	O
differentiator	O
effectively	O
emphasizes	O
the	O
high	O
frequency	O
components	O
in	O
the	O
input	O
signal	O
.	O
That	O
is	O
,	O
the	O
zero	O
crossing	O
characteristics	O
of	O
a	O
signal	O
can	O
easily	O
be	O
dominated	O
by	O
a	O
strong	O
low	O
frequency	O
component	O
,	O
and	O
the	O
use	O
of	O
the	O
first	O
derivative	O
as	O
the	O
function	O
on	O
which	O
zero	O
crossing	O
analysis	O
is	O
performed	O
minimizes	O
this	O
problem	O
.	O

It	O
should	O
be	O
noted	O
that	O
the	O
filtering	O
functions	O
are	O
not	O
necessarily	O
so	O
minimal	O
.	O
In	O
particular	O
,	O
the	O
zero	O
crossing	O
characteristics	O
of	O
a	O
speech	O
signal	O
are	O
highly	O
sensitive	O
to	O
the	O
frequency	O
preemphasis	O
and	O
also	O
to	O
the	O
phase	O
shifting	O
introduced	O
by	O
a	O
prefiltering	O
section	O
,	O
and	O
a	O
wide	O
variety	O
of	O
prefiltering	O
characteristics	O
may	O
optionally	O
be	O
used	O
,	O
e.g.	O
,	O
to	O
provide	O
a	O
more	O
critical	O
distinction	O
between	O
the	O
words	O
in	O
a	O
given	O
vocabulary	O
set	O
or	O
to	O
reject	O
particular	O
noise	O
characteristics	O
.	O
That	O
is	O
,	O
the	O
prefiltering	O
characteristics	O
will	O
substantially	O
affect	O
the	O
extent	O
to	O
which	O
perceptually	O
distinct	O
input	O
frames	O
are	O
measurably	O
distinct	O
in	O
the	O
very	O
limited	O
information	O
provided	O
by	O
the	O
recognition	O
algorithm	O
of	O
the	O
present	O
invention	O
.	O
A	O
wide	O
variety	O
of	O
such	O
filtering	O
characteristics	O
could	O
be	O
introduced	O
in	O
modifications	O
and	O
variations	O
of	O
the	O
present	O
invention	O
,	O
but	O
the	O
principal	O
embodiment	O
of	O
the	O
present	O
invention	O
uses	O
only	O
simple	O
processing	O
functions	O
as	O
noted	O
.	O

In	O
addition	O
,	O
bandpass	O
filtering	O
can	O
also	O
be	O
used	O
in	O
the	O
signal	O
conditioner	O
,	O
to	O
reject	O
out	O
of	O
band	O
signals	O
,	O
although	O
this	O
is	O
not	O
used	O
in	O
the	O
presently	O
preferred	O
embodiment	O
.	O

It	O
should	O
be	O
noted	O
that	O
the	O
Schmitt	O
trigger	O
performs	O
a	O
rather	O
important	O
signal	O
processing	O
function	O
,	O
namely	O
center-clipping	O
.	O
That	O
is	O
,	O
where	O
zero	O
crossings	O
to	O
a	O
function	O
including	O
noise	O
are	O
being	O
measured	O
,	O
even	O
a	O
very	O
low	O
noise	O
power	O
,	O
at	O
moments	O
when	O
the	O
function	O
value	O
is	O
near	O
zero	O
,	O
can	O
introduce	O
many	O
spurious	O
zero	O
crossings	O
.	O
To	O
avoid	O
this	O
problem	O
in	O
recognition	O
,	O
center-clipping	O
(	O
using	O
the	O
hysteresis	O
characteristics	O
of	O
the	O
Schmitt	O
trigger	O
)	O
in	O
effect	O
ignores	O
zero	O
crossings	O
unless	O
the	O
waveform	O
reaches	O
a	O
certain	O
minimum	O
value	O
between	O
two	O
adjacent	O
zero	O
crossings	O
.	O
Although	O
a	O
Schmitt	O
trigger	O
is	O
not	O
the	O
only	O
way	O
to	O
accomplish	O
this	O
center-clipping	O
,	O
some	O
such	O
function	O
in	O
the	O
signal	O
conditioner	O
is	O
highly	O
desirable	O
,	O
since	O
it	O
greatly	O
reduces	O
the	O
noise	O
in	O
the	O
low-interval	O
zero	O
crossings	O
.	O

The	O
actual	O
zero	O
crossing	O
information	O
can	O
be	O
obtained	O
in	O
a	O
variety	O
of	O
ways	O
,	O
as	O
is	O
obvious	O
to	O
those	O
skilled	O
in	O
the	O
art	O
.	O
For	O
example	O
,	O
the	O
analog	O
input	O
signal	O
can	O
be	O
applied	O
to	O
the	O
Schmitt	O
trigger	O
mentioned	O
,	O
or	O
to	O
a	O
polarity	O
sensing	O
saturated	O
output	O
amplifier	O
,	O
to	O
provide	O
a	O
strongly	O
clipped	O
signal	O
,	O
i	O
.	O
e	O
.	O
,	O
a	O
sequence	O
of	O
rectangular	O
waveforms	O
of	O
alternating	O
sign	O
.	O
These	O
waveforms	O
can	O
then	O
be	O
converted	O
to	O
logic	O
levels	O
and	O
provided	O
as	O
inputs	O
to	O
a	O
microcomputer	O
which	O
counts	O
the	O
duration	O
of	O
each	O
rectangular	O
waveform	O
portion	O
(	O
that	O
is	O
,	O
the	O
duration	O
of	O
each	O
interval	O
between	O
zero	O
crossings	O
)	O
in	O
terms	O
of	O
clock	O
cycles	O
of	O
the	O
microcomputer	O
.	O
Of	O
course	O
,	O
this	O
function	O
could	O
easily	O
be	O
embodied	O
in	O
SSI	O
logic	O
,	O
with	O
a	O
flip-flop	O
and	O
counters	O
,	O
or	O
otherwise	O
,	O
but	O
the	O
embodiment	O
in	O
a	O
microprocessor	O
or	O
microcomputer	O
is	O
preferred	O
.	O
The	O
clock	O
resolution	O
of	O
the	O
microprocessor	O
is	O
preferably	O
plus	O
or	O
minus	O
40	O
microseconds	O
or	O
less	O
,	O
but	O
most	O
commercial	O
microprocessors	O
can	O
meet	O
this	O
.	O
For	O
example	O
,	O
an	O
8080	O
,	O
a	O
Z-80	O
,	O
or	O
a	O
TMS	O
7000	O
would	O
all	O
be	O
suitable	O
.	O

The	O
next	O
step	O
in	O
processing	O
the	O
speech	O
signal	O
is	O
to	O
generate	O
counts	O
of	O
the	O
zero-crossing	O
interval	O
distribution	O
in	O
each	O
frame	O
of	O
a	O
sequence	O
of	O
frames	O
,	O
spaced	O
at	O
a	O
frame	O
period	O
.	O
In	O
the	O
presently	O
preferred	O
embodiment	O
,	O
the	O
frame	O
period	O
is	O
20	O
msec	O
,	O
but	O
this	O
frame	O
period	O
can	O
easily	O
be	O
varied	O
.	O
If	O
a	O
longer	O
frame	O
period	O
is	O
used	O
,	O
rapid	O
speech	O
may	O
not	O
be	O
well	O
recognized	O
,	O
but	O
this	O
may	O
be	O
an	O
acceptbale	O
tradeoff	O
in	O
some	O
applications	O
for	O
the	O
sake	O
of	O
lower	O
processor	O
load	O
.	O
Similarly	O
,	O
a	O
shorter	O
frame	O
period	O
imposes	O
a	O
higher	O
processor	O
load	O
,	O
but	O
provides	O
a	O
relatively	O
slight	O
gain	O
in	O
performance	O
.	O
Thus	O
,	O
frame	O
periods	O
in	O
the	O
range	O
of	O
1	O
to	O
200	O
msec	O
are	O
within	O
the	O
scope	O
of	O
the	O
present	O
invention	O
.	O

It	O
should	O
be	O
noted	O
that	O
the	O
input	O
is	O
not	O
necessarily	O
even	O
divided	O
into	O
frames	O
prior	O
to	O
this	O
stage	O
.	O
That	O
is	O
,	O
an	O
advantage	O
of	O
using	O
a	O
microprocessor	O
to	O
measure	O
the	O
zero	O
crossing	O
intervals	O
is	O
that	O
the	O
microprocessor	O
can	O
at	O
the	O
same	O
time	O
impose	O
the	O
initial	O
division	O
of	O
the	O
analog	O
input	O
signal	O
into	O
frames	O
.	O

At	O
each	O
frame	O
,	O
a	O
feature	O
vector	O
is	O
generated	O
from	O
the	O
input	O
as	O
follows	O
:	O
first	O
,	O
the	O
RMS	O
energy	O
of	O
the	O
analog	O
signal	O
is	O
measured	O
over	O
an	O
interval	O
which	O
need	O
not	O
exactly	O
coincide	O
with	O
the	O
frame	O
period	O
.	O
For	O
example	O
,	O
in	O
the	O
presently	O
preferred	O
embodiment	O
,	O
the	O
energy	O
is	O
measured	O
over	O
an	O
analysis	O
window	O
of	O
30	O
msec	O
.	O
This	O
provides	O
some	O
smoothing	O
of	O
the	O
energy	O
values	O
between	O
frames	O
,	O
and	O
precludes	O
missing	O
short	O
high-energy	O
events	O
.	O
In	O
addition	O
,	O
the	O
zero	O
crossing	O
intervals	O
are	O
classified	O
at	O
this	O
time	O
.	O
Again	O
,	O
the	O
analysis	O
window	O
over	O
which	O
the	O
characteristics	O
of	O
the	O
zero	O
crossings	O
are	O
measured	O
need	O
not	O
be	O
exactly	O
the	O
same	O
as	O
the	O
frame	O
period	O
,	O
and	O
is	O
30	O
msec	O
in	O
the	O
presently	O
preferred	O
embodiment	O
.	O

Thus	O
,	O
to	O
generate	O
the	O
feature	O
vector	O
,	O
the	O
zero	O
crossing	O
intervals	O
of	O
the	O
analog	O
waveform	O
over	O
a	O
30	O
msec	O
interval	O
are	O
examined	O
.	O
The	O
presently	O
preferred	O
method	O
of	O
extracting	O
a	O
feature	O
vector	O
from	O
the	O
multiple	O
zero	O
crossing	O
interval	O
numbers	O
is	O
as	O
follows	O
,	O
but	O
of	O
course	O
a	O
wide	O
range	O
of	O
other	O
expedients	O
could	O
be	O
used	O
to	O
provide	O
a	O
feature	O
vector	O
representative	O
of	O
the	O
distribution	O
of	O
zero	O
crossing	O
intervals	O
.	O
In	O
the	O
presently	O
preferred	O
embodiment	O
,	O
the	O
zero	O
crossing	O
intervals	O
within	O
the	O
30	O
msec	O
analysis	O
waveform	O
are	O
sorted	O
into	O
four	O
"	O
bins	O
"	O
,	O
where	O
each	O
bin	O
generally	O
corresponds	O
to	O
a	O
bandpass	O
filter	O
.	O
That	O
is	O
,	O
bin	O
1	O
counts	O
the	O
number	O
of	O
zero	O
crossing	O
intervals	O
within	O
the	O
analysis	O
window	O
which	O
have	O
durations	O
between	O
seven	O
and	O
13	O
samples	O
(	O
one	O
sample	O
is	O
equal	O
to	O
80	O
microseconds	O
in	O
this	O
embodiment	O
)	O
;	O
bin	O
2	O
counts	O
the	O
number	O
of	O
zero	O
crossing	O
intervals	O
in	O
the	O
analysis	O
window	O
with	O
a	O
duration	O
between	O
four	O
and	O
six	O
intervals	O
;	O
bin	O
3	O
counts	O
the	O
number	O
of	O
zero	O
crossing	O
intervals	O
in	O
the	O
analysis	O
window	O
with	O
a	O
duration	O
of	O
two	O
or	O
three	O
samples	O
;	O
and	O
bin	O
4	O
counts	O
the	O
number	O
of	O
zero	O
crossing	O
intervals	O
in	O
the	O
analysis	O
window	O
which	O
have	O
a	O
duration	O
of	O
one	O
sample	O
.	O
These	O
numbers	O
are	O
preferably	O
accumulated	O
by	O
the	O
microcomputer	O
as	O
the	O
clipped	O
rectangular	O
waveform	O
is	O
received	O
,	O
so	O
that	O
the	O
actual	O
durations	O
of	O
the	O
various	O
zero	O
crossings	O
need	O
not	O
be	O
stored	O
at	O
any	O
point	O
.	O
That	O
is	O
,	O
when	O
the	O
clipped	O
input	O
waveform	O
changes	O
sign	O
,	O
the	O
microcomputer	O
preferably	O
notes	O
the	O
number	O
of	O
clock	O
pulses	O
since	O
the	O
last	O
change	O
of	O
sign	O
,	O
increments	O
the	O
count	O
in	O
the	O
appropriate	O
bin	O
by	O
one	O
,	O
and	O
resets	O
its	O
count	O
register	O
and	O
begins	O
to	O
count	O
the	O
number	O
of	O
clock	O
pulses	O
until	O
the	O
next	O
zero	O
crossing	O
.	O
Thus	O
,	O
the	O
number	O
of	O
zero	O
crossings	O
counted	O
in	O
any	O
one	O
"	O
bin	O
"	O
corresponds	O
generally	O
to	O
the	O
energy	O
which	O
would	O
have	O
been	O
measured	O
through	O
a	O
corresponding	O
bandpass	O
filter	O
,	O
and	O
the	O
distribution	O
over	O
all	O
of	O
the	O
bins	O
provides	O
an	O
analog	O
feature	O
vector	O
,	O
which	O
in	O
the	O
presently	O
preferred	O
embodiment	O
includes	O
four	O
analog	O
numbers	O
.	O

Next	O
,	O
this	O
integer	O
feature	O
vector	O
is	O
converted	O
to	O
a	O
binary	O
feature	O
vector	O
as	O
follows	O
.	O
For	O
example	O
,	O
the	O
count	O
found	O
in	O
bin	O
3	O
is	O
compared	O
to	O
two	O
thresholds	O
to	O
generate	O
elements	O
five	O
and	O
six	O
of	O
the	O
binary	O
feature	O
vector	O
:	O
if	O
the	O
count	O
is	O
greater	O
than	O
a	O
threshold	O
B3L	O
,	O
then	O
element	O
5	O
of	O
the	O
binary	O
feature	O
vector	O
is	O
set	O
at	O
1	O
(	O
and	O
otherwise	O
remains	O
at	O
zero	O
)	O
;	O
if	O
the	O
count	O
in	O
bin	O
3	O
is	O
less	O
than	O
a	O
second	O
threshold	O
B3U	O
,	O
then	O
a	O
1	O
is	O
entered	O
in	O
element	O
6	O
of	O
the	O
binary	O
feature	O
vector	O
,	O
which	O
also	O
otherwise	O
remains	O
at	O
zero	O
)	O
.	O
That	O
is	O
,	O
each	O
bin	O
has	O
lower	O
and	O
upper	O
thresholds	O
,	O
which	O
are	O
empirically	O
chosen	O
to	O
maximize	O
the	O
discrimination	O
between	O
words	O
used	O
.	O
In	O
the	O
presently	O
preferred	O
embodiment	O
,	O
the	O
eight	O
thresholds	O
used	O
,	O
expressed	O
in	O
number	O
of	O
sample	O
values	O
,	O
are	O
:	O

______________________________________	O
Bin	O
number	O
Lower	O
threshold	O
Upper	O
Threshold	O
______________________________________	O
1	O
1	O
4	O
2	O
4	O
8	O
3	O
8	O
16	O
4	O
16	O
32	O
______________________________________	O

Again	O
,	O
it	O
should	O
be	O
noted	O
that	O
the	O
presently	O
operational	O
embodiment	O
has	O
used	O
very	O
frequent	O
high	O
density	O
resolution	O
sampling	O
as	O
an	O
initial	O
step	O
,	O
and	O
hence	O
the	O
zero	O
crossing	O
intervals	O
are	O
expressed	O
in	O
samples	O
,	O
but	O
the	O
contemplated	O
best	O
mode	O
of	O
the	O
present	O
invention	O
would	O
not	O
use	O
such	O
expensive	O
high-rate	O
high-resolution	O
sampling	O
,	O
and	O
would	O
use	O
analog	O
stages	O
initially	O
instead	O
,	O
as	O
discussed	O
above	O
.	O

Thus	O
,	O
the	O
foregoing	O
process	O
has	O
produced	O
a	O
feature	O
vector	O
(	O
eight	O
bits	O
in	O
the	O
presently	O
preferred	O
embodiment	O
)	O
for	O
each	O
frame	O
of	O
the	O
input	O
signal	O
.	O
This	O
feature	O
vector	O
is	O
compared	O
with	O
various	O
reference	O
vectors	O
according	O
to	O
a	O
distance	O
measure	O
,	O
and	O
word	O
recognition	O
is	O
made	O
in	O
accordance	O
with	O
the	O
sequence	O
of	O
distance	O
measures	O
between	O
the	O
sequence	O
of	O
reference	O
vectors	O
in	O
a	O
word	O
template	O
and	O
all	O
or	O
some	O
of	O
the	O
sequence	O
of	O
input	O
feature	O
vectors	O
received	O
.	O

The	O
distance	O
measure	O
used	O
is	O
essentially	O
a	O
Hamming	O
distance	O
measure	O
between	O
the	O
input	O
frame	O
and	O
any	O
particular	O
reference	O
frame	O
,	O
but	O
there	O
is	O
one	O
important	O
additional	O
point	O
of	O
novelty	O
in	O
the	O
distance	O
measure	O
.	O
A	O
mask	O
vector	O
is	O
preferably	O
stored	O
along	O
with	O
each	O
reference	O
vector	O
,	O
to	O
mask	O
the	O
less	O
significant	O
elements	O
of	O
the	O
reference	O
vectors	O
.	O
Thus	O
,	O
the	O
actual	O
template	O
for	O
a	O
word	O
consists	O
of	O
a	O
sequence	O
of	O
pairs	O
of	O
binary	O
vectors	O
:	O
for	O
each	O
reference	O
frame	O
in	O
the	O
word	O
template	O
,	O
both	O
a	O
reference	O
feature	O
vector	O
and	O
a	O
mask	O
vector	O
are	O
stored	O
.	O
For	O
example	O
,	O
if	O
the	O
fourth	O
element	O
of	O
a	O
mask	O
vector	O
is	O
1	O
,	O
then	O
the	O
fourth	O
element	O
of	O
the	O
corresponding	O
reference	O
vector	O
is	O
used	O
in	O
the	O
distance	O
computation	O
.	O
If	O
the	O
mask	O
vector	O
element	O
is	O
zero	O
,	O
the	O
corresponding	O
element	O
of	O
the	O
associated	O
reference	O
vector	O
is	O
not	O
used	O
in	O
the	O
distance	O
computation	O
.	O
Thus	O
,	O
the	O
distance	O
between	O
the	O
test	O
feature	O
vector	O
TF	O
,	O
and	O
the	O
i-th	O
reference	O
vector	O
RF	O
(	O
i	O
)	O
and	O
mask	O
vector	O
RM	O
(	O
i	O
)	O
is	O
defined	O
by	O
the	O
following	O
logical	O
operation	O
:	O
D.	O
sub	O
.	O
TF	O
,	O
i	O
=	O
Hamming	O
(	O
RM	O
(	O
i	O
)	O
.	O
and	O
.	O
(	O
TF	O
.	O
xor	O
.	O
RF	O
(	O
i	O
)	O
)	O
)	O
.	O

Thus	O
,	O
D.	O
sub	O
.	O
TF	O
,	O
i	O
is	O
the	O
Hamming	O
distance	O
between	O
the	O
test	O
vector	O
TF	O
and	O
the	O
i	O
vector	O
set	O
of	O
the	O
template	O
for	O
the	O
given	O
word	O
.	O
This	O
distance	O
indicates	O
the	O
number	O
of	O
similarities	O
between	O
test	O
feature	O
vector	O
TF	O
and	O
reference	O
vector	O
RF	O
(	O
i	O
)	O
,	O
with	O
masking	O
defined	O
by	O
the	O
zero	O
valued	O
elements	O
in	O
the	O
mask	O
vector	O
RM	O
(	O
i	O
)	O
.	O

It	O
should	O
be	O
recognized	O
that	O
this	O
use	O
of	O
a	O
mask	O
vector	O
to	O
exclude	O
insignificant	O
components	O
of	O
each	O
reference	O
vector	O
is	O
broadly	O
novel	O
,	O
and	O
may	O
be	O
modified	O
and	O
varied	O
widely	O
.	O
For	O
example	O
,	O
it	O
is	O
not	O
strictly	O
necessary	O
that	O
the	O
feature	O
and	O
reference	O
vectors	O
be	O
binary	O
,	O
since	O
a	O
binary	O
masking	O
value	O
may	O
be	O
used	O
to	O
mask	O
the	O
results	O
of	O
an	O
analog	O
subtraction	O
step	O
as	O
well	O
.	O
In	O
fact	O
,	O
it	O
is	O
not	O
even	O
strictly	O
necessary	O
that	O
the	O
mask	O
vector	O
itself	O
be	O
binary	O
,	O
although	O
this	O
is	O
greatly	O
preferable	O
.	O
If	O
the	O
mask	O
vector	O
is	O
allowed	O
to	O
take	O
on	O
analog	O
values	O
,	O
then	O
it	O
functions	O
essentially	O
as	O
a	O
weight	O
vector	O
.	O
A	O
weighting	O
vector	O
is	O
still	O
useful	O
for	O
disregarding	O
insignificant	O
bits	O
in	O
a	O
recognition	O
comparison	O
,	O
but	O
an	O
analog	O
weighting	O
vector	O
does	O
not	O
offer	O
nearly	O
the	O
computational	O
efficiency	O
which	O
is	O
provided	O
by	O
a	O
binary	O
mask	O
vector	O
.	O
Moreover	O
,	O
preparations	O
of	O
a	O
binary	O
mask	O
vector	O
for	O
a	O
given	O
word	O
recognition	O
set	O
can	O
be	O
performed	O
very	O
simply	O
and	O
efficiently	O
,	O
as	O
will	O
be	O
described	O
below	O
.	O

In	O
addition	O
,	O
it	O
should	O
be	O
noted	O
that	O
the	O
novelty	O
in	O
the	O
use	O
of	O
a	O
masking	O
vector	O
is	O
not	O
by	O
any	O
means	O
limited	O
to	O
use	O
of	O
an	O
eight-bit	O
feature	O
vector	O
,	O
nor	O
to	O
recognition	O
applications	O
where	O
the	O
essential	O
feature	O
vector	O
extraction	O
step	O
is	O
based	O
on	O
zero	O
crossing	O
intervals	O
,	O
but	O
can	O
be	O
applied	O
to	O
any	O
speech	O
recognition	O
system	O
whatsoever	O
.	O

The	O
method	O
by	O
which	O
the	O
reference	O
vectors	O
in	O
a	O
word	O
template	O
are	O
generated	O
will	O
now	O
be	O
described	O
.	O

To	O
construct	O
a	O
template	O
,	O
the	O
starting	O
point	O
is	O
a	O
large	O
number	O
of	O
independent	O
samples	O
of	O
that	O
word	O
as	O
pronounced	O
by	O
a	O
population	O
which	O
is	O
sufficiently	O
diverse	O
to	O
approximate	O
that	O
whose	O
speech	O
the	O
recognizer	O
will	O
be	O
required	O
to	O
recognize	O
.	O
For	O
example	O
,	O
if	O
the	O
speech	O
recognizer	O
in	O
use	O
will	O
be	O
exposed	O
to	O
spoken	O
inputs	O
from	O
men	O
,	O
women	O
and	O
children	O
having	O
all	O
of	O
the	O
common	O
regional	O
accents	O
,	O
then	O
the	O
initial	O
data	O
base	O
should	O
also	O
be	O
obtained	O
from	O
men	O
,	O
women	O
,	O
and	O
children	O
,	O
and	O
should	O
also	O
include	O
as	O
many	O
as	O
possible	O
of	O
the	O
regional	O
accent	O
types	O
which	O
must	O
be	O
recognized	O
in	O
use	O
.	O

Correspondingly	O
,	O
if	O
the	O
recognizer	O
is	O
to	O
be	O
operated	O
in	O
a	O
speaker-dependent	O
mode	O
or	O
is	O
to	O
be	O
customized	O
for	O
a	O
small	O
group	O
of	O
speakers	O
,	O
the	O
number	O
of	O
samples	O
must	O
remain	O
large	O
,	O
but	O
the	O
speakers	O
within	O
the	O
relevant	O
set	O
will	O
be	O
proportionately	O
represented	O
.	O
For	O
example	O
,	O
if	O
four	O
speakers	O
are	O
to	O
be	O
recognized	O
,	O
each	O
should	O
contribute	O
an	O
average	O
of	O
25	O
samples	O
to	O
the	O
data	O
base	O
.	O

The	O
first	O
step	O
is	O
a	O
manual	O
classification	O
step	O
.	O
Suppose	O
that	O
a	O
template	O
is	O
to	O
be	O
constructed	O
for	O
the	O
word	O
"	O
stop	O
"	O
.	O
This	O
word	O
has	O
six	O
distinct	O
acoustic	O
segments	O
as	O
shown	O
in	O
the	O
spectrogram	O
of	O
FIG	O
.	O
5	O
.	O
These	O
are	O
the	O
initial	O
sibilant/s/	O
,	O
stop	O
and	O
release/t/	O
,	O
vowel	O
portion/A/	O
,	O
and	O
the	O
final	O
stop	O
and	O
release/p/	O
.	O
These	O
six	O
segments	O
are	O
preferably	O
marked	O
interactively	O
,	O
with	O
the	O
aid	O
of	O
spectrogram	O
and	O
waveform	O
plots	O
,	O
on	O
graphics	O
terminals	O
,	O
for	O
each	O
sample	O
in	O
the	O
data	O
base	O
,	O
Thus	O
,	O
this	O
step	O
manually	O
establishes	O
the	O
location	O
of	O
corresponding	O
acoustic	O
segments	O
within	O
the	O
data	O
base	O
sampled	O
.	O
This	O
step	O
is	O
used	O
because	O
various	O
speakers	O
will	O
vary	O
the	O
relative	O
length	O
of	O
different	O
acoustic	O
segments	O
within	O
a	O
word	O
,	O
and	O
it	O
is	O
necessary	O
,	O
when	O
estimating	O
from	O
the	O
data	O
sample	O
what	O
feature	O
vector	O
would	O
correspond	O
to	O
a	O
vowel/A/	O
,	O
that	O
the	O
computation	O
not	O
be	O
distorted	O
by	O
time-warped	O
samples	O
in	O
which	O
the	O
speaker	O
was	O
actually	O
pronouncing	O
a/t/	O
or	O
a/p/	O
.	O
Of	O
course	O
,	O
this	O
time-alignment	O
of	O
the	O
samples	O
in	O
the	O
data	O
base	O
could	O
be	O
accomplished	O
other	O
ways	O
,	O
including	O
automatic	O
classification	O
of	O
the	O
samples	O
by	O
acoustic	O
segment	O
boundaries	O
according	O
to	O
,	O
e.g.	O
,	O
LPC	O
characteristics	O
,	O
but	O
the	O
presently	O
preferred	O
embodiment	O
uses	O
manual	O
classification	O
at	O
this	O
step	O
.	O

Thus	O
,	O
after	O
this	O
manual	O
classification	O
step	O
,	O
the	O
segment	O
within	O
each	O
sample	O
in	O
the	O
data	O
base	O
which	O
corresponds	O
to	O
the	O
successive	O
acoustic	O
segments	O
which	O
must	O
be	O
included	O
in	O
the	O
reference	O
vector	O
has	O
been	O
established	O
.	O
The	O
average	O
duration	O
of	O
each	O
of	O
the	O
acoustic	O
segments	O
is	O
then	O
computed	O
to	O
establish	O
the	O
number	O
of	O
reference	O
frames	O
needed	O
in	O
each	O
segment	O
.	O
For	O
example	O
,	O
suppose	O
the	O
sibilant	O
/s/	O
has	O
an	O
average	O
duration	O
of	O
130	O
msec	O
.	O
Then	O
,	O
at	O
a	O
reference	O
frame	O
period	O
of	O
40	O
msec	O
.	O
,	O
three	O
reference	O
frames	O
in	O
the	O
word	O
template	O
will	O
correspond	O
to	O
the	O
sibilant	O
/s/	O
.	O
(	O
The	O
period	O
of	O
the	O
reference	O
frame	O
in	O
the	O
presently	O
preferred	O
embodiment	O
is	O
exactly	O
twice	O
as	O
long	O
as	O
the	O
frame	O
interval	O
in	O
the	O
input	O
speech	O
,	O
for	O
reasons	O
which	O
will	O
be	O
discussed	O
below	O
.	O
)	O
The	O
next	O
step	O
is	O
to	O
locate	O
,	O
in	O
each	O
of	O
the	O
100	O
samples	O
,	O
which	O
portions	O
of	O
the	O
sample	O
shall	O
be	O
included	O
in	O
the	O
computation	O
of	O
the	O
expected	O
characteristics	O
of	O
each	O
of	O
the	O
three	O
reference	O
frames	O
in	O
the	O
word	O
template	O
which	O
are	O
to	O
correspond	O
to	O
the	O
sibilant	O
/s/	O
.	O
That	O
is	O
,	O
in	O
this	O
example	O
the	O
three	O
/s/	O
reference	O
feature	O
vectors	O
should	O
be	O
computed	O
based	O
on	O
measurements	O
at	O
three	O
points	O
evenly	O
spaced	O
within	O
the	O
duration	O
of	O
the	O
phoneme	O
/s/	O
,	O
for	O
each	O
sample	O
in	O
the	O
data	O
base	O
.	O
Thus	O
,	O
the	O
result	O
of	O
this	O
process	O
is	O
that	O
,	O
for	O
each	O
frame	O
in	O
the	O
word	O
template	O
for	O
which	O
a	O
reference	O
vector	O
must	O
be	O
computed	O
,	O
a	O
unique	O
location	O
within	O
each	O
sample	O
in	O
the	O
data	O
base	O
to	O
correspond	O
to	O
that	O
frame	O
has	O
been	O
identified	O
.	O

By	O
way	O
of	O
example	O
,	O
FIG	O
.	O
4	O
generally	O
illustrates	O
the	O
process	O
by	O
which	O
each	O
reference	O
vector	O
in	O
the	O
word	O
template	O
is	O
computed	O
,	O
based	O
on	O
the	O
corresponding	O
portions	O
of	O
the	O
various	O
samples	O
in	O
the	O
data	O
base	O
.	O
First	O
,	O
a	O
tolerance	O
number	O
called	O
a	O
unanimity	O
factor	O
(	O
nu	O
)	O
is	O
chosen	O
empirically	O
.	O
In	O
the	O
presently	O
preferred	O
embodiment	O
nu	O
is	O
set	O
equal	O
to	O
0	O
.	O
93	O
,	O
but	O
may	O
be	O
greater	O
or	O
lesser	O
depending	O
on	O
the	O
uniformity	O
of	O
the	O
speakers	O
in	O
the	O
data	O
base	O
,	O
and	O
to	O
some	O
extent	O
on	O
the	O
size	O
of	O
the	O
data	O
base	O
.	O
However	O
,	O
in	O
the	O
presently	O
preferred	O
embodiment	O
,	O
a	O
value	O
greater	O
than	O
90	O
%	O
is	O
preferably	O
used	O
,	O
and	O
is	O
preferably	O
in	O
the	O
range	O
of	O
90	O
to	O
97	O
%	O
.	O

The	O
unanimity	O
factor	O
nu	O
tells	O
how	O
many	O
disagreements	O
can	O
be	O
tolerated	O
on	O
any	O
particular	O
bit	O
of	O
the	O
feature	O
vector	O
for	O
corresponding	O
frames	O
before	O
concluding	O
that	O
there	O
is	O
no	O
concurrence	O
of	O
behavior	O
over	O
the	O
population	O
.	O
That	O
is	O
,	O
for	O
example	O
,	O
suppose	O
that	O
nu	O
is	O
chosen	O
equal	O
to	O
0	O
.	O
93	O
.	O
In	O
this	O
case	O
,	O
if	O
93	O
or	O
more	O
of	O
100	O
samples	O
in	O
the	O
data	O
base	O
have	O
a	O
value	O
for	O
the	O
first	O
analog	O
parameter	O
(	O
at	O
corresponding	O
frame	O
locations	O
)	O
which	O
is	O
larger	O
than	O
B1L	O
,	O
then	O
the	O
first	O
elements	O
of	O
the	O
reference	O
feature	O
vector	O
and	O
of	O
the	O
mask	O
vector	O
are	O
set	O
equal	O
to	O
1	O
.	O
If	O
93	O
or	O
more	O
of	O
the	O
samples	O
have	O
a	O
value	O
for	O
the	O
first	O
parameter	O
which	O
is	O
below	O
B1L	O
,	O
then	O
the	O
first	O
element	O
of	O
the	O
reference	O
feature	O
vector	O
is	O
0	O
and	O
the	O
first	O
element	O
of	O
the	O
mask	O
vector	O
is	O
1	O
.	O
That	O
is	O
,	O
in	O
this	O
case	O
the	O
population	O
would	O
have	O
agreed	O
that	O
the	O
general	O
behavior	O
is	O
to	O
have	O
the	O
number	O
of	O
zero	O
crossing	O
intervals	O
in	O
the	O
first	O
"	O
bin	O
"	O
less	O
than	O
the	O
threshold	O
B1L	O
.	O
However	O
,	O
if	O
less	O
than	O
93	O
samples	O
agree	O
in	O
this	O
respect	O
,	O
then	O
the	O
first	O
element	O
of	O
the	O
mask	O
vector	O
is	O
set	O
equal	O
to	O
zero	O
,	O
and	O
the	O
first	O
element	O
of	O
the	O
reference	O
vector	O
is	O
a	O
"	O
don	O
'	O
t	O
care	O
"	O
value	O
and	O
can	O
be	O
0	O
or	O
1	O
.	O

Thus	O
,	O
this	O
process	O
generates	O
a	O
word	O
template	O
which	O
is	O
a	O
time	O
ordered	O
sequence	O
of	O
vector	O
pairs	O
,	O
namely	O
a	O
feature	O
vector	O
and	O
a	O
mask	O
vector	O
at	O
each	O
reference	O
frame	O
interval	O
.	O

The	O
basic	O
distance	O
measure	O
,	O
which	O
compares	O
one	O
frame	O
of	O
speech	O
input	O
to	O
some	O
one	O
frame	O
of	O
a	O
word	O
template	O
has	O
been	O
described	O
above	O
.	O
However	O
,	O
the	O
word	O
identification	O
rests	O
not	O
merely	O
on	O
testing	O
the	O
identity	O
of	O
frame	O
to	O
frame	O
,	O
but	O
rather	O
on	O
finding	O
the	O
similarity	O
of	O
a	O
sequence	O
of	O
input	O
frames	O
to	O
the	O
sequence	O
of	O
reference	O
vectors	O
in	O
a	O
word	O
template	O
.	O
In	O
the	O
presently	O
preferred	O
embodiment	O
,	O
a	O
dynamic	O
programming	O
technique	O
is	O
used	O
to	O
find	O
an	O
optimal	O
subsequence	O
match	O
between	O
the	O
sequence	O
of	O
reference	O
vectors	O
in	O
the	O
word	O
template	O
and	O
a	O
subsequence	O
of	O
feature	O
vectors	O
in	O
the	O
speech	O
input	O
.	O
This	O
dynamic	O
programming	O
algorithm	O
permits	O
time-warping	O
by	O
various	O
speakers	O
to	O
be	O
accommodated	O
,	O
but	O
also	O
has	O
other	O
advantages	O
.	O
In	O
particular	O
,	O
the	O
end	O
points	O
can	O
be	O
unconstrained	O
.	O
That	O
is	O
,	O
no	O
separate	O
decision	O
step	O
needs	O
to	O
be	O
made	O
as	O
to	O
which	O
frame	O
in	O
an	O
input	O
sequence	O
of	O
frames	O
the	O
end	O
point	O
of	O
the	O
word	O
template	O
should	O
be	O
identified	O
to	O
.	O
Moreover	O
,	O
a	O
second	O
advantage	O
of	O
this	O
approach	O
is	O
that	O
the	O
storage	O
requirements	O
are	O
reduced	O
,	O
since	O
the	O
reference	O
frame	O
interval	O
is	O
twice	O
the	O
frame	O
interval	O
imposed	O
on	O
the	O
speech	O
input	O
signal	O
.	O
In	O
general	O
,	O
the	O
unconstrained	O
end-point	O
approach	O
is	O
accomplished	O
by	O
providing	O
a	O
cumulative	O
cost	O
profile	O
,	O
for	O
each	O
point	O
in	O
time	O
,	O
which	O
assumes	O
that	O
the	O
current	O
input	O
frame	O
is	O
the	O
last	O
frame	O
.	O
However	O
,	O
to	O
economize	O
on	O
processor	O
time	O
,	O
the	O
preferred	O
embodiment	O
uses	O
an	O
end-of-word	O
window	O
instead	O
,	O
as	O
will	O
be	O
discussed	O
below	O
.	O

Thus	O
,	O
the	O
foregoing	O
steps	O
produce	O
a	O
scaler	O
dissimilarity	O
measure	O
D.	O
sub	O
.	O
N	O
,	O
j	O
which	O
shows	O
the	O
dissimilarity	O
between	O
an	O
input	O
frame	O
j	O
and	O
a	O
reference	O
frame	O
N.	O
This	O
dissimilarity	O
measure	O
is	O
then	O
transformed	O
,	O
through	O
a	O
dynamic	O
programming	O
procedure	O
,	O
into	O
a	O
minimal	O
subsequence	O
distance	O
measure	O
(	O
scanning	O
error	O
)	O
E.	O
sub	O
.	O
N	O
,	O
j	O
,	O
which	O
is	O
preferably	O
defined	O
as	O
follows	O
:	O
E.	O
sub	O
.	O
Nj	O
=	O
D.	O
sub	O
.	O
Nj	O
+	O
min	O
[	O
E.sub.N-1,j-1	O
+	O
K	O
,	O
E.sub.N-1,j-2	O
,	O
E.sub.N-1,j-3	O
+	O
K/3	O
,	O
E.sub.N-1,j-4	O
+	O
K	O
]	O
The	O
quantity	O
"	O
K	O
"	O
is	O
a	O
constant	O
which	O
is	O
optionally	O
used	O
to	O
impose	O
a	O
warping	O
penalty	O
.	O
That	O
is	O
,	O
the	O
expected	O
ratio	O
of	O
reference	O
frames	O
to	O
sample	O
frames	O
is	O
one	O
reference	O
frame	O
to	O
every	O
two	O
sample	O
frames	O
.	O
However	O
,	O
if	O
this	O
is	O
not	O
in	O
fact	O
the	O
actual	O
spacing	O
,	O
then	O
a	O
penalty	O
amount	O
is	O
added	O
to	O
the	O
minimal	O
subsequence	O
distance	O
for	O
every	O
reference	O
in	O
which	O
the	O
local	O
ratio	O
of	O
input	O
frames	O
to	O
reference	O
frames	O
is	O
different	O
from	O
2	O
-	O
1	O
.	O
Note	O
that	O
the	O
penalty	O
added	O
where	O
the	O
ratio	O
is	O
locally	O
3	O
-	O
1	O
is	O
much	O
smaller	O
than	O
that	O
imposed	O
where	O
the	O
ratio	O
is	O
locally	O
4	O
-	O
1	O
or	O
1	O
-	O
1	O
.	O
Thus	O
,	O
only	O
a	O
modest	O
penalty	O
is	O
added	O
where	O
the	O
input	O
speech	O
is	O
slightly	O
slower	O
than	O
the	O
reference	O
speech	O
rate	O
(	O
down	O
to	O
11/2	O
times	O
as	O
slow	O
)	O
,	O
but	O
a	O
substantially	O
larger	O
penalty	O
is	O
added	O
if	O
the	O
input	O
speech	O
is	O
faster	O
than	O
the	O
reference	O
speech	O
,	O
or	O
is	O
more	O
than	O
11/2	O
times	O
as	O
slow	O
as	O
the	O
rate	O
affected	O
by	O
the	O
reference	O
speech	O
.	O

That	O
is	O
,	O
where	O
input	O
frames	O
are	O
matched	O
to	O
reference	O
frames	O
at	O
an	O
average	O
rate	O
which	O
is	O
between	O
2	O
-	O
1	O
and	O
3	O
-	O
1	O
,	O
and	O
where	O
the	O
time	O
distribution	O
of	O
the	O
input	O
frame	O
is	O
the	O
same	O
as	O
that	O
of	O
the	O
refrence	O
frame	O
,	O
then	O
the	O
particular	O
mappings	O
of	O
reference	O
frame	O
onto	O
input	O
frame	O
within	O
the	O
optimal	O
subsequence	O
will	O
vary	O
between	O
every	O
other	O
input	O
frame	O
and	O
every	O
third	O
input	O
frame	O
,	O
and	O
the	O
total	O
speed-mismatch	O
penalty	O
will	O
be	O
a	O
linear	O
function	O
of	O
the	O
speech	O
rate	O
mismatch	O
.	O
However	O
,	O
where	O
the	O
warping	O
of	O
the	O
input	O
sample	O
is	O
sufficiently	O
nonlinear	O
that	O
,	O
within	O
the	O
optimal	O
subsequence	O
,	O
some	O
adjacent	O
pairs	O
of	O
the	O
reference	O
template	O
sequence	O
match	O
either	O
adjacent	O
input	O
frames	O
or	O
to	O
input	O
frames	O
which	O
are	O
separated	O
by	O
three	O
other	O
input	O
frames	O
,	O
an	O
additional	O
penalty	O
will	O
be	O
added	O
to	O
the	O
smooth	O
penalty	O
for	O
linear	O
warping	O
.	O
This	O
additional	O
penalty	O
may	O
be	O
referred	O
to	O
as	O
a	O
nonlinear	O
warping	O
penalty	O
,	O
although	O
it	O
should	O
be	O
noted	O
that	O
nonlinear	O
warping	O
is	O
penalized	O
only	O
if	O
it	O
causes	O
some	O
local	O
portion	O
of	O
the	O
reference-to-input	O
mapping	O
to	O
be	O
denser	O
than	O
1	O
-	O
2	O
or	O
sparser	O
than	O
1	O
-	O
3	O
.	O
Thus	O
,	O
this	O
warping	O
penalty	O
incorporates	O
speech-rate	O
information	O
into	O
the	O
recognition	O
process	O
,	O
but	O
does	O
not	O
require	O
large	O
additional	O
amounts	O
of	O
computation	O
time	O
.	O

The	O
warping	O
penalty	O
is	O
optional	O
,	O
and	O
is	O
not	O
strictly	O
necessary	O
for	O
practicing	O
the	O
present	O
invention	O
.	O
That	O
is	O
,	O
the	O
iterative	O
statement	O
of	O
the	O
dynamic	O
programming	O
measure	O
can	O
be	O
restated	O
as	O
#	O
#	O
EQU1	O
#	O
#	O
The	O
presently	O
preferred	O
embodiment	O
does	O
not	O
use	O
warping	O
penalties	O
to	O
minimize	O
the	O
computational	O
load	O
.	O

Alternatively	O
,	O
a	O
larger	O
than	O
2-to-1	O
warping	O
factor	O
can	O
be	O
permitted	O
,	O
or	O
a	O
sparser	O
ratio	O
of	O
reference	O
templates	O
to	O
input	O
frames	O
could	O
be	O
used	O
,	O
as	O
desired	O
.	O
The	O
warping	O
penalties	O
can	O
accordingly	O
be	O
widely	O
varied	O
.	O

The	O
foregoing	O
dynamic	O
programming	O
procedure	O
can	O
provide	O
a	O
cumulative	O
fit	O
measure	O
for	O
each	O
word	O
in	O
the	O
vocabulary	O
,	O
at	O
each	O
input	O
frame	O
interval	O
.	O
In	O
this	O
case	O
,	O
the	O
recognizer	O
is	O
capable	O
of	O
operating	O
in	O
a	O
connected-speech	O
recognition	O
mode	O
rather	O
than	O
an	O
isolated-speech	O
recognition	O
mode	O
.	O

However	O
,	O
this	O
imposes	O
a	O
heavy	O
additional	O
processing	O
load	O
and	O
is	O
not	O
the	O
preferred	O
embodiment	O
of	O
the	O
invention	O
.	O

That	O
is	O
,	O
the	O
processing	O
load	O
required	O
to	O
find	O
a	O
cumulative	O
optimal	O
subsequence	O
match	O
at	O
each	O
input	O
frame	O
interval	O
is	O
too	O
much	O
for	O
the	O
economical	O
implementations	O
at	O
which	O
the	O
present	O
invention	O
is	O
especially	O
directed	O
.	O
To	O
reduce	O
this	O
processing	O
load	O
,	O
words	O
are	O
preferably	O
recognized	O
only	O
at	O
word	O
ending	O
points	O
identified	O
by	O
an	O
end-of-word	O
detector	O
.	O
The	O
operation	O
of	O
the	O
end-of-word	O
detector	O
will	O
now	O
be	O
described	O
with	O
reference	O
to	O
FIG	O
.	O
3	O
.	O
The	O
end-of-word	O
operation	O
as	O
depicted	O
in	O
FIG	O
.	O
3	O
provides	O
the	O
integer	O
feature	O
vector	O
32	O
for	O
each	O
frame	O
of	O
input	O
speech	O
as	O
an	O
input	O
to	O
a	O
plural	O
frame	O
buffer	O
memory	O
34	O
,	O
which	O
may	O
include	O
storage	O
for	O
20	O
frames	O
of	O
speech	O
data	O
for	O
example	O
.	O

In	O
the	O
presently	O
preferred	O
embodiment	O
,	O
the	O
zero	O
crossings	O
are	O
not	O
only	O
sorted	O
into	O
bins	O
,	O
but	O
a	O
count	O
is	O
kept	O
of	O
the	O
total	O
number	O
of	O
zero	O
crossings	O
.	O
For	O
example	O
,	O
this	O
can	O
be	O
done	O
by	O
adding	O
together	O
the	O
counts	O
in	O
the	O
various	O
bins	O
of	O
the	O
integer	O
feature	O
vector	O
,	O
depending	O
on	O
the	O
bin	O
threshold	O
values	O
.	O
Alternatively	O
,	O
this	O
can	O
be	O
done	O
by	O
simply	O
keeping	O
a	O
direct	O
running	O
count	O
of	O
the	O
number	O
of	O
zero	O
crossings	O
,	O
and	O
holding	O
this	O
as	O
a	O
directly	O
computed	O
parameter	O
during	O
each	O
frame	O
of	O
input	O
speech	O
.	O
A	O
further	O
alternative	O
is	O
simply	O
to	O
count	O
the	O
number	O
of	O
high-frequency	O
zero	O
crossings	O
for	O
each	O
frame	O
,	O
and	O
sum	O
those	O
across	O
frames	O
as	O
at	O
36	O
.	O

The	O
key	O
test	O
which	O
is	O
implemented	O
in	O
the	O
end-of-word	O
decision	O
of	O
this	O
aspect	O
of	O
the	O
present	O
invention	O
is	O
to	O
ascertain	O
whether	O
the	O
number	O
of	O
zero	O
crossings	O
exceeds	O
a	O
given	O
threshold	O
number	O
as	O
at	O
38	O
during	O
a	O
reasonably	O
long	O
period	O
of	O
time	O
(	O
e.g.	O
300	O
milliseconds	O
)	O
.	O
If	O
the	O
threshold	O
number	O
is	O
exceeded	O
as	O
at	O
40	O
,	O
this	O
large	O
number	O
of	O
zero	O
crossings	O
indicates	O
that	O
no	O
low-frequency	O
energy	O
,	O
and	O
therefore	O
presumably	O
no	O
speech	O
,	O
is	O
present	O
during	O
this	O
300	O
millisecond	O
window	O
.	O
It	O
should	O
be	O
noted	O
that	O
this	O
is	O
somewhat	O
sensitive	O
to	O
the	O
bias	O
level	O
used	O
in	O
the	O
Schmitt	O
trigger	O
(	O
or	O
other	O
center-clipping	O
mechanism	O
)	O
.	O
That	O
is	O
,	O
if	O
the	O
bias	O
level	O
in	O
the	O
Schmitt	O
trigger	O
is	O
set	O
too	O
high	O
,	O
then	O
noise	O
at	O
the	O
end	O
of	O
a	O
word	O
,	O
in	O
a	O
quiet	O
environment	O
,	O
will	O
not	O
be	O
able	O
to	O
produce	O
the	O
high	O
number	O
of	O
zero	O
crossings	O
required	O
for	O
the	O
detection	O
of	O
end	O
of	O
word	O
.	O
Correspondingly	O
,	O
if	O
the	O
bias	O
level	O
is	O
too	O
low	O
,	O
a	O
long	O
unvoiced	O
consonant	O
(	O
such	O
as	O
the	O
s	O
at	O
the	O
end	O
of	O
a	O
word	O
such	O
as	O
"	O
guess	O
"	O
)	O
may	O
generate	O
enough	O
high-frequency	O
zero	O
crossings	O
to	O
trigger	O
the	O
end	O
of	O
word	O
detector	O
erroneously	O
.	O

Thus	O
,	O
the	O
end-of-word	O
detector	O
selectively	O
indicates	O
that	O
an	O
end-of-word	O
has	O
occurred	O
.	O
If	O
so	O
,	O
then	O
word	O
recognition	O
is	O
performed	O
on	O
the	O
assumption	O
that	O
the	O
word	O
will	O
have	O
ended	O
during	O
a	O
second	O
window	O
period	O
,	O
which	O
is	O
not	O
necessarily	O
the	O
same	O
window	O
over	O
which	O
the	O
end-of-word	O
operates	O
.	O
That	O
is	O
,	O
in	O
the	O
presently	O
preferred	O
embodiment	O
,	O
an	O
end-of-word	O
is	O
detected	O
when	O
300	O
milliseconds	O
have	O
occurred	O
without	O
input	O
speech	O
energy	O
,	O
and	O
the	O
first	O
200	O
milliseconds	O
of	O
the	O
300	O
millisecond	O
end-of-word	O
detection	O
window	O
are	O
then	O
searched	O
for	O
a	O
hypothetical	O
word	O
ending	O
point	O
.	O
However	O
,	O
this	O
second	O
window	O
,	O
during	O
which	O
an	O
end-of-word	O
is	O
looked	O
for	O
,	O
can	O
be	O
the	O
same	O
as	O
or	O
different	O
from	O
the	O
end-of-word	O
detection	O
window	O
,	O
and	O
can	O
be	O
varied	O
within	O
very	O
broad	O
parameters	O
.	O
In	O
the	O
example	O
shown	O
in	O
FIG	O
.	O
3	O
the	O
end-of-word	O
detection	O
lies	O
within	O
the	O
first	O
13	O
frames	O
of	O
speech	O
data	O
included	O
in	O
the	O
20-frame	O
buffer	O
memory	O
34	O
.	O
The	O
essential	O
trade-off	O
here	O
is	O
that	O
,	O
if	O
the	O
recognition	O
window	O
is	O
made	O
smaller	O
,	O
the	O
processor	O
load	O
is	O
reduced	O
but	O
the	O
frequency	O
of	O
non-recognition	O
errors	O
is	O
likely	O
to	O
be	O
increased	O
.	O

The	O
invention	O
as	O
presently	O
practiced	O
is	O
embodied	O
in	O
a	O
VAX	O
11/780	O
,	O
with	O
analog	O
input	O
and	O
output	O
connections	O
(	O
i	O
.	O
e	O
.	O
,	O
microphone	O
,	O
preamplifier	O
,	O
analog-to-digital	O
converter	O
,	O
digital-to-analog	O
converter	O
,	O
audio	O
amplifier	O
and	O
loudspeaker	O
)	O
,	O
and	O
is	O
implemented	O
in	O
the	O
Fortran	O
code	O
in	O
the	O
attached	O
appendix	O
which	O
is	O
hereby	O
incorporated	O
by	O
reference	O
.	O
However	O
,	O
as	O
discussed	O
above	O
,	O
the	O
present	O
invention	O
can	O
be	O
implemented	O
in	O
a	O
cheap	O
micro-computer	O
system	O
,	O
and	O
the	O
contemplated	O
best	O
modes	O
of	O
the	O
invention	O
in	O
the	O
future	O
are	O
expected	O
to	O
be	O
microprocessor	O
or	O
microcomputer	O
embodiments	O
.	O

In	O
particular	O
,	O
an	O
embodiment	O
of	O
the	O
present	O
invention	O
in	O
an	O
8-bit	O
microprocessor	O
system	O
is	O
believed	O
to	O
be	O
straight-forward	O
.	O
No	O
expensive	O
data	O
converter	O
chip	O
or	O
means	O
for	O
energy	O
measurement	O
is	O
required	O
.	O
The	O
only	O
analog	O
stages	O
needed	O
,	O
in	O
the	O
preferred	O
embodiment	O
are	O
the	O
low-pass	O
filter	O
,	O
differentiator	O
,	O
and	O
Schmitt	O
trigger	O
.	O
If	O
the	O
present	O
invention	O
is	O
embodied	O
in	O
a	O
16-bit	O
system	O
,	O
the	O
additional	O
processing	O
power	O
and	O
word	O
length	O
will	O
mean	O
simply	O
that	O
a	O
slightly	O
larger	O
vocabulary	O
can	O
be	O
accommodated	O
,	O
and	O
will	O
also	O
make	O
development	O
of	O
the	O
vocabulary	O
templates	O
slightly	O
easier	O
.	O

As	O
will	O
be	O
obvious	O
to	O
those	O
skilled	O
in	O
the	O
art	O
,	O
the	O
present	O
invention	O
provides	O
numerous	O
broad	O
points	O
of	O
novelty	O
over	O
the	O
prior	O
art	O
of	O
speech	O
recognition	O
.	O
Therefore	O
,	O
the	O
scope	O
of	O
the	O
present	O
invention	O
can	O
be	O
embodied	O
in	O
numerous	O
modifications	O
and	O
variations	O
and	O
is	O
not	O
limited	O
as	O
specified	O
in	O
the	O
accompanying	O
claims	O
.	O

1	O
.	O
A	O
method	O
for	O
recognizing	O
speech	O
independent	O
of	O
the	O
speaker	O
thereof	O
,	O
said	O
method	O
comprising	O
:	O
receiving	O
an	O
analog	O
input	O
speech	O
signal	O
;	O
conditioning	O
said	O
analog	O
speech	O
signal	O
to	O
produce	O
a	O
sequence	O
of	O
rectangular	O
waveforms	O
of	O
polarity	O
signs	O
alternating	O
between	O
plus	O
and	O
minus	O
polarities	O
as	O
a	O
digital	O
waveform	O
signal	O
;	O
counting	O
the	O
number	O
of	O
polarity	O
transitions	O
in	O
the	O
digital	O
waveform	O
signal	O
to	O
obtain	O
a	O
zero-crossing	O
count	O
for	O
each	O
frame	O
of	O
the	O
digital	O
waveform	O
signal	O
;	O
measuring	O
the	O
time	O
duration	O
intervals	O
between	O
zero-crossings	O
of	O
the	O
digital	O
waveform	O
signal	O
;	O
providing	O
a	O
sequence	O
of	O
binary	O
feature	O
vectors	O
based	O
upon	O
the	O
measurements	O
of	O
the	O
time	O
duration	O
intervals	O
between	O
zero-crossings	O
of	O
the	O
digital	O
waveform	O
signal	O
and	O
corresponding	O
to	O
respective	O
frames	O
of	O
the	O
digital	O
waveform	O
signal	O
;	O
providing	O
a	O
vocabulary	O
consisting	O
of	O
a	O
relatively	O
small	O
number	O
of	O
words	O
,	O
wherein	O
each	O
of	O
the	O
words	O
included	O
in	O
the	O
vocabulary	O
is	O
represented	O
by	O
a	O
plurality	O
of	O
binary	O
reference	O
vectors	O
which	O
have	O
been	O
organized	O
in	O
sequences	O
with	O
each	O
of	O
said	O
binary	O
reference	O
vector	O
sequences	O
corresponding	O
to	O
a	O
word	O
acoustically	O
distinct	O
from	O
the	O
other	O
words	O
included	O
in	O
the	O
vocabulary	O
;	O
comparing	O
each	O
of	O
said	O
binary	O
feature	O
vectors	O
with	O
each	O
of	O
said	O
plurality	O
of	O
binary	O
reference	O
vectors	O
;	O
determining	O
a	O
distance	O
measure	O
with	O
respect	O
to	O
each	O
of	O
said	O
binary	O
reference	O
vectors	O
for	O
each	O
successive	O
binary	O
feature	O
vector	O
in	O
said	O
sequence	O
of	O
binary	O
feature	O
vectors	O
in	O
response	O
to	O
the	O
comparison	O
therebetween	O
;	O
and	O
recognizing	O
words	O
in	O
accordance	O
with	O
the	O
distance	O
measures	O
between	O
each	O
of	O
said	O
binary	O
reference	O
vector	O
sequences	O
and	O
successively	O
received	O
binary	O
feature	O
vectors	O
corresponding	O
to	O
respective	O
frames	O
of	O
the	O
digital	O
waveform	O
signal	O
.	O

2	O
.	O
A	O
method	O
for	O
recognizing	O
speech	O
as	O
set	O
forth	O
in	O
claim	O
1	O
,	O
wherein	O
the	O
provision	O
of	O
said	O
sequence	O
of	O
binary	O
feature	O
vectors	O
is	O
accomplished	O
by	O
sorting	O
the	O
zero-crossing	O
time	O
duration	O
interval	O
measurements	O
received	O
during	O
respective	O
frames	O
of	O
the	O
digital	O
waveform	O
signal	O
into	O
corresponding	O
ones	O
of	O
a	O
plurality	O
of	O
bins	O
respectively	O
representative	O
of	O
different	O
time	O
duration	O
intervals	O
between	O
zero-crossings	O
;	O
counting	O
the	O
number	O
of	O
zero-crossing	O
time	O
duration	O
intervals	O
for	O
each	O
of	O
the	O
plurality	O
of	O
bins	O
;	O
comparing	O
the	O
counts	O
of	O
respective	O
bins	O
to	O
upper	O
and	O
lower	O
reference	O
thresholds	O
corresponding	O
to	O
the	O
respective	O
bins	O
;	O
and	O
providing	O
said	O
sequence	O
of	O
binary	O
feature	O
vectors	O
in	O
response	O
to	O
the	O
comparison	O
between	O
the	O
counts	O
of	O
the	O
respective	O
bins	O
and	O
the	O
upper	O
and	O
lower	O
thresholds	O
corresponding	O
thereto	O
.	O

3	O
.	O
A	O
method	O
for	O
recognizing	O
speech	O
as	O
set	O
forth	O
in	O
claim	O
1	O
,	O
further	O
including	O
establishing	O
the	O
identity	O
of	O
an	O
end	O
of	O
word	O
prior	O
to	O
the	O
recognition	O
of	O
a	O
word	O
as	O
a	O
precondition	O
thereto	O
,	O
the	O
establishing	O
of	O
said	O
end	O
of	O
word	O
identification	O
including	O
:	O
monitoring	O
the	O
zero-crossing	O
count	O
for	O
the	O
digital	O
waveform	O
signal	O
,	O
and	O
declaring	O
an	O
end	O
of	O
word	O
condition	O
whenever	O
the	O
average	O
frequency	O
of	O
said	O
zero-crossings	O
exceeds	O
an	O
end	O
point	O
target	O
zero-crossing	O
frequency	O
for	O
a	O
time	O
duration	O
longer	O
than	O
a	O
predetermined	O
reference	O
time	O
duration	O
.	O

4	O
.	O
The	O
method	O
of	O
claim	O
1	O
,	O
wherein	O
said	O
distance	O
measure-determining	O
step	O
comprises	O
a	O
Hamming	O
distance	O
measurement	O
.	O

5	O
.	O
The	O
method	O
of	O
claim	O
3	O
,	O
wherein	O
said	O
distance	O
measure-determining	O
step	O
comprises	O
a	O
Hamming	O
distance	O
measurement	O
.	O

6	O
.	O
The	O
method	O
of	O
claim	O
1	O
,	O
wherein	O
said	O
recognizing	O
step	O
comprises	O
a	O
dynamic	O
programming	O
step	O
to	O
achieve	O
an	O
optimal	O
subsequence	O
match	O
between	O
one	O
of	O
said	O
sequences	O
of	O
said	O
binary	O
reference	O
vectors	O
and	O
spaced	O
successive	O
ones	O
of	O
said	O
binary	O
feature	O
vectors	O
.	O

7	O
.	O
The	O
method	O
of	O
claim	O
3	O
,	O
wherein	O
said	O
recognizing	O
step	O
comprises	O
a	O
dynamic	O
programming	O
step	O
to	O
achieve	O
an	O
optimal	O
subsequence	O
match	O
between	O
one	O
of	O
said	O
sequences	O
of	O
said	O
binary	O
reference	O
vectors	O
and	O
spaced	O
successive	O
ones	O
of	O
said	O
binary	O
feature	O
vectors	O
.	O

8	O
.	O
The	O
method	O
of	O
claim	O
4	O
,	O
wherein	O
said	O
recognizing	O
step	O
comprises	O
a	O
dynamic	O
programming	O
step	O
to	O
achieve	O
an	O
optimal	O
subsequence	O
match	O
between	O
one	O
of	O
said	O
sequences	O
of	O
said	O
binary	O
reference	O
vectors	O
and	O
spaced	O
successive	O
ones	O
of	O
said	O
binary	O
feature	O
vectors	O
.	O

9	O
.	O
The	O
method	O
of	O
claim	O
5	O
,	O
wherein	O
said	O
recognizing	O
step	O
comprises	O
a	O
dynamic	O
programming	O
step	O
to	O
achieve	O
an	O
optimal	O
subsequence	O
match	O
between	O
one	O
of	O
said	O
sequences	O
of	O
said	O
binary	O
reference	O
vectors	O
and	O
spaced	O
successive	O
ones	O
of	O
said	O
binary	O
feature	O
vectors	O
.	O

10	O
.	O
The	O
method	O
of	O
claim	O
1	O
,	O
wherein	O
said	O
conditioning	O
step	O
includes	O
center	O
clipping	O
said	O
analog	O
input	O
speech	O
signal	O
.	O

11	O
.	O
The	O
method	O
of	O
claim	O
3	O
,	O
wherein	O
said	O
conditioning	O
step	O
includes	O
center	O
clipping	O
said	O
analog	O
input	O
speech	O
signal	O
.	O

12	O
.	O
The	O
method	O
of	O
claim	O
10	O
,	O
wherein	O
said	O
center	O
clipping	O
step	O
is	O
performed	O
by	O
a	O
Schmitt	O
trigger	O
.	O

13	O
.	O
The	O
method	O
of	O
claim	O
11	O
,	O
wherein	O
said	O
center	O
clipping	O
step	O
is	O
performed	O
by	O
a	O
Schmitt	O
trigger	O
.	O

14	O
.	O
The	O
method	O
of	O
claim	O
1	O
,	O
wherein	O
said	O
conditioning	O
step	O
includes	O
the	O
performance	O
of	O
an	O
operation	O
corresponding	O
to	O
differentiation	O
of	O
said	O
analog	O
input	O
speech	O
signal	O
.	O

15	O
.	O
The	O
method	O
of	O
claim	O
3	O
,	O
wherein	O
said	O
conditioning	O
step	O
includes	O
the	O
performance	O
of	O
an	O
operation	O
corresponding	O
to	O
differentiation	O
of	O
said	O
analog	O
input	O
speech	O
signal	O
.	O

16	O
.	O
A	O
word	O
recognition	O
system	O
for	O
identifying	O
a	O
spoken	O
word	O
independent	O
of	O
the	O
speaker	O
thereof	O
,	O
wherein	O
the	O
spoken	O
word	O
is	O
represented	O
by	O
an	O
analog	O
speech	O
signal	O
,	O
said	O
word	O
recognition	O
system	O
comprising	O
:	O
signal	O
conditioning	O
means	O
for	O
receiving	O
an	O
analog	O
input	O
speech	O
signal	O
and	O
producing	O
a	O
digital	O
waveform	O
signal	O
as	O
a	O
sequence	O
of	O
rectangular	O
waveforms	O
of	O
polarity	O
signs	O
alternating	O
between	O
plus	O
and	O
minus	O
polarities	O
,	O
said	O
signal	O
conditioning	O
means	O
including	O
a	O
zero-crossing	O
detector	O
for	O
counting	O
the	O
number	O
of	O
polarity	O
transitions	O
in	O
the	O
digital	O
waveform	O
signal	O
to	O
obtain	O
a	O
zero-crossing	O
count	O
for	O
each	O
frame	O
of	O
the	O
digital	O
waveform	O
signal	O
;	O
memory	O
means	O
storing	O
a	O
plurality	O
of	O
binary	O
reference	O
templates	O
of	O
digital	O
speech	O
data	O
respectively	O
representative	O
of	O
individual	O
words	O
and	O
comprising	O
the	O
vocabulary	O
of	O
the	O
word	O
recognition	O
system	O
,	O
the	O
vocabulary	O
consisting	O
of	O
a	O
relatively	O
small	O
number	O
of	O
words	O
with	O
each	O
of	O
the	O
words	O
included	O
in	O
the	O
vocabulary	O
being	O
represented	O
by	O
a	O
binary	O
reference	O
template	O
defined	O
by	O
a	O
predetermined	O
plurality	O
of	O
binary	O
reference	O
vectors	O
arranged	O
in	O
a	O
predetermined	O
sequence	O
and	O
comprising	O
an	O
acoustic	O
description	O
of	O
an	O
individual	O
word	O
in	O
a	O
time-ordered	O
sequence	O
,	O
each	O
of	O
said	O
binary	O
reference	O
templates	O
corresponding	O
to	O
a	O
word	O
acoustically	O
distinct	O
from	O
the	O
other	O
words	O
included	O
in	O
the	O
vocabulary	O
;	O
means	O
operably	O
coupled	O
to	O
said	O
signal	O
conditioning	O
means	O
for	O
extracting	O
binary	O
feature	O
vectors	O
from	O
said	O
digital	O
waveform	O
signal	O
based	O
upon	O
the	O
time	O
duration	O
intervals	O
between	O
zero-crossings	O
of	O
the	O
digital	O
waveform	O
signal	O
;	O
means	O
operably	O
associated	O
with	O
said	O
binary	O
feature	O
vector	O
extracting	O
means	O
for	O
comparing	O
each	O
binary	O
feature	O
vector	O
of	O
said	O
digital	O
waveform	O
signal	O
with	O
the	O
corresponding	O
binary	O
reference	O
vectors	O
of	O
each	O
of	O
said	O
binary	O
reference	O
templates	O
to	O
provide	O
a	O
distance	O
measure	O
with	O
respect	O
to	O
each	O
of	O
the	O
binary	O
feature	O
vectors	O
and	O
the	O
predetermined	O
binary	O
reference	O
vector	O
sequences	O
defining	O
acoustic	O
descriptions	O
of	O
the	O
respective	O
words	O
included	O
in	O
the	O
vocabulary	O
of	O
the	O
word	O
recognition	O
system	O
;	O
and	O
word	O
recognizing	O
means	O
for	O
determining	O
which	O
one	O
of	O
the	O
plurality	O
of	O
the	O
binary	O
reference	O
templates	O
is	O
the	O
closest	O
match	O
to	O
said	O
digital	O
waveform	O
signal	O
representing	O
said	O
analog	O
input	O
speech	O
signal	O
based	O
upon	O
the	O
distance	O
measures	O
of	O
each	O
of	O
said	O
binary	O
reference	O
vector	O
sequences	O
and	O
successively	O
received	O
binary	O
feature	O
vectors	O
corresponding	O
to	O
respective	O
frames	O
of	O
the	O
digital	O
waveform	O
signal	O
.	O

17	O
.	O
A	O
word	O
recognition	O
system	O
as	O
set	O
forth	O
in	O
claim	O
16	O
,	O
further	O
including	O
dynamic	O
programming	O
means	O
operably	O
connected	O
to	O
the	O
output	O
of	O
said	O
comparing	O
means	O
for	O
receiving	O
the	O
distance	O
measures	O
between	O
each	O
of	O
said	O
binary	O
reference	O
vector	O
sequences	O
and	O
successively	O
received	O
binary	O
feature	O
vectors	O
to	O
provide	O
an	O
optimal	O
subsequence	O
match	O
therebetween	O
.	O

18	O
.	O
A	O
word	O
recognition	O
system	O
as	O
set	O
forth	O
in	O
claim	O
16	O
,	O
further	O
including	O
word-end	O
detector	O
means	O
operably	O
interposed	O
between	O
said	O
zero-crossing	O
detector	O
of	O
said	O
signal	O
conditioning	O
means	O
and	O
said	O
binary	O
feature	O
vector	O
extracting	O
means	O
for	O
monitoring	O
the	O
zero-crossing	O
count	O
for	O
the	O
digital	O
waveform	O
signal	O
and	O
producing	O
a	O
signal	O
output	O
declaring	O
an	O
end	O
of	O
word	O
condition	O
whenever	O
the	O
average	O
frequency	O
of	O
said	O
zero-crossings	O
exceeds	O
an	O
end	O
point	O
target	O
zero-crossing	O
frequency	O
for	O
a	O
time	O
duration	O
longer	O
than	O
a	O
predetermined	O
reference	O
time	O
duration	O
;	O
and	O
said	O
word	O
recognizing	O
means	O
including	O
decision	O
logic	O
means	O
having	O
inputs	O
for	O
receiving	O
the	O
distance	O
measures	O
of	O
each	O
of	O
said	O
binary	O
reference	O
vector	O
sequences	O
and	O
successively	O
received	O
binary	O
feature	O
vectors	O
and	O
the	O
output	O
from	O
said	O
word-end	O
detector	O
means	O
as	O
a	O
precondition	O
to	O
providing	O
a	O
word	O
recognition	O
output	O
.	O

