US	O
7027979	O
B2	O
20060411	O

US	O
10341726	O
20030114	O

10	O
eng	O
eng	O

US	O
10341726	O
20030114	O

20060411	O

20060411	O

381	O

G10L	O
19/00	O
20060101CFI20060411BHUS	O

20060101	O

C	O
G	O
10	O
L	O
19	O
00	O
F	O
I	O

20060411	O

US	O

B	O
H	O

G10L	O
19/14	O
20060101AFI20060411BHUS	O

20060101	O

A	O
G	O
10	O
L	O
19	O
14	O
F	O
I	O

20060411	O

US	O

B	O
H	O

G10L	O
15/00	O
20060101C	O
I20051008RMEP	O

20060101	O

C	O
G	O
10	O
L	O
15	O
00	O
I	O

20051008	O

EP	O

R	O
M	O

G10L	O
15/02	O
20060101A	O
N20051008RMEP	O

20060101	O

A	O
G	O
10	O
L	O
15	O
02	O
N	O

20051008	O

EP	O

R	O
M	O

G10L	O
15/28	O
20060101A	O
I20051008RMEP	O

20060101	O

A	O
G	O
10	O
L	O
15	O
28	O
I	O

20051008	O

EP	O

R	O
M	O

G10L	O
19/00	O
20060101A	O
N20051008RMEP	O

20060101	O

A	O
G	O
10	O
L	O
19	O
00	O
N	O

20051008	O

EP	O

R	O
M	O

US	O

704/205	O
704	O
205	O

704/234	O
704	O
234	O

704/243	O
704	O
243	O

704/256	O
704	O
256	O

704/E15.047	O
704	O
E15	O
.	O
047	O

706/14	O
706	O
14	O

G10L	O
21/02A4E	O
G	O
10	O
L	O
21	O
02	O

A	O
4	O
E	O

G10L	O
15/28D	O
G	O
10	O
L	O
15	O
28	O

D	O

S10L	O
15	O
:	O
02	O
S	O
10	O
L	O
15	O
02	O

S10L101	O
:	O
04	O
S	O
10	O
L	O
101	O
04	O

US	O

704/256	O
704	O
256	O

US	O

704/252	O
704	O
252	O

US	O

704/243	O
704	O
243	O

US	O

704/236	O
704	O
236	O

US	O

704/240	O
704	O
240	O

US	O

704/234	O
704	O
234	O

US	O

704/233	O
704	O
233	O

US	O

704/211	O
704	O
211	O

US	O

704/207	O
704	O
207	O

US	O

704/205	O
704	O
205	O

US	O

704/203	O
704	O
203	O

US	O

706/14	O
706	O
14	O

20	O
Method	O
and	O
apparatus	O
for	O
speech	O
reconstruction	O
within	O
a	O
distributed	O
speech	O
recognition	O
system	O

US	O
5745874	O
A	O
Neely	O
19980428	O

19960304	O

US	O
6076058	O
A	O
Chengalvarayan	O
20000613	O

19980302	O

US	O
6157909	O
A	O
Mauuary	O
et_al.	O

20001205	O

19980720	O

US	O
6633839	O
B2	O
Kushner	O
et_al.	O

20031014	O

20010202	O

US	O
6691090	O
B1	O
Laurila	O
et_al.	O

20040210	O

20001024	O

US	O
6721698	O
B1	O
Hariharan	O
et_al.	O

20040413	O

20001027	O

US	O
20020147579	O
A1	O
Kushner	O
et_al.	O

20021010	O

20010202	O

WO	O
0133550	O
A1	O
20010510	O

20001019	O

WO	O
WO2062120	O
A2	O
20020800	O

Chazan	B-Citation
et_al.	I-Citation
,	I-Citation
(	I-Citation
“	I-Citation
Speech	I-Citation
reconstruction	I-Citation
from	I-Citation
mel	I-Citation
frequency	I-Citation
cepstral	I-Citation
coefficients	I-Citation
and	I-Citation
pitch	I-Citation
frequency	I-Citation
”	I-Citation
,	I-Citation
Proceedings	I-Citation
'00	I-Citation
,	I-Citation
2000	I-Citation
IEEE	I-Citation
International	I-Citation
Conference	I-Citation
on	I-Citation
Acoustics	I-Citation
,	I-Citation
Speech	I-Citation
,	I-Citation
and	I-Citation
Signal	I-Citation
Processing	I-Citation
,	I-Citation
2000	I-Citation
,	I-Citation
vol.	I-Citation
3	I-Citation
,	I-Citation
pp.	I-Citation
1299	I-Citation
-	I-Citation
1302	I-Citation
)	I-Citation
.	O

Kang	B-Citation
et_al.	I-Citation
,	I-Citation
(	I-Citation
“	I-Citation
A	I-Citation
phase	I-Citation
generation	I-Citation
method	I-Citation
for	I-Citation
speech	I-Citation
reconstruction	I-Citation
from	I-Citation
spectral	I-Citation
envelope	I-Citation
and	I-Citation
pitch	I-Citation
intervals	I-Citation
”	I-Citation
,	I-Citation
Proceedings	I-Citation
'0	I-Citation
IEEE	I-Citation
International	I-Citation
Conference	I-Citation
on	I-Citation
Acoustics	I-Citation
,	I-Citation
Speech	I-Citation
,	I-Citation
and	I-Citation
Signal	I-Citation
Processing	I-Citation
,	I-Citation
2002	I-Citation
,	I-Citation
vol.	I-Citation
1	I-Citation
,	I-Citation
pp.	I-Citation
429	I-Citation
-	I-Citation
432	I-Citation
)	I-Citation
.	O

US	O
7860708	O
B2	O
20101228	O

20070411	O

US	O
20040138888	O
A1	O
20040715	O

Motorola	O
,	O
Inc.	O

02	O

Schaumburg	O
IL	O
US	O

Ramabadran	O
Tenkasi	O

Naperville	O
IL	O
US	O

US	O

Haas	O
Kenneth	O
A.	O

Chen	O
Sylvia	O

Chawan	O
Vijay	O
2654	O

CN	O
100371988	O
C	O
20080227	O

20040113	O

EP	O
1588354	O
A4	O
20060301	O

20040113	O

EP	O
1588354	O
A2	O
20051026	O

20040113	O

US	O
7027979	O
B2	O
20060411	O

20030114	O

US	O
20040138888	O
A1	O
20040715	O

20030114	O

EP	O
1588354	O
B1	O
20110824	O

20040113	O

WO	O
2004066269	O
A3	O
20040805	O

20040113	O

WO	O
2004066269	O
A2	O
20040805	O

20040113	O

CN	O
1739143	O
A	O
20060222	O

20040113	O

RU	O
2005125737	O
A	O
20060110	O

20040113	O

BR	O
PI0406765	O
A	O
20051220	O

20040113	O

KR	O
1020050092112	O
A	O
20050920	O

20050714	O

RU	O
2366007	O
C2	O
20090827	O

20040113	O

US	O
20040138888	O
A1	O
20040715	O

20030114	O

CN	O
1739143	O
A	O
20060222	O

20040113	O

RU	O
2005125737	O
A	O
20060110	O

20040113	O

CN	O
100371988	O
C	O
20080227	O

20040113	O

KR	O
1020050092112	O
A	O
20050920	O

20050714	O

EP	O
1588354	O
B1	O
20110824	O

20040113	O

EP	O
1588354	O
A2	O
20051026	O

20040113	O

EP	O
1588354	O
A4	O
20060301	O

20040113	O

WO	O
2004066269	O
A3	O
20040805	O

20040113	O

WO	O
2004066269	O
A2	O
20040805	O

20040113	O

US	O
7027979	O
B2	O
20060411	O

20030114	O

BR	O
PI0406765	O
A	O
20051220	O

20040113	O

RU	O
2366007	O
C2	O
20090827	O

20040113	O

A	O
method	O
and	O
apparatus	O
for	O
speech	O
reconstruction	O
within	O
a	O
distributed	O
speech	O
recognition	O
system	O
is	O
provided	O
herein	O
.	O
Missing	O
MFCCs	O
are	O
reconstructed	O
and	O
utilized	O
to	O
generate	O
speech	O
.	O
Particularly	O
,	O
partial	O
recovery	O
of	O
the	O
missing	O
MFCCs	O
is	O
achieved	O
by	O
exploiting	O
the	O
dependence	O
of	O
the	O
missing	O
MFCCs	O
on	O
the	O
transmitted	O
pitch	O
period	O
P	O
as	O
well	O
as	O
on	O
the	O
transmitted	O
MFCCs	O
.	O
Harmonic	O
magnitudes	O
are	O
then	O
obtained	O
from	O
the	O
transmitted	O
and	O
reconstructed	O
MFCCs	O
,	O
and	O
the	O
speech	O
is	O
reconstructed	O
utilizing	O
these	O
harmonic	O
magnitudes	O
.	O

20030114	O

AS	O
ASSIGNMENT	O
N	O
US	O
7027979B2	O
MOTOROLA	O
,	O
INC.	O
,	O
ILLINOIS	O
ASSIGNMENT	O
OF	O
ASSIGNORS	O
INTEREST;ASSIGNOR:RAMABADRAN	O
,	O
TENKASI;REEL/FRAME:013666/0275	O

20030114	O

20090922	O

FPAY	O
+	O
FEE	O
PAYMENT	O
N	O
US	O
7027979B2	O
4	O

20101213	O

AS	O
ASSIGNMENT	O
N	O
US	O
7027979B2	O
MOTOROLA	O
MOBILITY	O
,	O
INC	O
,	O
ILLINOIS	O
ASSIGNMENT	O
OF	O
ASSIGNORS	O
INTEREST;ASSIGNOR:MOTOROLA	O
,	O
INC;REEL/FRAME:025673/0558	O

20100731	O

FIELD	O
OF	O
THE	O
INVENTION	O
The	O
present	O
invention	O
relates	O
generally	O
to	O
speech	O
reconstruction	O
and	O
in	O
particular	O
,	O
to	O
a	O
method	O
and	O
apparatus	O
for	O
speech	O
reconstruction	O
within	O
a	O
distributed	O
speech	O
recognition	O
system	O
.	O

BACKGROUND	O
OF	O
THE	O
INVENTION	O
Automatic	O
speech	O
recognition	O
(	O
ASR	O
)	O
is	O
the	O
method	O
of	O
automatically	O
recognizing	O
the	O
nature	O
of	O
oral	O
instructions	O
based	O
on	O
the	O
information	O
included	O
in	O
speech	O
waves	O
.	O
ASR	O
has	O
ushered	O
in	O
a	O
new	O
generation	O
of	O
security	O
devices	O
based	O
on	O
oral	O
,	O
rather	O
than	O
physical	O
,	O
keys	O
and	O
has	O
made	O
possible	O
a	O
whole	O
range	O
of	O
“	O
no-hands	O
”	O
or	O
“	O
hands-free	O
”	O
features	O
,	O
such	O
as	O
voice	O
dialing	O
and	O
information	O
retrieval	O
by	O
voice	O
.	O

At	O
the	O
highest	O
level	O
,	O
all	O
ASR	O
systems	O
process	O
speech	O
for	O
feature	O
extraction	O
(	O
also	O
known	O
as	O
signal-processing	O
front	O
end	O
)	O
and	O
feature	O
matching	O
(	O
also	O
known	O
as	O
signal-processing	O
back	O
end	O
)	O
.	O
Feature	O
extraction	O
is	O
the	O
method	O
by	O
which	O
a	O
small	O
amount	O
of	O
data	O
is	O
extracted	O
from	O
a	O
speech	O
input	O
to	O
represent	O
the	O
speech	O
input	O
.	O
Feature	O
matching	O
is	O
the	O
method	O
by	O
which	O
the	O
nature	O
of	O
instructions	O
contained	O
in	O
the	O
speech	O
input	O
are	O
identified	O
by	O
comparing	O
the	O
extracted	O
data	O
with	O
a	O
known	O
data	O
set	O
.	O
In	O
a	O
standard	O
ASR	O
system	O
,	O
a	O
single	O
processing	O
unit	O
carries	O
out	O
both	O
of	O
these	O
functions	O
.	O

The	O
performance	O
of	O
an	O
ASR	O
system	O
that	O
uses	O
speech	O
transmitted	O
,	O
for	O
example	O
,	O
over	O
a	O
mobile	O
or	O
wireless	O
channel	O
as	O
an	O
input	O
,	O
however	O
,	O
may	O
be	O
significantly	O
degraded	O
as	O
compared	O
with	O
the	O
performance	O
of	O
an	O
ASR	O
system	O
that	O
uses	O
the	O
original	O
unmodified	O
speech	O
as	O
the	O
input	O
.	O
This	O
degradation	O
in	O
system	O
performance	O
may	O
be	O
caused	O
by	O
distortions	O
introduced	O
in	O
the	O
transmitted	O
speech	O
by	O
the	O
coding	O
algorithm	O
as	O
well	O
as	O
channel	O
transmission	O
errors	O
.	O

A	O
distributed	O
speech	O
recognition	O
(	O
DSR	O
)	O
system	O
attempts	O
to	O
correct	O
the	O
system	O
performance	O
degradation	O
caused	O
by	O
transmitted	O
speech	O
by	O
separating	O
feature	O
extraction	O
from	O
feature	O
matching	O
and	O
having	O
the	O
two	O
methods	O
executed	O
by	O
two	O
different	O
processing	O
units	O
disposed	O
at	O
two	O
different	O
locations	O
.	O
For	O
example	O
,	O
in	O
a	O
DSR	O
mobile	O
or	O
wireless	O
communications	O
system	O
or	O
network	O
including	O
a	O
first	O
communication	O
device	O
(	O
e.g.	O
,	O
a	O
mobile	O
unit	O
)	O
and	O
a	O
second	O
communication	O
device	O
(	O
e.g.	O
,	O
a	O
server	O
)	O
,	O
the	O
mobile	O
unit	O
performs	O
only	O
feature	O
extraction	O
,	O
i	O
.	O
e	O
.	O
,	O
the	O
mobile	O
unit	O
extracts	O
and	O
encodes	O
recognition	O
features	O
from	O
the	O
speech	O
input	O
.	O
The	O
mobile	O
unit	O
then	O
transmits	O
the	O
encoded	O
features	O
over	O
an	O
error-protected	O
data	O
channel	O
to	O
the	O
server	O
.	O
The	O
server	O
receives	O
the	O
encoded	O
recognition	O
features	O
,	O
and	O
performs	O
only	O
feature	O
matching	O
,	O
i	O
.	O
e	O
.	O
,	O
the	O
server	O
matches	O
the	O
encoded	O
features	O
to	O
those	O
in	O
a	O
known	O
data	O
set	O
.	O

With	O
this	O
approach	O
,	O
coding	O
distortions	O
are	O
minimized	O
,	O
and	O
transmission	O
channel	O
errors	O
have	O
very	O
little	O
effect	O
on	O
the	O
recognition	O
system	O
performance	O
.	O
Moreover	O
,	O
the	O
mobile	O
unit	O
has	O
to	O
perform	O
only	O
the	O
relatively	O
computationally	O
inexpensive	O
feature	O
extraction	O
,	O
leaving	O
the	O
more	O
complex	O
,	O
expensive	O
feature	O
matching	O
to	O
the	O
server	O
.	O
By	O
reserving	O
the	O
more	O
computationally	O
complex	O
activities	O
to	O
the	O
server	O
processor	O
,	O
greater	O
design	O
flexibility	O
is	O
preserved	O
for	O
the	O
mobile	O
unit	O
processor	O
,	O
where	O
processor	O
size	O
and	O
speed	O
typically	O
are	O
at	O
a	O
premium	O
given	O
the	O
recent	O
emphasis	O
on	O
unit	O
miniaturization	O
.	O

The	O
European	O
Telecommunications	O
Standards	O
Institute	O
(	O
ETSI	O
)	O
recently	O
published	O
a	O
standard	O
for	O
DSR	O
feature	O
extraction	O
and	O
compression	O
algorithms	O
.	O
European	O
Telecommunications	O
Standards	O
Institute	O
Standard	O
ES	O
201	O
108	O
,	O
Speech	O
Processing	O
,	O
Transmission	O
and	O
Quality	O
aspects	O
(	O
STQ	O
)	O
;	O
Distributed	O
speech	O
recognition	O
;	O
Front-end	O
feature	O
extraction	O
algorithm	O
;	O
Compression	O
algorithms	O
,	O
Ver	O
.	O
1	O
.	O
1	O
.	O
2	O
,	O
April	O
2000	O
(	O
hereinafter	O
“	O
ETSI	O
Front-End	O
Standard	O
”	O
)	O
,	O
hereby	O
incorporated	O
by	O
reference	O
in	O
its	O
entirety	O
.	O
While	O
several	O
methods	O
,	O
such	O
as	O
Linear	O
Prediction	O
(	O
LP	O
)	O
,	O
exist	O
for	O
encoding	O
data	O
from	O
a	O
speech	O
input	O
,	O
the	O
ETSI	O
Front-End	O
Standard	O
includes	O
a	O
feature	O
extraction	O
algorithm	O
that	O
extracts	O
and	O
encodes	O
the	O
speech	O
input	O
as	O
a	O
log-energy	O
value	O
and	O
a	O
series	O
of	O
Mel-frequency	O
cepstral	O
coefficients	O
(	O
MFCC	O
)	O
for	O
each	O
frame	O
.	O
These	O
parameters	O
essentially	O
capture	O
the	O
spectral	O
envelope	O
information	O
of	O
the	O
speech	O
input	O
,	O
and	O
are	O
commonly	O
used	O
in	O
most	O
large	O
vocabulary	O
speech	O
recognizers	O
.	O
The	O
ETSI	O
Front-End	O
Standard	O
further	O
includes	O
algorithms	O
for	O
compression	O
(	O
by	O
vector	O
quantization	O
)	O
and	O
error-protection	O
(	O
cyclic	O
redundancy	O
check	O
codes	O
)	O
.	O
The	O
ETSI	O
Front-End	O
Standard	O
also	O
describes	O
suitable	O
algorithms	O
for	O
bit	O
stream	O
decoding	O
and	O
channel	O
error	O
mitigation	O
.	O
At	O
an	O
update	O
interval	O
of	O
10	O
ms	O
and	O
with	O
the	O
addition	O
of	O
synchronization	O
and	O
header	O
information	O
,	O
the	O
data	O
transmission	O
rate	O
works	O
out	O
to	O
4800	O
bits	O
per	O
second	O
.	O

More	O
recently	O
,	O
the	O
European	O
Telecommunications	O
Standards	O
Institute	O
(	O
ETSI	O
)	O
has	O
published	O
another	O
standard	O
for	O
DSR	O
feature	O
extraction	O
and	O
compression	O
algorithms	O
.	O
European	O
Telecommunications	O
Standards	O
Institute	O
Standard	O
ES	O
202	O
050	O
,	O
Speech	O
Processing	O
,	O
Transmission	O
and	O
Quality	O
aspects	O
(	O
STQ	O
)	O
;	O
Distributed	O
speech	O
recognition	O
;	O
Advanced	O
Front-end	O
feature	O
extraction	O
algorithm	O
;	O
Compression	O
algorithms	O
,	O
Ver	O
.	O
1	O
.	O
1	O
.	O
1	O
,	O
July	O
2002	O
(	O
hereinafter	O
“	O
ETSI	O
Advanced	O
Front-End	O
Standard	O
”	O
)	O
,	O
hereby	O
incorporated	O
by	O
reference	O
in	O
its	O
entirety	O
.	O
The	O
ETSI	O
Advanced	O
Front-End	O
Standard	O
is	O
quite	O
similar	O
to	O
the	O
ETSI	O
Front-End	O
Standard	O
in	O
terms	O
of	O
the	O
features	O
extracted	O
,	O
bit	O
rate	O
,	O
and	O
so	O
on	O
but	O
is	O
more	O
noise-robust	O
.	O
That	O
is	O
,	O
the	O
ETSI	O
Advanced	O
Front-End	O
Standard	O
provides	O
better	O
performance	O
under	O
noisy	O
background	O
conditions	O
.	O

In	O
summary	O
,	O
a	O
DSR	O
system	O
,	O
such	O
as	O
one	O
designed	O
in	O
accordance	O
with	O
the	O
ETSI	O
Front-End	O
Standard	O
(	O
or	O
the	O
ETSI	O
Advanced	O
Front-End	O
Standard	O
)	O
,	O
offers	O
many	O
advantages	O
for	O
mobile	O
communications	O
network	O
implementation	O
.	O
Such	O
a	O
system	O
may	O
provide	O
equivalent	O
recognition	O
performance	O
to	O
an	O
ASR	O
system	O
,	O
but	O
with	O
a	O
low	O
complexity	O
front-end	O
that	O
may	O
be	O
incorporated	O
in	O
a	O
mobile	O
unit	O
and	O
a	O
low	O
bandwidth	O
requirement	O
for	O
the	O
transmission	O
of	O
the	O
coded	O
recognition	O
features	O
.	O

DSR	O
systems	O
have	O
the	O
drawback	O
that	O
the	O
original	O
speech	O
input	O
is	O
not	O
available	O
at	O
the	O
back	O
end	O
for	O
storage	O
and/or	O
verification	O
purposes	O
.	O
It	O
would	O
be	O
helpful	O
to	O
have	O
the	O
original	O
speech	O
input	O
available	O
for	O
:	O
(	O
i	O
)	O
back	O
end	O
applications	O
that	O
require	O
human	O
assistance	O
,	O
e.g.	O
,	O
to	O
permit	O
hand	O
correction	O
of	O
documents	O
generated	O
using	O
remote	O
dictation	O
systems	O
by	O
allowing	O
comparison	O
of	O
the	O
document	O
to	O
the	O
original	O
speech	O
input	O
or	O
to	O
permit	O
smooth	O
transition	O
when	O
a	O
recognition	O
task	O
is	O
handed	O
over	O
from	O
a	O
DSR	O
system	O
to	O
a	O
human	O
operator	O
;	O
(	O
ii	O
)	O
prophylactic	O
storage	O
of	O
legally	O
sensitive	O
information	O
,	O
e.g.	O
,	O
to	O
record	O
the	O
exact	O
statements	O
made	O
during	O
financial	O
transactions	O
such	O
as	O
the	O
placement	O
of	O
a	O
securities	O
order	O
;	O
and	O
(	O
iii	O
)	O
validation	O
of	O
utterances	O
during	O
database	O
collection	O
,	O
e.g.	O
,	O
for	O
training	O
the	O
recognizer	O
in	O
batch	O
mode	O
(	O
and	O
especially	O
incremental	O
mode	O
)	O
and	O
system	O
tune-up	O
.	O

On	O
the	O
other	O
hand	O
,	O
original	O
speech	O
is	O
available	O
at	O
the	O
back	O
end	O
if	O
a	O
standard	O
ASR	O
system	O
is	O
used	O
.	O
However	O
,	O
as	O
noted	O
above	O
,	O
ASR	O
has	O
significant	O
distortion	O
difficulties	O
when	O
used	O
in	O
a	O
mobile	O
or	O
wireless	O
application	O
.	O
In	O
order	O
to	O
address	O
this	O
issue	O
,	O
U.S.	O
patent	O
application	O
Publication	O
No.	O
2002/0147579	O
(	O
which	O
is	O
incorporated	O
by	O
reference	O
herein	O
)	O
provides	O
for	O
a	O
method	O
for	O
speech	O
reconstruction	O
at	O
the	O
back	O
end	O
using	O
a	O
sinusoidal	O
vocoder	O
.	O
In	O
accordance	O
with	O
the	O
'579	O
application	O
,	O
13	O
transmitted	O
MFCCs	O
(	O
C0	O
–	O
C12	O
)	O
are	O
transformed	O
into	O
harmonic	O
magnitudes	O
that	O
are	O
utilized	O
in	O
speech	O
reconstruction	O
.	O

The	O
above	O
technique	O
for	O
transforming	O
MFCCs	O
into	O
harmonic	O
magnitudes	O
works	O
fairly	O
well	O
.	O
The	O
speech	O
reconstructed	O
by	O
a	O
sinusoidal	O
coder	O
using	O
these	O
transformed	O
magnitudes	O
is	O
highly	O
intelligible	O
and	O
of	O
reasonable	O
quality	O
.	O
However	O
,	O
it	O
is	O
apparent	O
that	O
the	O
reconstruction	O
performance	O
(	O
in	O
terms	O
of	O
speech	O
intelligibility	O
and	O
quality	O
)	O
would	O
be	O
better	O
if	O
all	O
the	O
23	O
MFCC	O
values	O
(	O
C0	O
–	O
C22	O
)	O
were	O
available	O
instead	O
of	O
only	O
the	O
13	O
transmitted	O
values	O
,	O
viz	O
.	O
,	O
C0	O
–	O
C12	O
.	O
Therefore	O
,	O
a	O
need	O
exists	O
for	O
a	O
method	O
and	O
apparatus	O
for	O
speech	O
reconstruction	O
within	O
a	O
distributed	O
speech	O
recognition	O
system	O
that	O
makes	O
use	O
of	O
missing	O
MFCC	O
values	O
to	O
improve	O
speech	O
reconstruction	O
.	O

BRIEF	O
DESCRIPTION	O
OF	O
THE	O
DRAWINGS	O

FIG	O
.	O
1	O
is	O
a	O
block	O
diagram	O
of	O
a	O
distributed	O
speech	O
recognition	O
system	O
in	O
accordance	O
with	O
the	O
preferred	O
embodiment	O
of	O
the	O
present	O
invention	O
.	O

FIG	O
.	O
2	O
is	O
a	O
more-detailed	O
block	O
diagram	O
of	O
the	O
distributed	O
speech	O
recognition	O
system	O
of	O
FIG	O
.	O
1	O
in	O
accordance	O
with	O
the	O
preferred	O
embodiment	O
of	O
the	O
present	O
invention	O
.	O

FIG	O
.	O
3	O
is	O
a	O
flow	O
chart	O
showing	O
operation	O
of	O
an	O
MFCC	O
reconstructor	O
in	O
accordance	O
with	O
the	O
preferred	O
embodiment	O
of	O
the	O
present	O
invention	O
.	O

FIG	O
.	O
4	O
is	O
a	O
flow	O
chart	O
showing	O
operation	O
of	O
a	O
DSR/Speech	O
processor	O
in	O
accordance	O
with	O
the	O
preferred	O
embodiment	O
of	O
the	O
present	O
invention	O
.	O

DETAILED	O
DESCRIPTION	O
OF	O
THE	O
DRAWINGS	O
To	O
address	O
the	O
above-mentioned	O
need	O
,	O
a	O
method	O
and	O
apparatus	O
for	O
speech	O
reconstruction	O
within	O
a	O
distributed	O
speech	O
recognition	O
system	O
is	O
provided	O
herein	O
.	O
In	O
accordance	O
with	O
the	O
preferred	O
embodiment	O
of	O
the	O
present	O
invention	O
,	O
the	O
missing	O
MFCCs	O
are	O
reconstructed	O
—	O
particularly	O
,	O
partial	O
recovery	O
of	O
the	O
missing	O
MFCCs	O
is	O
achieved	O
by	O
exploiting	O
the	O
dependence	O
of	O
the	O
missing	O
MFCCs	O
on	O
the	O
transmitted	O
pitch	O
period	O
P	O
as	O
well	O
as	O
on	O
the	O
transmitted	O
MFCCs	O
.	O
Harmonic	O
magnitudes	O
are	O
then	O
obtained	O
from	O
the	O
transmitted	O
and	O
reconstructed	O
MFCCs	O
,	O
and	O
the	O
speech	O
is	O
reconstructed	O
utilizing	O
these	O
transformed	O
magnitudes	O
.	O

Because	O
harmonic	O
magnitudes	O
are	O
obtained	O
utilizing	O
all	O
MFCCs	O
(	O
transmitted	O
and	O
reconstructed	O
)	O
,	O
an	O
improvement	O
in	O
the	O
accuracy	O
of	O
the	O
transformed	O
harmonic	O
magnitudes	O
results	O
.	O
Any	O
improvement	O
in	O
the	O
accuracy	O
of	O
the	O
transformed	O
harmonic	O
magnitudes	O
results	O
in	O
corresponding	O
improvement	O
in	O
the	O
intelligibility/quality	O
of	O
the	O
reconstructed	O
speech	O
.	O

The	O
present	O
invention	O
encompasses	O
a	O
method	O
for	O
speech	O
reconstruction	O
.	O
The	O
method	O
comprises	O
the	O
steps	O
of	O
receiving	O
a	O
first	O
plurality	O
of	O
Mel-frequency	O
cepstral	O
coefficients	O
(	O
MFCCs	O
)	O
,	O
calculating	O
a	O
second	O
plurality	O
of	O
MFCCs	O
,	O
and	O
utilizing	O
the	O
received	O
and	O
the	O
calculated	O
MFCCs	O
for	O
reconstructing	O
speech	O
.	O

The	O
present	O
invention	O
additionally	O
encompasses	O
a	O
method	O
for	O
speech	O
reconstruction	O
.	O
The	O
method	O
comprising	O
the	O
steps	O
of	O
receiving	O
Mel-frequency	O
cepstral	O
coefficients	O
C0	O
–	O
C12	O
,	O
calculating	O
Mel-frequency	O
cepstral	O
coefficients	O
C13	O
–	O
C22	O
,	O
and	O
utilizing	O
coefficients	O
C0	O
–	O
C22	O
for	O
reconstructing	O
speech	O
.	O

Finally	O
,	O
the	O
present	O
invention	O
encompasses	O
an	O
apparatus	O
comprising	O
a	O
receiver	O
receiving	O
a	O
first	O
plurality	O
of	O
Mel-frequency	O
cepstral	O
coefficients	O
(	O
MFCCs	O
)	O
,	O
a	O
MFCC	O
reconstructor	O
calculating	O
a	O
second	O
plurality	O
of	O
MFCCs	O
,	O
and	O
a	O
speech	O
processor	O
utilizing	O
the	O
received	O
and	O
the	O
calculated	O
MFCCs	O
for	O
reconstructing	O
speech	O
.	O

Turning	O
now	O
to	O
the	O
drawings	O
,	O
wherein	O
like	O
numerals	O
designate	O
like	O
components	O
,	O
FIG	O
.	O
1	O
is	O
a	O
block	O
diagram	O
of	O
communication	O
system	O
100	O
in	O
accordance	O
with	O
the	O
preferred	O
embodiment	O
of	O
the	O
present	O
invention	O
.	O
Communication	O
system	O
100	O
preferably	O
comprises	O
a	O
standard	O
cellular	O
communication	O
system	O
such	O
as	O
a	O
code-division	O
,	O
multiple-access	O
(	O
CDMA	O
)	O
communication	O
system	O
.	O
Although	O
the	O
system	O
100	O
preferably	O
is	O
a	O
mobile	O
or	O
wireless	O
radio	O
frequency	O
communication	O
system	O
,	O
the	O
system	O
100	O
could	O
be	O
any	O
type	O
of	O
communication	O
system	O
,	O
for	O
example	O
a	O
wired	O
or	O
wireless	O
system	O
or	O
a	O
system	O
using	O
a	O
method	O
of	O
communication	O
other	O
than	O
radio	O
frequency	O
communication	O
.	O

Communication	O
system	O
100	O
includes	O
mobile	O
communications	O
device	O
101	O
(	O
such	O
as	O
a	O
mobile	O
station	O
)	O
and	O
fixed	O
communications	O
device	O
103	O
(	O
such	O
as	O
a	O
base	O
station	O
)	O
,	O
mobile	O
device	O
101	O
communicating	O
with	O
the	O
fixed	O
device	O
103	O
through	O
the	O
use	O
of	O
radio	O
frequency	O
transmissions	O
.	O
Base	O
station	O
103	O
,	O
in	O
turn	O
,	O
communicates	O
with	O
server	O
107	O
over	O
a	O
wired	O
connection	O
,	O
as	O
does	O
server	O
107	O
with	O
remote	O
site	O
109	O
.	O
Using	O
system	O
100	O
,	O
a	O
user	O
can	O
communicate	O
with	O
remote	O
site	O
,	O
and	O
optionally	O
with	O
a	O
user	O
associated	O
with	O
remote	O
site	O
109	O
.	O

While	O
only	O
one	O
mobile	O
device	O
101	O
,	O
fixed	O
device	O
103	O
,	O
server	O
107	O
,	O
and	O
remote	O
site	O
109	O
are	O
shown	O
in	O
FIG	O
.	O
1	O
,	O
it	O
will	O
be	O
recognized	O
that	O
the	O
system	O
100	O
may	O
,	O
and	O
typically	O
does	O
,	O
include	O
a	O
plurality	O
of	O
mobile	O
devices	O
101	O
communicating	O
with	O
a	O
plurality	O
of	O
fixed	O
devices	O
103	O
,	O
fixed	O
devices	O
103	O
in	O
turn	O
being	O
in	O
communication	O
with	O
a	O
plurality	O
of	O
servers	O
107	O
in	O
communication	O
with	O
a	O
plurality	O
of	O
remote	O
sites	O
109	O
.	O
For	O
ease	O
of	O
illustration	O
,	O
a	O
single	O
mobile	O
device	O
101	O
,	O
fixed	O
device	O
103	O
,	O
server	O
107	O
and	O
remote	O
site	O
109	O
have	O
been	O
shown	O
,	O
but	O
the	O
invention	O
described	O
herein	O
is	O
not	O
limited	O
by	O
the	O
size	O
of	O
the	O
system	O
100	O
shown	O
.	O

Communication	O
system	O
100	O
is	O
a	O
distributed	O
speech	O
recognition	O
system	O
as	O
described	O
in	O
US2002/0147579	O
Method	O
and	O
Apparatus	O
for	O
Speech	O
Reconstruction	O
in	O
a	O
Distributed	O
Speech	O
Recognition	O
System	O
.	O
As	O
described	O
in	O
the	O
'579	O
application	O
mobile	O
device	O
101	O
performs	O
feature	O
extraction	O
and	O
the	O
server	O
107	O
performs	O
feature	O
matching	O
.	O
Communication	O
system	O
100	O
also	O
provides	O
reconstructed	O
speech	O
at	O
the	O
server	O
107	O
for	O
storage	O
and/or	O
verification	O
.	O
As	O
discussed	O
above	O
,	O
the	O
communication	O
system	O
described	O
in	O
the	O
'579	O
application	O
utilizes	O
a	O
plurality	O
of	O
transmitted	O
MFCCs	O
to	O
produce	O
the	O
harmonic	O
magnitudes	O
used	O
for	O
speech	O
reconstruction	O
.	O
While	O
the	O
technique	O
for	O
transforming	O
MFCCs	O
into	O
harmonic	O
magnitudes	O
works	O
fairly	O
well	O
,	O
the	O
reconstruction	O
performance	O
(	O
in	O
terms	O
of	O
speech	O
intelligibility	O
and	O
quality	O
)	O
would	O
be	O
better	O
if	O
all	O
the	O
23	O
MFCC	O
values	O
(	O
C0	O
–	O
C22	O
)	O
were	O
available	O
instead	O
of	O
only	O
the	O
13	O
transmitted	O
values	O
,	O
viz	O
.	O
,	O
C0	O
–	O
C12	O
.	O
In	O
order	O
to	O
address	O
this	O
issue	O
,	O
in	O
the	O
preferred	O
embodiment	O
of	O
the	O
present	O
invention	O
,	O
the	O
non-transmitted	O
MFCCs	O
are	O
reconstructed	O
and	O
the	O
harmonic	O
magnitudes	O
are	O
produced	O
by	O
utilizing	O
both	O
the	O
non-transmitted	O
,	O
reconstructed	O
MFCCs	O
as	O
well	O
as	O
the	O
transmitted	O
MFCCs	O
.	O

FIG	O
.	O
2	O
is	O
a	O
more-detailed	O
block	O
diagram	O
of	O
the	O
distributed	O
speech	O
recognition	O
system	O
of	O
FIG	O
.	O
1	O
in	O
accordance	O
with	O
the	O
preferred	O
embodiment	O
of	O
the	O
present	O
invention	O
.	O
As	O
is	O
evident	O
,	O
the	O
distributed	O
speech	O
recognition	O
system	O
is	O
similar	O
to	O
the	O
distributed	O
speech	O
recognition	O
system	O
of	O
the	O
'579	O
application	O
except	O
for	O
the	O
addition	O
of	O
MFCC	O
reconstructor	O
219	O
.	O

As	O
shown	O
mobile	O
device	O
101	O
includes	O
speech	O
input	O
device	O
209	O
(	O
such	O
as	O
a	O
microphone	O
)	O
,	O
which	O
is	O
coupled	O
to	O
DSR	O
signal	O
generator	O
207	O
and	O
speech	O
vocoder-analyzer	O
205	O
.	O
DSR	O
signal	O
generator	O
207	O
extracts	O
the	O
spectral	O
data	O
about	O
the	O
speech	O
input	O
received	O
via	O
speech	O
input	O
device	O
209	O
,	O
and	O
generates	O
a	O
coded	O
signal	O
which	O
is	O
representative	O
of	O
the	O
spectral	O
data	O
.	O
Vocoder-analyzer	O
205	O
extracts	O
additional	O
data	O
about	O
the	O
speech	O
input	O
which	O
may	O
be	O
used	O
to	O
reconstruct	O
the	O
speech	O
at	O
the	O
back	O
end	O
.	O

Summer	O
203	O
combines	O
the	O
coded	O
signal	O
from	O
the	O
DSR	O
signal	O
generator	O
207	O
and	O
the	O
additional	O
data	O
extracted	O
by	O
vocoder-analyzer	O
205	O
into	O
a	O
unified	O
signal	O
,	O
which	O
is	O
passed	O
to	O
transmitter	O
201	O
coupled	O
to	O
summer	O
203	O
.	O
Transmitter	O
201	O
is	O
a	O
radio	O
frequency	O
transmitter	O
or	O
transceiver	O
,	O
although	O
as	O
the	O
method	O
according	O
to	O
the	O
present	O
invention	O
could	O
be	O
used	O
with	O
other	O
types	O
of	O
communication	O
systems	O
,	O
in	O
which	O
case	O
the	O
transmitter	O
would	O
be	O
selected	O
to	O
be	O
compatible	O
with	O
whatever	O
system	O
is	O
selected	O
.	O

DSR	O
signal	O
generator	O
operates	O
as	O
follows	O
in	O
a	O
system	O
designed	O
in	O
accordance	O
with	O
the	O
ETSI	O
Front-End	O
Standard	O
:	O
The	O
speech	O
input	O
is	O
converted	O
from	O
analog	O
to	O
digital	O
,	O
for	O
example	O
at	O
a	O
sampling	O
frequency	O
(	O
Fs	O
)	O
of	O
8000	O
samples/second	O
and	O
16	O
bits/sample	O
.	O
The	O
digitized	O
speech	O
is	O
passed	O
through	O
a	O
DC-offset	O
removal	O
filter	O
,	O
and	O
divided	O
into	O
overlapping	O
frames	O
.	O
Frame	O
size	O
is	O
dependant	O
on	O
the	O
sampling	O
frequency	O
.	O
For	O
the	O
ETSI	O
Front-End	O
Standard	O
,	O
which	O
accommodates	O
three	O
different	O
sampling	O
frequencies	O
of	O
8	O
,	O
11	O
,	O
and	O
16	O
kHz	O
,	O
the	O
possible	O
frame	O
sizes	O
are	O
200	O
,	O
256	O
,	O
and	O
400	O
samples	O
,	O
respectively	O
.	O

The	O
frame	O
energy	O
level	O
is	O
computed	O
and	O
its	O
natural	O
logarithm	O
is	O
determined	O
.	O
The	O
resultant	O
value	O
is	O
also	O
referred	O
to	O
as	O
the	O
log-energy	O
value	O
.	O
The	O
framed	O
,	O
digitized	O
speech	O
signal	O
is	O
then	O
passed	O
through	O
a	O
pre-emphasis	O
filter	O
to	O
emphasize	O
the	O
higher	O
frequency	O
components	O
.	O
Each	O
speech	O
frame	O
is	O
then	O
windowed	O
(	O
e.g.	O
,	O
using	O
a	O
Hamming	O
window	O
)	O
,	O
and	O
transformed	O
into	O
the	O
frequency	O
domain	O
using	O
a	O
Fast	O
Fourier	O
Transform	O
(	O
“	O
FFT	O
”	O
)	O
.	O
Similar	O
to	O
the	O
frame	O
size	O
,	O
the	O
size	O
of	O
the	O
FFT	O
used	O
depends	O
on	O
the	O
sampling	O
frequency	O
,	O
for	O
example	O
a	O
256-point	O
FFT	O
is	O
used	O
for	O
8	O
and	O
11	O
kHz	O
sampling	O
frequencies	O
and	O
a	O
512-point	O
FFT	O
is	O
used	O
for	O
a	O
16	O
KHz	O
sampling	O
frequency	O
.	O

The	O
FFT	O
magnitudes	O
in	O
the	O
frequency	O
range	O
between	O
64	O
Hz	O
and	O
Fs/2	O
(	O
for	O
example	O
,	O
4	O
kHz	O
for	O
a	O
sampling	O
frequency	O
of	O
8	O
kHz	O
)	O
are	O
then	O
transformed	O
into	O
the	O
Mel-frequency	O
domain	O
by	O
a	O
process	O
known	O
as	O
Mel-filtering	O
.	O
A	O
transformation	O
into	O
the	O
Mel-frequency	O
domain	O
is	O
performed	O
because	O
psychophysical	O
studies	O
have	O
shown	O
that	O
human	O
perception	O
of	O
the	O
frequency	O
contents	O
of	O
sounds	O
for	O
speech	O
signals	O
does	O
not	O
follow	O
a	O
linear	O
scale	O
.	O
Accordingly	O
,	O
for	O
each	O
tone	O
with	O
an	O
actual	O
frequency	O
,	O
f	O
,	O
measured	O
in	O
Hz	O
,	O
a	O
subjective	O
pitch	O
may	O
be	O
represented	O
on	O
a	O
second	O
scale	O
,	O
which	O
is	O
referred	O
to	O
as	O
the	O
Mel-frequency	O
scale	O
.	O

The	O
Mel-filtering	O
process	O
is	O
as	O
follows	O
.	O
First	O
,	O
the	O
frequency	O
range	O
(	O
e.g.	O
,	O
64	O
Hz	O
to	O
4000	O
Hz	O
)	O
is	O
warped	O
into	O
a	O
Mel-frequency	O
scale	O
using	O
the	O
expression	O
:	O

Mel	O
⁡	O

(	O
f	O
)	O

=	O

2595	O
.	O
0	O
*	O

log	O
10	O

⁡	O

(	O

1	O
+	O

f	O
700	O
.	O
0	O

)	O

.	O

Using	O
this	O
equation	O
,	O
the	O
Mel-frequencies	O
corresponding	O
,	O
for	O
example	O
,	O
to	O
frequencies	O
of	O
64	O
Hz	O
and	O
4000	O
Hz	O
are	O
98	O
.	O
6	O
and	O
2146	O
.	O
1	O
,	O
respectively	O
.	O
This	O
Mel-frequency	O
range	O
is	O
then	O
divided	O
into	O
23	O
equal-sized	O
,	O
half-overlapping	O
bands	O
(	O
also	O
known	O
as	O
channels	O
or	O
bins	O
)	O
,	O
each	O
band	O
170	O
.	O
6	O
wide	O
and	O
the	O
center	O
of	O
each	O
band	O
85	O
.	O
3	O
apart	O
.	O
The	O
center	O
of	O
the	O
first	O
band	O
is	O
located	O
at	O
98.6+85.3=183.9	O
,	O
and	O
that	O
of	O
the	O
last	O
band	O
is	O
located	O
at	O
2146	O
.	O
1	O
−	O
85	O
.	O
3	O
−	O
2060	O
.	O
8	O
.	O
These	O
bands	O
of	O
equal	O
size	O
in	O
the	O
Mel-frequency	O
domain	O
correspond	O
to	O
bands	O
of	O
unequal	O
sizes	O
in	O
the	O
linear	O
frequency	O
domain	O
with	O
the	O
size	O
increasing	O
along	O
the	O
frequency	O
axis	O
.	O
The	O
FFT	O
magnitudes	O
falling	O
inside	O
each	O
band	O
are	O
then	O
averaged	O
(	O
filtered	O
)	O
using	O
a	O
triangular	O
weighting	O
window	O
(	O
with	O
the	O
weight	O
at	O
the	O
center	O
equal	O
to	O
1	O
.	O
0	O
and	O
at	O
either	O
end	O
equal	O
to	O
0	O
.	O
0	O
)	O
.	O
The	O
filtered	O
band	O
outputs	O
are	O
then	O
subjected	O
to	O
a	O
natural	O
logarithm	O
operation	O
.	O

The	O
23	O
log-spectral	O
values	O
generated	O
are	O
then	O
transformed	O
into	O
the	O
cepstral	O
domain	O
by	O
means	O
of	O
a	O
23-point	O
DCT	O
(	O
Discrete	O
Cosine	O
Transform	O
)	O
.	O
It	O
should	O
be	O
noted	O
that	O
only	O
the	O
first	O
13	O
values	O
(	O
C0	O
through	O
C12	O
)	O
are	O
calculated	O
,	O
with	O
the	O
remaining	O
ten	O
values	O
(	O
C13	O
through	O
C22	O
)	O
being	O
discarded	O
,	O
i	O
.	O
e	O
.	O
,	O
not	O
computed	O
.	O
The	O
frame	O
log-energy	O
and	O
the	O
13	O
cepstral	O
values	O
(	O
also	O
referred	O
to	O
as	O
Mel-Frequency	O
Cepstral	O
Coefficients	O
,	O
or	O
MFCCs	O
)	O
are	O
then	O
compressed	O
(	O
quantized	O
)	O
and	O
transmitted	O
to	O
fixed	O
device	O
107	O
.	O
For	O
communication	O
system	O
100	O
operating	O
according	O
to	O
the	O
ETSI	O
Front-End	O
Standard	O
,	O
the	O
MFCC	O
and	O
log-energy	O
values	O
are	O
updated	O
every	O
10	O
ms	O
.	O

As	O
mentioned	O
above	O
,	O
vocoder-analyzer	O
205	O
also	O
receives	O
the	O
speech	O
input	O
.	O
In	O
particular	O
,	O
vocoder-analyzer	O
205	O
analyzes	O
the	O
input	O
to	O
determine	O
other	O
data	O
about	O
the	O
speech	O
input	O
which	O
may	O
be	O
used	O
by	O
server	O
107	O
in	O
addition	O
to	O
the	O
data	O
derivable	O
from	O
the	O
DSR-coded	O
speech	O
to	O
reconstruct	O
the	O
speech	O
.	O
The	O
exact	O
data	O
extracted	O
by	O
vocoder-analyzer	O
205	O
is	O
dependent	O
upon	O
the	O
characteristics	O
of	O
the	O
speech	O
vocoder	O
associated	O
with	O
server	O
107	O
which	O
will	O
be	O
synthesizing	O
the	O
reconstructed	O
speech	O
.	O
For	O
example	O
,	O
Code	O
Excited	O
Linear	O
Predictive	O
(	O
CELP	O
)	O
vocoders	O
require	O
codebook	O
indices	O
for	O
each	O
sub-frame	O
of	O
speech	O
to	O
be	O
prepared	O
.	O
For	O
parametric	O
vocoders	O
(	O
e.g.	O
,	O
sinusoidal	O
vocoders	O
)	O
,	O
additional	O
excitation	O
data	O
may	O
be	O
required	O
,	O
such	O
as	O
the	O
class	O
(	O
voiced	O
,	O
unvoiced	O
,	O
etc	O
.	O
)	O
and	O
the	O
pitch	O
period	O
as	O
well	O
as	O
higher-resolution	O
energy	O
data	O
such	O
as	O
the	O
sub-frame	O
energy	O
levels	O
.	O

One	O
will	O
recognize	O
that	O
the	O
quality	O
of	O
speech	O
synthesized	O
by	O
CELP	O
coders	O
falls	O
rapidly	O
when	O
the	O
bit	O
rate	O
is	O
reduced	O
below	O
about	O
4800	O
bps	O
.	O
On	O
the	O
other	O
hand	O
,	O
parametric	O
vocoders	O
provide	O
reasonable	O
speech	O
quality	O
at	O
lower	O
bit	O
rates	O
.	O
Since	O
one	O
of	O
the	O
main	O
requirements	O
of	O
a	O
DSR	O
system	O
is	O
low	O
data	O
transmission	O
rate	O
,	O
a	O
parametric	O
vocoder	O
,	O
specifically	O
a	O
sinusoidal	O
vocoder	O
,	O
will	O
be	O
typically	O
used	O
in	O
server	O
107	O
.	O
Consequently	O
,	O
according	O
to	O
the	O
preferred	O
embodiment	O
of	O
the	O
invention	O
,	O
speech	O
vocoder-analyzer	O
205	O
determines	O
class	O
,	O
pitch	O
period	O
and	O
sub-frame	O
energy	O
data	O
for	O
each	O
speech	O
frame	O
,	O
although	O
optionally	O
the	O
sub-frame	O
energy	O
data	O
may	O
be	O
omitted	O
because	O
the	O
sub-frame	O
energies	O
may	O
be	O
computed	O
by	O
interpolation	O
from	O
the	O
log-energy	O
value	O
.	O

Vocoder-analyzer	O
205	O
preferably	O
operates	O
on	O
a	O
frame	O
size	O
of	O
approximately	O
20	O
ms	O
,	O
i	O
.	O
e	O
.	O
,	O
the	O
parameters	O
are	O
transmitted	O
once	O
every	O
20	O
ms	O
.	O
In	O
each	O
frame	O
,	O
2	O
bits	O
are	O
used	O
for	O
the	O
class	O
parameter	O
,	O
i	O
.	O
e	O
.	O
,	O
to	O
indicate	O
whether	O
a	O
frame	O
is	O
non-speech	O
,	O
voiced	O
,	O
unvoiced	O
,	O
mixed-voiced	O
,	O
etc	O
.	O
The	O
speech/non-speech	O
classification	O
is	O
preferably	O
done	O
using	O
an	O
energy-based	O
Voice	O
Activity	O
Detector	O
(	O
VAD	O
)	O
,	O
while	O
the	O
determination	O
of	O
voicing	O
level	O
is	O
based	O
on	O
a	O
number	O
of	O
features	O
including	O
periodic	O
correlation	O
(	O
normalized	O
correlation	O
at	O
a	O
lag	O
equal	O
to	O
a	O
pitch	O
period	O
)	O
,	O
a	O
periodic	O
energy	O
ratio	O
(	O
ratio	O
of	O
energies	O
of	O
decorrelated	O
and	O
original	O
frames	O
)	O
,	O
and	O
high-frequency	O
energy	O
ratio	O
.	O
The	O
pitch	O
period	O
parameter	O
,	O
which	O
provides	O
information	O
about	O
the	O
harmonic	O
frequencies	O
,	O
can	O
typically	O
be	O
represented	O
using	O
an	O
additional	O
7	O
bits	O
for	O
a	O
typical	O
pitch	O
frequency	O
range	O
of	O
about	O
55	O
Hz	O
to	O
420	O
Hz	O
.	O
The	O
pitch	O
period	O
is	O
preferably	O
estimated	O
using	O
a	O
time-domain	O
correlation	O
analysis	O
of	O
low-pass	O
filtered	O
speech	O
.	O
If	O
the	O
higher-resolution	O
energy	O
data	O
,	O
e.g.	O
,	O
sub-frame	O
energy	O
,	O
parameter	O
is	O
to	O
be	O
transmitted	O
,	O
this	O
may	O
be	O
accomplished	O
using	O
an	O
additional	O
8	O
bits	O
.	O
The	O
sub-frame	O
energies	O
are	O
quantized	O
in	O
the	O
log-domain	O
by	O
a	O
4-dimensional	O
VQ	O
,	O
with	O
the	O
energy	O
for	O
non-speech	O
and	O
unvoiced	O
speech	O
frames	O
computed	O
over	O
a	O
sub-frame	O
(	O
4	O
sub-frames	O
per	O
frame	O
)	O
and	O
the	O
energy	O
for	O
voiced	O
frames	O
computed	O
over	O
a	O
pitch	O
period	O
.	O
As	O
an	O
alternative	O
,	O
the	O
sub-frame	O
energies	O
may	O
be	O
combined	O
with	O
the	O
log-energy	O
value	O
to	O
reduce	O
the	O
bit	O
rate	O
.	O

Assuming	O
that	O
class	O
,	O
pitch	O
period	O
,	O
and	O
sub-frame	O
energy	O
values	O
are	O
transmitted	O
every	O
20	O
ms	O
,	O
i	O
.	O
e	O
.	O
,	O
once	O
for	O
every	O
two	O
DSR	O
frames	O
if	O
an	O
ETSI	O
Standard	O
system	O
is	O
used	O
,	O
approximately	O
800	O
to	O
850	O
bps	O
will	O
be	O
added	O
to	O
the	O
data	O
transmission	O
rate	O
.	O
If	O
the	O
additional	O
energy	O
data	O
is	O
not	O
transmitted	O
,	O
as	O
little	O
as	O
450	O
bps	O
may	O
be	O
added	O
to	O
the	O
data	O
transmission	O
rate	O
.	O

The	O
detailed	O
structure	O
of	O
server	O
107	O
is	O
now	O
discussed	O
with	O
reference	O
to	O
the	O
right-half	O
of	O
FIG	O
.	O
2	O
.	O
Receiver	O
211	O
(	O
which	O
is	O
a	O
radio-frequency	O
(	O
RF	O
)	O
receiver	O
)	O
is	O
coupled	O
to	O
conventional	O
DSR	O
parameter	O
extractor	O
213	O
and	O
MFCC	O
reconstructor	O
219	O
.	O
The	O
DSR	O
parameter	O
extractor	O
213	O
is	O
coupled	O
to	O
conventional	O
DSR	O
processor	O
215	O
and	O
conventional	O
speech	O
recognizer	O
217	O
to	O
compare	O
the	O
encoded	O
data	O
with	O
a	O
known	O
data	O
set	O
,	O
while	O
the	O
MFCC	O
reconstructor	O
219	O
is	O
coupled	O
to	O
DSR/speech	O
processor	O
221	O
,	O
which	O
in	O
turn	O
is	O
coupled	O
to	O
speech	O
vocoder-synthesizer	O
223	O
(	O
as	O
indicated	O
previously	O
,	O
preferably	O
a	O
sinusoidal	O
speech	O
vocoder-synthesizer	O
)	O
and	O
speech	O
output	O
(	O
e.g.	O
,	O
speaker	O
)	O
225	O
.	O

During	O
operation	O
,	O
receiver	O
211	O
receives	O
pitch	O
period	O
P	O
as	O
well	O
as	O
the	O
transmitted	O
MFCCs	O
,	O
C0	O
–	O
C12	O
.	O
These	O
are	O
passed	O
to	O
MFCC	O
reconstructor	O
219	O
where	O
the	O
non-transmitted	O
MFCCs	O
are	O
reconstructed	O
.	O
Exact	O
recovery	O
of	O
the	O
missing	O
coefficients	O
is	O
not	O
possible	O
.	O
However	O
,	O
a	O
partial	O
recovery	O
can	O
be	O
achieved	O
by	O
exploiting	O
the	O
dependence	O
of	O
the	O
missing	O
MFCCs	O
(	O
in	O
this	O
case	O
C13	O
–	O
C22	O
)	O
,	O
on	O
the	O
transmitted	O
pitch	O
period	O
P	O
as	O
well	O
as	O
on	O
the	O
transmitted	O
MFCCs	O
,	O
C0	O
–	O
C12	O
.	O
In	O
a	O
first	O
embodiment	O
,	O
a	O
lookup	O
table	O
is	O
utilized	O
to	O
generate	O
the	O
missing	O
MFCCs	O
.	O

In	O
order	O
to	O
exploit	O
the	O
dependence	O
between	O
the	O
missing	O
MFCCs	O
and	O
the	O
pitch	O
period	O
,	O
a	O
large	O
database	O
of	O
speech	O
signals	O
is	O
utilized	O
to	O
extract	O
the	O
relevant	O
information	O
,	O
(	O
pitch	O
period	O
and	O
the	O
missing	O
MFCCs	O
)	O
for	O
each	O
“	O
voiced	O
”	O
frame	O
within	O
the	O
database	O
.	O
The	O
pitch	O
period	O
range	O
[	O
PMIN	O
,	O
PMAX	O
]	O
is	O
then	O
divided	O
into	O
different	O
groups	O
G1	O
,	O
G2	O
,	O
.	O
.	O
.	O
,	O
GM	O
and	O
the	O
missing	O
MFCC	O
vectors	O
corresponding	O
to	O
each	O
group	O
are	O
separated	O
.	O
The	O
average	O
of	O
the	O
missing	O
MFCC	O
vectors	O
corresponding	O
to	O
each	O
group	O
is	O
next	O
computed	O
and	O
stored	O
.	O
These	O
average	O
vectors	O
D1	O
,	O
D2	O
,	O
.	O
.	O
.	O
,	O
DM	O
(	O
of	O
dimension	O
10	O
)	O
represent	O
the	O
partially	O
recovered	O
missing	O
MFCCs	O
as	O
a	O
function	O
of	O
the	O
pitch	O
period	O
.	O
In	O
actual	O
operation	O
,	O
i	O
.	O
e	O
.	O
,	O
during	O
speech	O
reconstruction	O
at	O
the	O
back-end	O
,	O
the	O
pitch	O
period	O
P	O
is	O
used	O
to	O
identify	O
the	O
appropriate	O
group	O
Gm	O
and	O
use	O
the	O
corresponding	O
(	O
pre-stored	O
)	O
average	O
vector	O
Dm	O
for	O
the	O
missing	O
MFCC	O
values	O
C13	O
–	O
C22	O
.	O
All	O
MFCC	O
values	O
(	O
actual	O
and	O
generated	O
)	O
are	O
then	O
passed	O
to	O
DSR/speech	O
processor	O
221	O
.	O

DSR/speech	O
processor	O
221	O
includes	O
a	O
program	O
which	O
controls	O
the	O
DSR/speech	O
processor	O
221	O
to	O
determine	O
and	O
decode	O
the	O
DSR-encoded	O
spectral	O
data	O
,	O
and	O
in	O
particular	O
the	O
harmonic	O
magnitudes	O
.	O
First	O
,	O
the	O
MFCC	O
values	O
corresponding	O
to	O
the	O
impulse	O
response	O
of	O
the	O
pre-emphasis	O
filter	O
are	O
subtracted	O
from	O
the	O
received	O
MFCC	O
values	O
to	O
remove	O
the	O
effect	O
of	O
the	O
pre-emphasis	O
filter	O
as	O
well	O
as	O
the	O
effect	O
of	O
the	O
Mel-filter	O
.	O
Next	O
,	O
the	O
MFCC	O
values	O
are	O
inverted	O
to	O
compute	O
the	O
log-spectral	O
value	O
for	O
each	O
desired	O
harmonic	O
frequency	O
.	O
The	O
log-spectral	O
values	O
are	O
then	O
exponentiated	O
to	O
get	O
the	O
spectral	O
magnitude	O
for	O
the	O
harmonics	O
.	O
Typically	O
,	O
these	O
steps	O
are	O
performed	O
every	O
20	O
ms	O
,	O
although	O
the	O
calculations	O
may	O
be	O
made	O
more	O
frequently	O
,	O
e.g.	O
,	O
every	O
10	O
ms	O
.	O

FIG	O
.	O
3	O
is	O
a	O
flow	O
chart	O
showing	O
operation	O
of	O
the	O
MFCC	O
reconstructor	O
of	O
FIG	O
.	O
2	O
in	O
accordance	O
with	O
the	O
preferred	O
embodiment	O
of	O
the	O
present	O
invention	O
.	O
The	O
logic	O
flow	O
begins	O
at	O
step	O
301	O
where	O
a	O
first	O
plurality	O
of	O
MFCC	O
values	O
are	O
received	O
.	O
As	O
discussed	O
above	O
,	O
only	O
the	O
first	O
13	O
values	O
(	O
C0	O
through	O
C12	O
)	O
are	O
transmitted	O
to	O
receiver	O
211	O
,	O
with	O
the	O
remaining	O
ten	O
values	O
(	O
C13	O
through	O
C22	O
)	O
being	O
discarded	O
by	O
mobile	O
unit	O
101	O
.	O
At	O
step	O
303	O
MFCC	O
reconstructor	O
219	O
calculates	O
the	O
missing	O
MFCC	O
values	O
.	O
Finally	O
,	O
at	O
step	O
305	O
MFCC	O
reconstructor	O
219	O
combines	O
the	O
received	O
MFCC	O
values	O
(	O
C0	O
through	O
C12	O
)	O
with	O
the	O
calculated	O
MFCC	O
values	O
(	O
C13	O
through	O
C22	O
)	O
to	O
generate	O
the	O
full-length	O
MFCC	O
vector	O
(	O
C0	O
through	O
C22	O
)	O
and	O
feed	O
it	O
to	O
the	O
DSR/Speech	O
Processor	O
221	O
.	O

FIG	O
.	O
4	O
is	O
a	O
flow	O
chart	O
showing	O
operation	O
of	O
DSR/Speech	O
processor	O
221	O
in	O
accordance	O
with	O
the	O
preferred	O
embodiment	O
of	O
the	O
present	O
invention	O
.	O
The	O
logic	O
flow	O
begins	O
at	O
step	O
401	O
where	O
both	O
the	O
transmitted	O
MFCC	O
values	O
(	O
C0	O
–	O
C12	O
)	O
and	O
the	O
reconstructed	O
MFCC	O
values	O
(	O
C13	O
–	O
C22	O
)	O
are	O
received	O
.	O
At	O
a	O
step	O
403	O
,	O
the	O
MFCC	O
values	O
C0	O
–	O
C22	O
corresponding	O
to	O
the	O
impulse	O
response	O
of	O
the	O
pre-emphasis	O
filter	O
are	O
subtracted	O
from	O
the	O
received	O
MFCC	O
values	O
principally	O
to	O
remove	O
the	O
effect	O
of	O
the	O
pre-emphasis	O
filter	O
.	O
Alternatively	O
,	O
the	O
effect	O
of	O
the	O
pre-emphasis	O
filter	O
may	O
be	O
removed	O
as	O
a	O
last	O
step	O
by	O
dividing	O
the	O
spectral	O
magnitude	O
of	O
the	O
harmonic	O
frequency	O
by	O
the	O
impulse	O
response	O
of	O
the	O
pre-emphasis	O
filter	O
at	O
that	O
corresponding	O
harmonic	O
frequency	O
.	O
However	O
,	O
in	O
addition	O
to	O
the	O
pre-emphasis	O
filter	O
,	O
the	O
Mel-filter	O
emphasizes	O
higher	O
frequencies	O
because	O
of	O
the	O
increasing	O
width	O
of	O
the	O
frequency	O
bands	O
along	O
the	O
linear	O
frequency	O
axis	O
.	O
The	O
Mel-filter	O
impulse	O
response	O
at	O
any	O
band	O
center	O
can	O
be	O
taken	O
to	O
be	O
the	O
width	O
of	O
the	O
corresponding	O
band	O
,	O
and	O
for	O
any	O
other	O
frequency	O
,	O
an	O
interpolated	O
value	O
can	O
be	O
used	O
.	O
By	O
computing	O
a	O
combined	O
impulse	O
response	O
of	O
the	O
pre-emphasis	O
filter	O
and	O
the	O
Mel-filter	O
,	O
the	O
effect	O
of	O
both	O
filters	O
can	O
be	O
removed	O
in	O
a	O
single	O
step	O
by	O
dividing	O
the	O
spectral	O
magnitude	O
of	O
the	O
harmonic	O
frequency	O
by	O
the	O
combined	O
impulse	O
response	O
at	O
that	O
corresponding	O
harmonic	O
frequency	O
.	O
The	O
step	O
403	O
achieves	O
the	O
same	O
result	O
.	O

The	O
modified	O
MFCC	O
values	O
with	O
the	O
effect	O
of	O
the	O
pre-emphasis	O
filter	O
and	O
the	O
Mel-filter	O
removed	O
are	O
then	O
used	O
to	O
estimate	O
the	O
spectral	O
magnitudes	O
according	O
to	O
the	O
following	O
steps	O
.	O
The	O
Mel-frequencies	O
corresponding	O
to	O
the	O
harmonic	O
frequencies	O
(	O
derivable	O
from	O
the	O
pitch	O
period	O
)	O
are	O
determined	O
at	O
a	O
step	O
405	O
.	O
An	O
inverse	O
discrete	O
cosine	O
transform	O
(	O
IDCT	O
)	O
is	O
then	O
performed	O
on	O
the	O
modified	O
MFCC	O
values	O
at	O
the	O
harmonic	O
Mel-frequencies	O
to	O
transform	O
the	O
cepstral	O
coefficients	O
into	O
log-spectral	O
values	O
at	O
steps	O
407	O
,	O
409	O
.	O

That	O
is	O
,	O
a	O
23-point	O
IDCT	O
of	O
the	O
MFCC	O
values	O
C0	O
through	O
C22	O
would	O
restore	O
the	O
original	O
23	O
log-spectral	O
values	O
except	O
for	O
the	O
distortion	O
caused	O
by	O
the	O
quantization	O
error	O
in	O
the	O
MFCC	O
values	O
C0	O
through	O
C12	O
and	O
the	O
reconstruction	O
error	O
in	O
the	O
MFCC	O
values	O
C13	O
through	O
C22	O
.	O
These	O
log-spectral	O
values	O
correspond	O
,	O
however	O
,	O
to	O
the	O
centers	O
of	O
the	O
23	O
frequency	O
bands	O
.	O
The	O
log-spectral	O
values	O
at	O
other	O
frequencies	O
are	O
required	O
to	O
determine	O
the	O
transformed	O
MFCC	O
values	O
for	O
the	O
harmonic	O
frequencies	O
.	O

To	O
increase	O
the	O
sampling	O
resolution	O
,	O
the	O
IDCT	O
size	O
can	O
be	O
increased	O
by	O
an	O
odd	O
multiple	O
of	O
23	O
,	O
that	O
is	O
(	O
2K	O
+	O
1	O
)	O
*	O
23	O
,	O
where	O
K	O
>	O
0	O
.	O
This	O
introduces	O
K	O
additional	O
Mel-frequency	O
points	O
on	O
either	O
side	O
of	O
the	O
23	O
original	O
Mel-frequencies	O
corresponding	O
to	O
the	O
centers	O
of	O
the	O
frequency	O
bands	O
.	O
For	O
example	O
,	O
if	O
K	O
=	O
85	O
,	O
there	O
are	O
85	O
additional	O
Mel-frequency	O
points	O
to	O
the	O
left	O
of	O
the	O
first	O
frequency	O
band	O
center	O
and	O
to	O
the	O
right	O
of	O
the	O
last	O
(	O
i	O
.	O
e	O
.	O
,	O
23rd	O
)	O
frequency	O
band	O
center	O
,	O
and	O
170	O
additional	O
Mel-frequency	O
points	O
between	O
any	O
two	O
consecutive	O
frequency	O
band	O
centers	O
.	O
The	O
total	O
number	O
of	O
Mel-frequency	O
points	O
,	O
in	O
this	O
case	O
,	O
is	O
171	O
*	O
23	O
=	O
3933	O
.	O
For	O
Fs	O
=	O
8000	O
Hz	O
,	O
the	O
centers	O
of	O
the	O
frequency	O
bands	O
are	O
85	O
.	O
3	O
apart	O
in	O
Mel-frequency	O
scale	O
,	O
and	O
the	O
choice	O
of	O
K	O
=	O
85	O
increases	O
the	O
resolution	O
such	O
that	O
consecutive	O
Mel-frequency	O
points	O
are	O
only	O
85.3/171=0.499	O
apart	O
.	O
It	O
is	O
important	O
to	O
note	O
that	O
the	O
leftmost	O
and	O
rightmost	O
Mel-frequency	O
points	O
of	O
the	O
IDCT	O
do	O
not	O
correspond	O
to	O
0	O
and	O
Fs/2	O
(	O
e.g.	O
,	O
4000	O
Hz	O
)	O
in	O
linear	O
frequency	O
scale	O
.	O
For	O
our	O
example	O
,	O
the	O
leftmost	O
Mel-frequency	O
point	O
is	O
at	O
183	O
.	O
9	O
−	O
85	O
*	O
0.499=141.48	O
,	O
and	O
the	O
rightmost	O
Mel-frequency	O
point	O
is	O
at	O
2060	O
.	O
8	O
+	O
85	O
*	O
0.499=2103.2	O
.	O
The	O
corresponding	O
points	O
in	O
the	O
linear	O
frequency	O
scale	O
are	O
respectively	O
93	O
.	O
6	O
Hz	O
and	O
3824	O
.	O
6	O
Hz	O
.	O
One	O
way	O
to	O
handle	O
frequencies	O
not	O
covered	O
by	O
the	O
IDCT	O
frequency	O
range	O
is	O
to	O
use	O
the	O
nearest	O
frequency	O
point	O
,	O
i	O
.	O
e	O
.	O
,	O
frequencies	O
below	O
93	O
.	O
6	O
Hz	O
are	O
assigned	O
the	O
frequency	O
point	O
at	O
93	O
.	O
6	O
Hz	O
,	O
and	O
similarly	O
frequencies	O
above	O
3824	O
.	O
6	O
Hz	O
are	O
assigned	O
the	O
frequency	O
point	O
at	O
3824	O
.	O
6	O
Hz	O
.	O
An	O
alternate	O
method	O
is	O
to	O
use	O
some	O
type	O
of	O
interpolation	O
.	O

The	O
higher	O
resolution	O
IDCT	O
essentially	O
interpolates	O
between	O
the	O
Mel-frequency	O
band	O
centers	O
using	O
the	O
DCT	O
basis	O
functions	O
themselves	O
as	O
the	O
interpolating	O
functions	O
.	O
However	O
,	O
it	O
is	O
not	O
necessary	O
to	O
perform	O
a	O
3933-point	O
IDCT	O
.	O
Instead	O
,	O
to	O
facilitate	O
computation	O
of	O
the	O
IDCT	O
at	O
selected	O
frequency	O
points	O
,	O
a	O
12	O
×	O
3933	O
matrix	O
L	O
of	O
IDCT	O
values	O
may	O
be	O
optionally	O
pre-computed	O
at	O
a	O
step	O
408	O
using	O
the	O
equation	O
:	O

L	O

i	O
,	O
j	O

=	O

(	O

2	O
23	O

)	O

⁢	O

cos	O
⁡	O

(	O

(	O

2	O
⁢	O
j	O

+	O
1	O

)	O

*	O
i	O
*	O
π	O

2	O
*	O
23	O
*	O
171	O

)	O

,	O

where	O
i	O
=	O
1	O
,	O
2	O
,	O
.	O
.	O
.	O
,	O
12	O
and	O
j	O
=	O
0	O
,	O
1	O
,	O
.	O
.	O
.	O
,	O
3932	O
.	O
The	O
zeroth	O
row	O
corresponding	O
to	O
C0	O
is	O
implicit	O
and	O
need	O
not	O
be	O
stored	O
since	O
its	O
value	O
is	O
constant	O
at	O
1/23	O
for	O
all	O
columns	O
.	O

Given	O
this	O
matrix	O
L	O
,	O
to	O
get	O
the	O
log-spectral	O
value	O
at	O
any	O
given	O
Mel-frequency	O
,	O
the	O
nearest	O
Mel-frequency	O
point	O
for	O
which	O
the	O
IDCT	O
has	O
been	O
calculated	O
is	O
located	O
,	O
the	O
corresponding	O
column	O
vector	O
of	O
the	O
matrix	O
L	O
is	O
selected	O
,	O
and	O
an	O
inner	O
product	O
between	O
the	O
corresponding	O
column	O
and	O
the	O
modified	O
MFCC	O
vector	O
[	O
C0	O
,	O
C1	O
,	O
.	O
.	O
.	O
,	O
C22	O
]	O
is	O
formed	O
.	O
Consequently	O
,	O
to	O
determine	O
the	O
log-spectral	O
values	O
for	O
the	O
harmonic	O
frequencies	O
,	O
for	O
example	O
,	O
the	O
nearest	O
Mel-frequency	O
points	O
are	O
located	O
and	O
the	O
corresponding	O
column	O
vectors	O
of	O
the	O
matrix	O
L	O
selected	O
at	O
the	O
step	O
407	O
.	O
Further	O
,	O
at	O
the	O
step	O
409	O
,	O
the	O
inner	O
products	O
are	O
formed	O
between	O
the	O
modified	O
MFCC	O
vector	O
and	O
the	O
column	O
vectors	O
of	O
matrix	O
L	O
selected	O
at	O
the	O
step	O
407	O
.	O
The	O
transformed	O
coefficients	O
are	O
then	O
exponentiated	O
to	O
compute	O
the	O
spectral	O
magnitudes	O
at	O
a	O
step	O
411	O
.	O

The	O
sinusoidal	O
speech	O
vocoder-synthesizer	O
223	O
uses	O
these	O
spectral	O
magnitudes	O
,	O
along	O
with	O
the	O
data	O
regarding	O
the	O
frame	O
energy	O
and	O
other	O
data	O
(	O
such	O
as	O
class	O
,	O
pitch	O
period	O
,	O
and	O
sub-frame	O
energy	O
)	O
also	O
extracted	O
by	O
the	O
DSR/speech	O
processor	O
221	O
under	O
the	O
control	O
of	O
the	O
afore-mentioned	O
program	O
,	O
to	O
reconstruct	O
the	O
speech	O
as	O
the	O
sum	O
of	O
a	O
number	O
of	O
sinusoidal	O
signals	O
with	O
different	O
frequencies	O
,	O
amplitudes	O
,	O
and	O
phases	O
.	O
In	O
particular	O
,	O
the	O
synthesizer	O
reconstructs	O
speech	O
using	O
a	O
sinusoidal	O
model	O
of	O
speech	O
production	O
:	O

s	O
⁡	O

(	O
j	O
)	O

=	O

∑	O
k	O

⁢	O

A	O

k	O
,	O
j	O

⁢	O

cos	O
⁡	O

(	O

Φ	O

k	O
,	O
j	O

)	O

where	O
the	O
speech	O
sample	O
s	O
(	O
j	O
)	O
is	O
synthesized	O
as	O
the	O
sum	O
of	O
a	O
number	O
of	O
harmonically	O
related	O
sinusoids	O
with	O
amplitude	O
Ak	O
,	O
j	O
and	O
phase	O
Φk	O
,	O
j	O
,	O
j	O
being	O
the	O
sample	O
index	O
and	O
k	O
being	O
the	O
harmonic	O
index	O
.	O

Typically	O
,	O
the	O
synthesis	O
process	O
starts	O
with	O
the	O
computation	O
of	O
the	O
frequencies	O
,	O
amplitudes	O
,	O
and	O
phases	O
at	O
the	O
midpoint	O
of	O
each	O
frame	O
.	O
The	O
frequencies	O
used	O
are	O
the	O
pitch	O
frequency	O
and	O
its	O
harmonics	O
,	O
which	O
can	O
be	O
computed	O
using	O
the	O
pitch	O
period	O
.	O
The	O
amplitudes	O
used	O
may	O
be	O
the	O
harmonic	O
amplitudes	O
,	O
which	O
may	O
be	O
estimated	O
using	O
the	O
spectral	O
amplitudes	O
determined	O
using	O
the	O
method	O
discussed	O
above	O
and	O
the	O
sub-frame	O
energy	O
corresponding	O
to	O
the	O
midpoint	O
of	O
the	O
frame	O
(	O
or	O
an	O
interpolation	O
thereof	O
using	O
the	O
log-energy	O
value	O
)	O
.	O
Alternatively	O
,	O
for	O
unvoiced	O
speech	O
for	O
example	O
,	O
the	O
amplitudes	O
may	O
correspond	O
to	O
a	O
set	O
of	O
frequencies	O
not	O
necessarily	O
identical	O
to	O
the	O
harmonic	O
frequencies	O
,	O
in	O
which	O
case	O
these	O
amplitudes	O
may	O
be	O
estimated	O
using	O
the	O
general	O
form	O
of	O
the	O
method	O
described	O
above	O
and	O
the	O
sub-frame	O
energy	O
corresponding	O
to	O
the	O
midpoint	O
of	O
the	O
frame	O
(	O
or	O
an	O
interpolation	O
thereof	O
using	O
the	O
log-energy	O
value	O
)	O
.	O
The	O
phases	O
computed	O
depend	O
on	O
the	O
class	O
parameter	O
.	O
For	O
voiced	O
speech	O
,	O
coherent	O
phases	O
are	O
computed	O
.	O
For	O
unvoiced	O
speech	O
,	O
random	O
,	O
non-coherent	O
,	O
phases	O
are	O
computed	O
.	O
For	O
mixed-voiced	O
speech	O
,	O
the	O
voiced	O
model	O
is	O
used	O
for	O
lower	O
frequencies	O
and	O
the	O
unvoiced	O
model	O
is	O
used	O
for	O
higher	O
frequencies	O
.	O
Any	O
linear	O
phase	O
component	O
is	O
removed	O
from	O
the	O
modeled	O
phases	O
.	O

Once	O
the	O
midpoint	O
frequency	O
,	O
amplitude	O
and	O
phase	O
values	O
are	O
known	O
,	O
the	O
amplitudes	O
and	O
phases	O
at	O
other	O
points	O
may	O
be	O
calculated	O
.	O
For	O
example	O
,	O
once	O
the	O
amplitudes	O
at	O
the	O
midpoints	O
of	O
the	O
current	O
and	O
previous	O
voiced	O
frames	O
are	O
known	O
,	O
the	O
amplitudes	O
at	O
the	O
sub-frame	O
boundaries	O
may	O
be	O
calculated	O
using	O
linear	O
interpolation	O
with	O
an	O
adjustment	O
for	O
the	O
energies	O
at	O
these	O
points	O
.	O
Amplitudes	O
within	O
a	O
sub-frame	O
may	O
also	O
be	O
calculated	O
using	O
linear	O
interpolation	O
.	O
The	O
harmonic	O
phases	O
at	O
different	O
sample	O
indices	O
may	O
be	O
calculated	O
by	O
allowing	O
the	O
phases	O
to	O
evolve	O
linearly	O
according	O
to	O
the	O
frequency	O
.	O
The	O
frequencies	O
are	O
allowed	O
to	O
change	O
at	O
the	O
sub-frame	O
boundaries	O
in	O
equal	O
steps	O
from	O
the	O
previous	O
values	O
to	O
the	O
current	O
values	O
.	O
Any	O
phase	O
discontinuities	O
arising	O
out	O
of	O
this	O
evolution	O
are	O
resolved	O
using	O
linear	O
phase	O
correction	O
factors	O
(	O
i	O
.	O
e	O
.	O
,	O
slight	O
frequency	O
shifts	O
)	O
.	O
If	O
the	O
previous	O
and	O
current	O
frames	O
are	O
of	O
different	O
classes	O
(	O
e.g.	O
,	O
one	O
is	O
voiced	O
and	O
the	O
other	O
is	O
unvoiced	O
)	O
or	O
both	O
are	O
voiced	O
but	O
the	O
pitch	O
periods	O
are	O
quite	O
different	O
,	O
e.g.	O
,	O
doubling	O
,	O
the	O
two	O
frames	O
are	O
synthesized	O
independently	O
and	O
overlap-added	O
in	O
the	O
time-domain	O
.	O

While	O
the	O
invention	O
has	O
been	O
particularly	O
shown	O
and	O
described	O
with	O
reference	O
to	O
a	O
particular	O
embodiment	O
,	O
it	O
will	O
be	O
understood	O
by	O
those	O
skilled	O
in	O
the	O
art	O
that	O
various	O
changes	O
in	O
form	O
and	O
details	O
may	O
be	O
made	O
therein	O
without	O
departing	O
from	O
the	O
spirit	O
and	O
scope	O
of	O
the	O
invention	O
.	O
For	O
example	O
,	O
although	O
the	O
non-transmitted	O
MFCCs	O
were	O
derived	O
utilizing	O
a	O
pitch	O
period	O
and	O
a	O
lookup	O
table	O
,	O
in	O
alternate	O
embodiments	O
of	O
the	O
present	O
invention	O
the	O
non-transmitted	O
MFCCs	O
may	O
be	O
derived	O
in	O
any	O
number	O
of	O
ways	O
.	O
For	O
example	O
,	O
a	O
single	O
,	O
pre-stored	O
vector	O
can	O
be	O
utilized	O
for	O
the	O
missing	O
MFCCs	O
.	O
In	O
particular	O
,	O
the	O
mean	O
of	O
the	O
missing	O
MFCC	O
vectors	O
of	O
dimension	O
10	O
(	O
C13	O
through	O
C22	O
)	O
_	O
corresponding	O
to	O
the	O
“	O
voiced	O
”	O
frames	O
of	O
a	O
large	O
speech	O
database	O
can	O
be	O
computed	O
off-line	O
,	O
pre-stored	O
,	O
and	O
utilized	O
for	O
the	O
missing	O
MFCCs	O
during	O
speech	O
reconstruction	O
.	O

Additionally	O
the	O
missing	O
MFCCs	O
can	O
be	O
derived	O
from	O
the	O
transmitted	O
MFCCs	O
.	O
In	O
particular	O
,	O
the	O
transmitted	O
(	O
C0	O
through	O
C12	O
)	O
MFCC	O
values	O
(	O
which	O
have	O
been	O
quantized	O
)	O
,	O
and	O
the	O
missing	O
(	O
C13	O
through	O
C22	O
)	O
MFCC	O
values	O
(	O
which	O
have	O
not	O
been	O
quantized	O
)	O
of	O
all	O
the	O
“	O
voiced	O
”	O
frames	O
from	O
a	O
large	O
speech	O
database	O
can	O
be	O
gathered	O
and	O
partitioned	O
into	O
a	O
suitable	O
number	O
of	O
groups	O
H1	O
,	O
H2	O
,	O
.	O
.	O
.	O
,	O
HK	O
.	O
This	O
grouping	O
is	O
similar	O
to	O
the	O
“	O
voronoi	O
”	O
regions	O
in	O
a	O
vector	O
quantizer	O
and	O
uses	O
the	O
Euclidean	O
distance	O
measure	O
based	O
on	O
the	O
first	O
13	O
MFCC	O
values	O
(	O
C0	O
through	O
C12	O
)	O
.	O
That	O
is	O
,	O
a	O
MFCC	O
vector	O
(	O
C0	O
through	O
C22	O
)	O
belongs	O
to	O
a	O
group	O
Hk	O
if	O
and	O
only	O
if	O
the	O
13-dimensional	O
sub-vector	O
(	O
C0	O
through	O
C12	O
)	O
is	O
closer	O
(	O
in	O
terms	O
of	O
the	O
Euclidean	O
distance	O
measure	O
)	O
to	O
the	O
centroid	O
of	O
the	O
group	O
(	O
formed	O
by	O
taking	O
the	O
mean	O
of	O
all	O
the	O
13-dimensional	O
sub-vectors	O
belonging	O
to	O
the	O
group	O
)	O
than	O
the	O
centroid	O
of	O
any	O
other	O
group	O
.	O
A	O
technique	O
similar	O
to	O
the	O
design	O
of	O
a	O
vector	O
quantizer	O
can	O
be	O
used	O
to	O
form	O
these	O
groups	O
.	O
Since	O
the	O
first	O
MFCC	O
value	O
C0	O
approximately	O
represents	O
the	O
energy	O
of	O
the	O
frame	O
and	O
may	O
not	O
have	O
any	O
useful	O
information	O
regarding	O
the	O
missing	O
MFCCs	O
,	O
it	O
may	O
be	O
dropped	O
from	O
consideration	O
in	O
the	O
formation	O
of	O
the	O
groups	O
—	O
that	O
is	O
,	O
we	O
may	O
use	O
the	O
12-dimensional	O
sub-vectors	O
(	O
C1	O
through	O
C12	O
)	O
instead	O
of	O
the	O
13-dimensional	O
sub-vectors	O
(	O
C0	O
through	O
C12	O
)	O
while	O
forming	O
the	O
groups	O
.	O
Once	O
the	O
groups	O
have	O
been	O
formed	O
,	O
the	O
mean	O
of	O
the	O
10	O
dimensional	O
sub-vectors	O
(	O
C13	O
through	O
C22	O
)	O
corresponding	O
to	O
the	O
missing	O
MFCC	O
values	O
in	O
a	O
DSR	O
system	O
of	O
all	O
the	O
vectors	O
in	O
each	O
group	O
can	O
be	O
calculated	O
and	O
pre-stored	O
as	O
E1	O
,	O
E2	O
,	O
.	O
.	O
.	O
,	O
EK	O
.	O
For	O
speech	O
reconstruction	O
at	O
the	O
back-end	O
of	O
a	O
DSR	O
system	O
,	O
given	O
the	O
transmitted	O
MFCC	O
values	O
(	O
C0	O
through	O
C12	O
)	O
for	O
a	O
particular	O
frame	O
,	O
we	O
first	O
find	O
out	O
which	O
particular	O
group	O
it	O
belongs	O
to	O
(	O
say	O
Hk	O
)	O
,	O
and	O
then	O
use	O
the	O
corresponding	O
mean	O
vector	O
Ek	O
to	O
substitute	O
for	O
missing	O
MFCC	O
values	O
(	O
C13	O
through	O
C22	O
)	O
.	O
This	O
technique	O
which	O
uses	O
the	O
transmitted	O
MFCC	O
values	O
in	O
the	O
selection	O
of	O
the	O
missing	O
MFCC	O
values	O
can	O
be	O
combined	O
with	O
the	O
pitch	O
period	O
based	O
selection	O
technique	O
mentioned	O
earlier	O
.	O
That	O
is	O
,	O
we	O
first	O
use	O
the	O
pitch	O
period	O
range	O
to	O
form	O
suitable	O
groups	O
G1	O
,	O
G2	O
,	O
.	O
.	O
.	O
,	O
GM	O
of	O
23-dimensional	O
vectors	O
(	O
C0	O
through	O
C22	O
)	O
of	O
all	O
“	O
voiced	O
”	O
frames	O
from	O
a	O
large	O
speech	O
database	O
and	O
then	O
sub-divide	O
each	O
of	O
these	O
groups	O
further	O
based	O
on	O
the	O
transmitted	O
MFCC	O
values	O
.	O
For	O
example	O
,	O
the	O
group	O
Gm	O
will	O
be	O
sub-divided	O
into	O
the	O
groups	O
Gm	O
,	O
1	O
,	O
Gm	O
,	O
2	O
,	O
.	O
.	O
.	O
,	O
Gm	O
,	O
K	O
based	O
on	O
the	O
transmitted	O
MFCC	O
values	O
(	O
C0	O
through	O
C12	O
)	O
.	O
The	O
10-dimensional	O
mean	O
vectors	O
corresponding	O
to	O
C13	O
through	O
C22	O
of	O
all	O
the	O
sub-groups	O
totaling	O
M	O
*	O
K	O
are	O
pre-computed	O
and	O
stored	O
.	O
During	O
speech	O
reconstruction	O
,	O
the	O
pitch	O
period	O
value	O
P	O
and	O
the	O
transmitted	O
MFCC	O
values	O
(	O
C0	O
through	O
C12	O
)	O
are	O
both	O
used	O
in	O
selecting	O
the	O
appropriate	O
pre-stored	O
vector	O
to	O
substitute	O
for	O
the	O
missing	O
MFCC	O
values	O
(	O
C13	O
through	O
C22	O
)	O
.	O
It	O
is	O
intended	O
that	O
such	O
changes	O
come	O
within	O
the	O
scope	O
of	O
the	O
following	O
claims	O
.	O

1	O
.	O
A	O
method	O
for	O
speech	O
reconstruction	O
,	O
the	O
method	O
comprising	O
the	O
steps	O
of	O
:	O
receiving	O
a	O
first	O
plurality	O
of	O
Mel-frequency	O
cepstral	O
coefficients	O
(	O
MFCCs	O
)	O
;calculating	O
a	O
second	O
plurality	O
of	O
MFCCs	O
;	O
andutilizing	O
the	O
received	O
and	O
the	O
calculated	O
MFCCs	O
for	O
reconstructing	O
speech	O
.	O

2	O
.	O
The	O
method	O
of	O
claim	O
1	O
wherein	O
the	O
step	O
of	O
utilizing	O
the	O
received	O
and	O
the	O
calculated	O
MFCCs	O
for	O
reconstructing	O
speech	O
comprises	O
the	O
steps	O
of	O
:	O
transforming	O
the	O
received	O
and	O
the	O
calculated	O
MFCCs	O
into	O
harmonic	O
magnitudes	O
;	O
andutilizing	O
the	O
harmonic	O
magnitudes	O
for	O
reconstructing	O
the	O
speech	O
.	O

3	O
.	O
The	O
method	O
of	O
claim	O
1	O
wherein	O
the	O
step	O
of	O
receiving	O
the	O
first	O
plurality	O
of	O
MFCCs	O
comprises	O
the	O
step	O
of	O
receiving	O
coefficients	O
C0	O
–	O
C12	O
.	O

4	O
.	O
The	O
method	O
of	O
claim	O
3	O
wherein	O
the	O
step	O
of	O
calculating	O
the	O
second	O
plurality	O
of	O
MFCCs	O
comprises	O
the	O
step	O
of	O
calculating	O
coefficients	O
C13	O
through	O
C22	O
.	O

5	O
.	O
The	O
method	O
of	O
claim	O
4	O
wherein	O
the	O
step	O
of	O
utilizing	O
the	O
received	O
and	O
the	O
calculated	O
MFCCs	O
for	O
reconstructing	O
speech	O
comprises	O
the	O
steps	O
of	O
:	O
transforming	O
coefficients	O
C0	O
through	O
C22	O
into	O
harmonic	O
magnitudes	O
;	O
andutilizing	O
the	O
harmonic	O
magnitudes	O
for	O
reconstructing	O
the	O
speech	O
.	O

6	O
.	O
The	O
method	O
of	O
claim	O
1	O
wherein	O
the	O
step	O
of	O
receiving	O
the	O
first	O
plurality	O
of	O
MFCCs	O
comprises	O
the	O
step	O
of	O
receiving	O
the	O
first	O
plurality	O
of	O
MFCCs	O
via	O
an	O
over-the-air	O
communication	O
link	O
.	O

7	O
.	O
The	O
method	O
of	O
claim	O
1	O
further	O
comprising	O
the	O
step	O
of	O
:	O
receiving	O
a	O
pitch	O
period	O
along	O
with	O
the	O
first	O
plurality	O
of	O
MFCCs	O
.	O

8	O
.	O
The	O
method	O
of	O
claim	O
1	O
wherein	O
the	O
step	O
of	O
calculating	O
the	O
second	O
plurality	O
of	O
MFCCs	O
comprises	O
the	O
step	O
of	O
calculating	O
the	O
second	O
plurality	O
of	O
MFCCs	O
,	O
wherein	O
the	O
second	O
plurality	O
of	O
MFCCs	O
are	O
based	O
on	O
the	O
pitch	O
period	O
.	O

9	O
.	O
The	O
method	O
of	O
claim	O
1	O
wherein	O
the	O
step	O
of	O
calculating	O
the	O
second	O
plurality	O
of	O
MFCCs	O
comprises	O
the	O
step	O
of	O
utilizing	O
a	O
single	O
,	O
pre-stored	O
vector	O
for	O
the	O
second	O
plurality	O
of	O
MFCCs	O
.	O

10	O
.	O
The	O
method	O
of	O
claim	O
1	O
wherein	O
the	O
step	O
of	O
calculating	O
the	O
second	O
plurality	O
of	O
MFCCs	O
comprises	O
the	O
step	O
of	O
deriving	O
the	O
second	O
plurality	O
of	O
MFCCs	O
from	O
the	O
first	O
plurality	O
of	O
MFCCs	O
.	O

11	O
.	O
A	O
method	O
for	O
speech	O
reconstruction	O
,	O
the	O
method	O
comprising	O
the	O
steps	O
of	O
:	O
receiving	O
Mel-frequency	O
cepstral	O
coefficients	O
C0	O
–	O
C12;calculating	O
Mel-frequency	O
cepstral	O
coefficients	O
C13	O
–	O
C22	O
;	O
andutilizing	O
coefficients	O
C0	O
–	O
C22	O
for	O
reconstructing	O
speech	O
.	O

12	O
.	O
The	O
method	O
of	O
claim	O
11	O
wherein	O
the	O
step	O
of	O
utilizing	O
coefficients	O
C0	O
–	O
C22	O
for	O
reconstructing	O
speech	O
comprises	O
the	O
steps	O
of	O
:	O
transforming	O
the	O
coefficients	O
C0	O
–	O
C22	O
into	O
harmonic	O
magnitudes	O
;	O
andutilizing	O
the	O
harmonic	O
magnitudes	O
for	O
reconstructing	O
the	O
speech	O
.	O

13	O
.	O
The	O
method	O
of	O
claim	O
11	O
wherein	O
the	O
step	O
of	O
receiving	O
coefficients	O
C0	O
–	O
C12	O
comprises	O
the	O
step	O
of	O
receiving	O
coefficients	O
C0	O
–	O
C12	O
via	O
an	O
over-the-air	O
communication	O
link	O
.	O

14	O
.	O
The	O
method	O
of	O
claim	O
11	O
further	O
comprising	O
the	O
step	O
of	O
:	O
receiving	O
a	O
pitch	O
period	O
along	O
with	O
coefficients	O
C0	O
–	O
C12	O
.	O

15	O
.	O
The	O
method	O
of	O
claim	O
14	O
wherein	O
the	O
step	O
of	O
calculating	O
coefficients	O
C13	O
–	O
C22	O
comprises	O
the	O
step	O
of	O
calculating	O
coefficients	O
C13	O
–	O
C22	O
based	O
on	O
the	O
pitch	O
period	O
.	O

16	O
.	O
The	O
method	O
of	O
claim	O
11	O
wherein	O
the	O
step	O
of	O
calculating	O
coefficients	O
C13	O
–	O
C22	O
comprises	O
the	O
step	O
of	O
utilizing	O
a	O
single	O
,	O
pre-stored	O
vector	O
for	O
coefficients	O
C13	O
–	O
C22	O
.	O

17	O
.	O
The	O
method	O
of	O
claim	O
11	O
wherein	O
the	O
step	O
of	O
calculating	O
coefficients	O
C13	O
–	O
C22	O
comprises	O
the	O
step	O
of	O
deriving	O
coefficients	O
C13	O
–	O
C22	O
from	O
the	O
coefficients	O
C0	O
–	O
C12	O
.	O

18	O
.	O
An	O
apparatus	O
comprising	O
:	O
a	O
receiver	O
receiving	O
a	O
first	O
plurality	O
of	O
Mel-frequency	O
cepstral	O
coefficients	O
(	O
MFCCs	O
)	O
;	O
a	O
MFCC	O
reconstructor	O
calculating	O
a	O
second	O
plurality	O
of	O
MFCCs	O
;	O
anda	O
speech	O
processor	O
utilizing	O
the	O
received	O
and	O
the	O
calculated	O
MFCCs	O
for	O
reconstructing	O
speech	O
.	O

19	O
.	O
The	O
apparatus	O
of	O
claim	O
18	O
wherein	O
the	O
receiver	O
is	O
a	O
radio-frequency	O
(	O
RF	O
)	O
receiver	O
.	O

20	O
.	O
The	O
apparatus	O
of	O
claim	O
18	O
wherein	O
:	O
the	O
first	O
plurality	O
of	O
MFCCs	O
comprise	O
coefficients	O
C0	O
–	O
C12	O
;	O
andthe	O
second	O
plurality	O
of	O
MFCCs	O
comprise	O
coefficients	O
C13	O
–	O
C22	O
.	O

