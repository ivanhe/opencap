US	O
6907398	O
B2	O
20050614	O

US	O
09946783	O
20010906	O

09	O
eng	O
eng	O

DE	O
10043946	O
20000906	O

20050614	O

20050614	O

563	O

7G	O
10L	O
15/14	O
A	O
7	O
G	O
10	O
L	O
15	O
14	O
A	O

G10L	O
15/00	O
20060101C	O
I20051008RMEP	O

20060101	O

C	O
G	O
10	O
L	O
15	O
00	O
I	O

20051008	O

EP	O

R	O
M	O

G10L	O
15/14	O
20060101A	O
N20051008RMEP	O

20060101	O

A	O
G	O
10	O
L	O
15	O
14	O
N	O

20051008	O

EP	O

R	O
M	O

G10L	O
15/16	O
20060101A	O
I20051008RMEP	O

20060101	O

A	O
G	O
10	O
L	O
15	O
16	O
I	O

20051008	O

EP	O

R	O
M	O

H03M	O
7/30	O
20060101C	O
I20051008RMEP	O

20060101	O

C	O
H	O
03	O
M	O
7	O
30	O
I	O

20051008	O

EP	O

R	O
M	O

H03M	O
7/30	O
20060101A	O
I20051008RMEP	O

20060101	O

A	O
H	O
03	O
M	O
7	O
30	O
I	O

20051008	O

EP	O

R	O
M	O

US	O

704/265	O
704	O
265	O

704/200	O
704	O
200	O

704/232	O
704	O
232	O

704/238	O
704	O
238	O

704/251	O
704	O
251	O

704/270	O
704	O
270	O

704/E15.017	O
704	O
E15	O
.	O
017	O

G10L	O
15/16	O
G	O
10	O
L	O
15	O
16	O

H03M	O
7/30	O
H	O
03	O
M	O
7	O
30	O

S10L	O
15	O
:	O
14M1	O
S	O
10	O
L	O
15	O
14	O

M	O
1	O

US	O

704/256	O
704	O
256	O

US	O

704/232	O
704	O
232	O

US	O

704/251	O
704	O
251	O

US	O

704/254	O
704	O
254	O

US	O

704/236	O
704	O
236	O

US	O

704/253	O
704	O
253	O

US	O

704/200	O
704	O
200	O

US	O

704/270	O
704	O
270	O

US	O

704/238	O
704	O
238	O

US	O

395/265	O
395	O
265	O

US	O

395/241	O
395	O
241	O

US	O

382/253	O
382	O
253	O

US	O

382/187	O
382	O
187	O

US	O

382/186	O
382	O
186	O

US	O

706/16	O
706	O
16	O

9	O
Compressing	O
HMM	O
prototypes	O

US	O
5535305	O
A	O
Acero	O
et_al.	O

19960709	O

19921231	O

US	O
5644652	O
A	O
Bellegarda	O
et_al.	O

19970701	O

19950419	O

US	O
5696877	O
A	O
Iso	O
19971209	O

19931130	O

US	O
5732388	O
A	O
Hoege	O
et_al.	O

19980324	O

19960111	O

US	O
5737486	O
A	O
Iso	O
19980407	O

19950504	O

US	O
5758021	O
A	O
Hackbarth	O
19980526	O

19920910	O

US	O
6029135	O
A	O
Krasle	O
20000222	O

19951114	O

US	O
6052481	O
A	O
Grajski	O
et_al.	O

20000418	O

19940902	O

US	O
6076053	O
A	O
Juang	O
et_al.	O

20000613	O

19980521	O

US	O
6151414	O
A	O
Lee	O
et_al.	O

20001121	O

19980130	O

US	O
6151592	O
A	O
Inazumi	O
20001121	O

19980120	O

US	O
6178398	O
B1	O
Peterson	O
et_al.	O

20010123	O

19971118	O

US	O
20010014858	O
A1	O
Hirayama	O
20010816	O

20010223	O

DE	O
19636739	O
C1	O
19970703	O

19960910	O

DE	O
19719381	O
C1	O
19980122	O

19970507	O

DE	O
69421354	O
T2	O
20000713	O

19940901	O

EP	O
709826	O
A1	O
19960501	O

19951026	O

EP	O
642117	O
B1	O
19991027	O

19940901	O

Bourlard	B-Citation
et_al.	I-Citation
,	I-Citation
“	I-Citation
Auto-Association	I-Citation
by	I-Citation
Multilayer	I-Citation
Perceptrons	I-Citation
and	I-Citation
Singular	I-Citation
Value	I-Citation
Decompositions	I-Citation
”	I-Citation
,	I-Citation
Biological	I-Citation
Cybernetics	I-Citation
,	I-Citation
Springer	I-Citation
Verlag	I-Citation
,	I-Citation
Berlin	I-Citation
,	I-Citation
59	I-Citation
.	I-Citation
pp.	I-Citation
291	I-Citation
-	I-Citation
294	I-Citation
,	I-Citation
1988	I-Citation
.	O

Gopinath	B-Citation
,	I-Citation
“	I-Citation
Maximum	I-Citation
Likelihood	I-Citation
Modeling	I-Citation
with	I-Citation
Gaussian	I-Citation
Distributions	I-Citation
for	I-Citation
Classification	I-Citation
”	I-Citation
,	I-Citation
Proceedings	I-Citation
of	I-Citation
the	I-Citation
1998	I-Citation
IEEE	I-Citation
International	I-Citation
Conference	I-Citation
on	I-Citation
Acoustics	I-Citation
,	I-Citation
Speech	I-Citation
and	I-Citation
Signal	I-Citation
Processing	I-Citation
,	I-Citation
ICASSP	I-Citation
'98	I-Citation
(	I-Citation
CAT	I-Citation
No.	I-Citation
98CH36181	I-Citation
)	I-Citation
,	I-Citation
Seattle	I-Citation
,	I-Citation
WA	I-Citation
,	I-Citation
USA	I-Citation
,	I-Citation
12	I-Citation
-	I-Citation
1	I-Citation
,	I-Citation
pp.	I-Citation
661	I-Citation
-	I-Citation
664	I-Citation
,	I-Citation
vol.	I-Citation
2	I-Citation
,	I-Citation
1998	I-Citation
,	I-Citation
New	I-Citation
York	I-Citation
,	I-Citation
NY	I-Citation
,	I-Citation
USA	I-Citation
,	I-Citation
IEEE	I-Citation
USA	I-Citation
.	O

US	O
7778831	O
B2	O
20100817	O

20060221	O

US	O
7970613	O
B2	O
20110628	O

20051112	O

US	O
8010358	O
B2	O
20110830	O

20060221	O

US	O
20020046031	O
A1	O
20020418	O

Siemens	O
Aktiengesellschaft	O
03	O

Munich	O
DE	O

Hoege	O
Harald	O

Gauting	O
DE	O

DE	O

DE	O

Staas	O
&	O
Halsey	O
LLP	O

Ometz	O
David	O
L.	O

2655	O

Jackson	O
Jakieda	O
R	O

US	O
20020046031	O
A1	O
20020418	O

20010906	O

DE	O
10043946	O
C2	O
20021212	O

20000906	O

EP	O
1187098	O
A3	O
20030122	O

20010809	O

EP	O
1187098	O
A2	O
20020313	O

20010809	O

DE	O
10043946	O
A1	O
20020829	O

20000906	O

DE	O
50111184	O
D1	O
20061123	O

20010809	O

US	O
6907398	O
B2	O
20050614	O

20010906	O

EP	O
1187098	O
B1	O
20061011	O

20010809	O

ES	O
2270930	O
T3	O
20070416	O

20010809	O

EP	O
1187098	O
A3	O
20030122	O

20010809	O

EP	O
1187098	O
A2	O
20020313	O

20010809	O

DE	O
10043946	O
A1	O
20020829	O

20000906	O

DE	O
10043946	O
C2	O
20021212	O

20000906	O

US	O
6907398	O
B2	O
20050614	O

20010906	O

DE	O
50111184	O
D1	O
20061123	O

20010809	O

US	O
20020046031	O
A1	O
20020418	O

20010906	O

EP	O
1187098	O
B1	O
20061011	O

20010809	O

ES	O
2270930	O
T3	O
20070416	O

20010809	O

A	O
method	O
is	O
described	O
for	O
compressing	O
the	O
storage	O
space	O
required	O
by	O
HMM	O
prototypes	O
in	O
an	O
electronic	O
memory	O
.	O
For	O
this	O
purpose	O
prescribed	O
HMM	O
prototypes	O
are	O
mapped	O
onto	O
compressed	O
HMM	O
prototypes	O
with	O
the	O
aid	O
of	O
a	O
neural	O
network	O
(	O
encoder	O
)	O
.	O
These	O
can	O
be	O
stored	O
with	O
a	O
smaller	O
storage	O
space	O
than	O
the	O
uncompressed	O
HMM	O
prototypes	O
.	O
A	O
second	O
neural	O
network	O
(	O
decoder	O
)	O
serves	O
to	O
reconstruct	O
the	O
HMM	O
prototypes	O
.	O

20011012	O

AS	O
ASSIGNMENT	O
N	O
US	O
6907398B2	O
SIEMENS	O
AKTIENGESELLSCHAFT	O
,	O
GERMANY	O
ASSIGNMENT	O
OF	O
ASSIGNORS	O
INTEREST;ASSIGNOR:HOEGE	O
,	O
HARALD;REEL/FRAME:012247/0005	O

20010913	O

20011218	O

AS	O
ASSIGNMENT	O
N	O
US	O
6907398B2	O
DEGUSSA	O
AG	O
,	O
GERMANY	O
ASSIGNMENT	O
OF	O
ASSIGNORS	O
INTEREST;ASSIGNORS:FARWICK	O
,	O
MIKE;HUTHMACHER	O
,	O
KLAUS;PFEFFERLE	O
,	O
WALTER	O
;	O
AND	O
OTHERS;REEL/FRAME:012670/0438;SIGNING	O
DATES	O
FROM	O
20011010	O
TO	O
20011112	O

20060801	O

CC	O
CERTIFICATE	O
OF	O
CORRECTION	O
C	O
US	O
6907398B2	O

20060912	O

CC	O
CERTIFICATE	O
OF	O
CORRECTION	O
C	O
US	O
6907398B2	O

20081110	O

FPAY	O
+	O
FEE	O
PAYMENT	O
N	O
US	O
6907398B2	O
4	O

CROSS	O
REFERENCE	O
TO	O
RELATED	O
APPLICATION	O
This	O
application	O
is	O
based	O
on	O
and	O
hereby	O
claims	O
priority	O
to	O
German	O
Application	O
No.	O
100	O
43	O
946	O
.	O
2	O
filed	O
on	O
Sep.	O
6	O
,	O
2000	O
in	O
Germany	O
,	O
the	O
contents	O
of	O
which	O
are	O
hereby	O
incorporated	O
by	O
reference	O
.	O

BACKGROUND	O
OF	O
THE	O
INVENTION	O
The	O
invention	O
relates	O
to	O
a	O
method	O
,	O
a	O
computer	O
program	O
and	O
a	O
data	O
medium	O
for	O
compressing	O
the	O
storage	O
space	O
required	O
by	O
Hidden	O
Markov	O
Model	O
“	O
HMM	O
”	O
prototypes	O
in	O
an	O
electronic	O
memory	O
,	O
and	O
to	O
a	O
system	O
for	O
automatic	O
speech	O
recognition	O
.	O

Speech	O
processing	O
methods	O
are	O
disclosed	O
,	O
for	O
example	O
,	O
in	O
U.S.	O
Pat	O
.	O
No.	O
6	O
,	O
029	O
,	O
135	O
,	O
U.S.	O
Pat	O
.	O
No.	O
5	O
,	O
732	O
,	O
388	O
,	O
DE	O
19636739	O
C1	O
and	O
DE	O
19719381	O
C1	O
.	O
In	O
this	O
case	O
,	O
naturally	O
spoken	O
speech	O
has	O
recently	O
been	O
described	O
as	O
a	O
rule	O
by	O
what	O
are	O
termed	O
Hidden	O
Markov	O
Models	O
(	O
HMMs	O
)	O
for	O
the	O
purpose	O
of	O
automatic	O
speech	O
recognition	O
.	O
In	O
Hidden	O
Markov	O
Models	O
,	O
the	O
term	O
“	O
emission	O
probability	O
”	O
denotes	O
the	O
probability	O
that	O
the	O
model	O
belonging	O
to	O
class	O
k	O
emits	O
or	O
generates	O
an	O
actually	O
spoken	O
sound	O
or	O
an	O
actually	O
spoken	O
sound	O
sequence	O
.	O
Here	O
,	O
the	O
class	O
k	O
can	O
be	O
,	O
for	O
example	O
,	O
a	O
sound	O
,	O
a	O
sound	O
sequence	O
,	O
or	O
a	O
word	O
or	O
word	O
sequence	O
.	O
An	O
HMM	O
prototype	O
is	O
the	O
mean	O
value	O
of	O
the	O
associated	O
emission	O
probability	O
distribution	O
.	O
They	O
are	O
obtained	O
from	O
speech	O
recordings	O
.	O

The	O
prototypes	O
are	O
yielded	O
from	O
the	O
recorded	O
sound	O
spectra	O
after	O
decomposition	O
into	O
individual	O
spectral	O
features	O
and	O
further	O
mathematical	O
transformations	O
.	O
They	O
comprise	O
a	O
number	O
of	O
real	O
numbers	O
,	O
the	O
components	O
and	O
can	O
therefore	O
be	O
regarded	O
as	O
vectors	O
.	O
The	O
individual	O
components	O
are	O
of	O
different	O
importance	O
as	O
regards	O
the	O
identification	O
or	O
assignment	O
to	O
certain	O
sounds	O
.	O

High-performance	O
recognizers	O
are	O
dependent	O
on	O
Hidden	O
Markov	O
Models	O
with	O
many	O
prototypes	O
.	O
The	O
storage	O
space	O
required	O
to	O
store	O
the	O
prototypes	O
generally	O
rises	O
in	O
proportion	O
to	O
the	O
number	O
of	O
prototypes	O
.	O
In	O
the	O
best	O
current	O
detectors	O
,	O
a	O
prototype	O
comprises	O
10	O
to	O
40	O
components	O
.	O
Each	O
component	O
is	O
represented	O
by	O
1	O
to	O
4	O
bytes	O
.	O

Whole	O
word	O
recognizers	O
decompose	O
the	O
words	O
into	O
arbitrary	O
phonetic	O
units	O
for	O
which	O
prototypes	O
are	O
created	O
.	O
They	O
manage	O
with	O
relatively	O
few	O
prototypes	O
,	O
for	O
example	O
,	O
1000	O
to	O
2000	O
in	O
the	O
case	O
of	O
a	O
vocabulary	O
of	O
10	O
to	O
50	O
words	O
.	O
Because	O
of	O
the	O
small	O
vocabulary	O
,	O
they	O
are	O
used	O
for	O
special	O
applications	O
such	O
as	O
number	O
recognition	O
or	O
navigation	O
in	O
a	O
menu	O
.	O

Type-in	O
recognizers	O
assign	O
prototypes	O
exactly	O
to	O
individual	O
sounds	O
.	O
They	O
require	O
4000	O
to	O
10	O
000	O
prototypes	O
,	O
it	O
being	O
possible	O
to	O
assign	O
100	O
and	O
more	O
prototypes	O
to	O
each	O
sound	O
.	O
The	O
use	O
of	O
a	O
type-in	O
recognizer	O
is	O
advantageous	O
in	O
many	O
applications	O
,	O
since	O
the	O
vocabulary	O
to	O
be	O
recognized	O
can	O
be	O
kept	O
variable	O
there	O
.	O

The	O
storage	O
requirement	O
for	O
a	O
type-in	O
recognizer	O
is	O
on	O
the	O
order	O
of	O
magnitude	O
of	O
40	O
to	O
1600	O
kilobytes	O
.	O
The	O
available	O
storage	O
space	O
is	O
very	O
limited	O
,	O
in	O
particular	O
in	O
the	O
case	O
of	O
mobile	O
consumer	O
terminals	O
(	O
for	O
example	O
,	O
mobile	O
phones	O
,	O
Palm	O
Pilots	O
,	O
etc	O
.	O
)	O
;	O
at	O
present	O
,	O
it	O
is	O
substantially	O
below	O
100	O
kilobytes	O
,	O
since	O
the	O
costs	O
of	O
the	O
memory	O
and	O
the	O
power	O
loss	O
caused	O
by	O
the	O
memory	O
constitute	O
limiting	O
factors	O
.	O
Methods	O
which	O
permit	O
a	O
drastic	O
compression	O
of	O
the	O
storage	O
requirement	O
are	O
required	O
in	O
order	O
to	O
be	O
able	O
to	O
implement	O
high-performance	O
type-in	O
recognizers	O
for	O
consumer	O
terminals	O
,	O
as	O
well	O
.	O

SUMMARY	O
OF	O
THE	O
INVENTION	O
It	O
is	O
one	O
possible	O
object	O
of	O
the	O
invention	O
to	O
permit	O
the	O
storage	O
space	O
required	O
by	O
HMM	O
prototypes	O
in	O
an	O
electronic	O
memory	O
to	O
be	O
reduced	O
by	O
compression	O
.	O

The	O
object	O
may	O
be	O
achieved	O
by	O
a	O
method	O
,	O
a	O
computer	O
program	O
,	O
and	O
a	O
data	O
medium	O
for	O
compressing	O
the	O
storage	O
space	O
required	O
by	O
HMM	O
prototypes	O
in	O
an	O
electronic	O
memory	O
.	O

The	O
computer	O
program	O
may	O
be	O
embodied	O
as	O
a	O
commercial	O
product	O
in	O
whatever	O
form	O
,	O
for	O
example	O
,	O
on	O
paper	O
,	O
on	O
a	O
computer-readable	O
data	O
medium	O
,	O
distributed	O
over	O
a	O
network	O
,	O
etc	O
.	O

The	O
first	O
step	O
is	O
to	O
prescribe	O
HMM	O
prototypes	O
Xj	O
,	O
(	O
j	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
J	O
)	O
,	O
with	O
the	O
components	O
Xjk	O
,	O
(	O
k	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
N	O
)	O
,	O
J	O
and	O
N	O
being	O
natural	O
numbers	O
.	O
As	O
mentioned	O
at	O
the	O
beginning	O
,	O
although	O
not	O
limited	O
,	O
typical	O
values	O
for	O
J	O
are	O
1000	O
or	O
10	O
000	O
,	O
also	O
100	O
000	O
in	O
the	O
case	O
of	O
extremely	O
high-power	O
recognizers	O
.	O
As	O
mentioned	O
above	O
,	O
N	O
is	O
generally	O
between	O
10	O
and	O
40	O
.	O
The	O
HMM	O
prototypes	O
Xj	O
are	O
mapped	O
(	O
coded	O
)	O
onto	O
compressed	O
HMM	O
prototypes	O
Yj	O
,	O
a	O
(	O
j	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
J	O
)	O
Yj	O
having	O
the	O
components	O
Yjm	O
,	O
(	O
m	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
M	O
)	O
,	O
M	O
being	O
a	O
natural	O
number	O
.	O
The	O
Yj	O
are	O
codings	O
of	O
the	O
Xj	O
optimized	O
toward	O
low	O
storage	O
space	O
.	O

There	O
remains	O
a	O
need	O
for	O
a	O
decoder	O
which	O
reconstructs	O
the	O
Xj	O
from	O
the	O
Yj	O
,	O
at	O
least	O
approximately	O
.	O
A	O
neural	O
network	O
(	O
decoder	O
)	O
is	O
provided	O
for	O
this	O
purpose	O
.	O
The	O
neural	O
network	O
maps	O
(	O
decodes	O
)	O
the	O
Yj	O
onto	O
the	O
reconstructed	O
HMM	O
prototypes	O
X	O
′	O
j	O
(	O
j	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
J	O
)	O
,	O
with	O
the	O
components	O
X	O
′	O
jk	O
,	O
(	O
k	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
N	O
)	O
.	O
The	O
X	O
′	O
j	O
are	O
the	O
reconstructions	O
of	O
the	O
Xj	O
.	O

The	O
compressed	O
HMM	O
prototypes	O
Yj	O
thus	O
form	O
an	O
associative	O
memory	O
for	O
the	O
HMM	O
prototypes	O
Xj	O
together	O
with	O
the	O
decoder	O
.	O

In	O
order	O
to	O
achieve	O
an	O
optimal	O
compression	O
of	O
the	O
HMM	O
prototypes	O
,	O
the	O
Yj	O
and	O
the	O
decoder	O
are	O
selected	O
in	O
such	O
a	O
way	O
that	O
,	O
on	O
the	O
one	O
hand	O
,	O
the	O
spacing	O
between	O
Xj	O
and	O
X	O
′	O
j	O
is	O
minimized	O
,	O
andthat	O
,	O
on	O
the	O
other	O
hand	O
,	O
the	O
storage	O
space	O
required	O
for	O
the	O
YJ	O
and	O
the	O
decoder	O
in	O
an	O
electronic	O
memory	O
is	O
minimized	O
.	O

Using	O
the	O
compression	O
according	O
to	O
one	O
aspect	O
of	O
the	O
invention	O
,	O
a	O
recognizer	O
,	O
for	O
example	O
in	O
a	O
mobile	O
phone	O
,	O
is	O
required	O
to	O
store	O
only	O
the	O
compressed	O
HMM	O
prototypes	O
Yj	O
and	O
the	O
structure	O
and	O
the	O
weights	O
of	O
the	O
decoder	O
in	O
the	O
form	O
of	O
a	O
neural	O
network	O
.	O

In	O
order	O
to	O
permit	O
flexible	O
optimization	O
of	O
the	O
coding	O
,	O
as	O
well	O
,	O
an	O
encoder	O
can	O
be	O
provided	O
for	O
mapping	O
(	O
coding	O
)	O
the	O
HMM	O
prototypes	O
Xj	O
onto	O
the	O
compressed	O
HMM	O
prototypes	O
Yj	O
.	O
In	O
an	O
advantageous	O
development	O
of	O
one	O
aspect	O
of	O
the	O
invention	O
,	O
a	O
neural	O
network	O
can	O
be	O
selected	O
as	O
the	O
encoder	O
.	O

Only	O
binary	O
numbers	O
are	O
suitable	O
for	O
the	O
purpose	O
of	O
storing	O
the	O
compressed	O
HMM	O
prototypes	O
YJ	O
.	O
Consequently	O
,	O
the	O
YJm	O
generated	O
are	O
converted	O
into	O
binary	O
numbers	O
YQjm	O
,	O
(	O
j	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
J	O
)	O
,	O
(	O
m	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
M	O
)	O
.	O
The	O
Yjm	O
are	O
real	O
numbers	O
if	O
the	O
encoder	O
is	O
designed	O
in	O
the	O
form	O
of	O
a	O
neural	O
network	O
.	O
The	O
interposition	O
of	O
a	O
bit	O
encoder	O
is	O
then	O
to	O
be	O
recommended	O
.	O
If	O
the	O
coding	O
is	O
not	O
carried	O
out	O
with	O
the	O
aid	O
of	O
a	O
neural	O
network	O
,	O
the	O
direct	O
mapping	O
of	O
the	O
Xjk	O
into	O
binary	O
numbers	O
Yjm	O
can	O
therefore	O
be	O
performed	O
.	O
The	O
structure	O
and	O
parameters	O
of	O
the	O
neural	O
network	O
operating	O
as	O
the	O
decoder	O
can	O
be	O
selected	O
in	O
such	O
a	O
way	O
that	O
the	O
decoder	O
can	O
map	O
the	O
binary	O
numbers	O
YQjm	O
onto	O
the	O
X	O
′	O
jk	O
.	O
Overall	O
,	O
the	O
structure	O
and	O
parameters	O
of	O
the	O
encoder	O
,	O
the	O
bit	O
encoder	O
and	O
the	O
decoder	O
are	O
selected	O
in	O
such	O
a	O
way	O
that	O
the	O
binary	O
numbers	O
YQjm	O
,	O
have	O
as	O
few	O
bits	O
as	O
possible	O
,	O
in	O
order	O
to	O
achieve	O
the	O
goal	O
of	O
optimal	O
compression	O
and	O
thus	O
a	O
low	O
storage	O
requirement	O
.	O
The	O
YQjm	O
has	O
only	O
1	O
bit	O
in	O
the	O
ideal	O
case	O
.	O

In	O
the	O
extreme	O
case	O
the	O
Yj	O
has	O
only	O
a	O
single	O
component	O
,	O
that	O
is	O
to	O
say	O
M	O
=	O
1	O
.	O
In	O
addition	O
,	O
YQj1	O
,	O
can	O
basically	O
be	O
set	O
to	O
1	O
.	O
The	O
Yj	O
themselves	O
then	O
need	O
not	O
be	O
stored	O
any	O
longer	O
.	O
They	O
then	O
simply	O
correspond	O
in	O
each	O
case	O
to	O
an	O
input	O
node	O
of	O
the	O
neural	O
network	O
of	O
the	O
decoder	O
.	O
Only	O
the	O
number	O
J	O
of	O
the	O
required	O
HMM	O
prototypes	O
is	O
prescribed	O
for	O
the	O
neural	O
network	O
of	O
the	O
decoder	O
in	O
order	O
to	O
reconstruct	O
the	O
HMM	O
prototypes	O
.	O

The	O
training	O
of	O
the	O
neural	O
network	O
operating	O
as	O
the	O
decoder	O
is	O
performed	O
by	O
the	O
Yj	O
at	O
the	O
inputs	O
and	O
Xj	O
at	O
the	O
outputs	O
.	O
The	O
numbers	O
X	O
′	O
j	O
generated	O
by	O
the	O
neural	O
network	O
are	O
examined	O
as	O
to	O
their	O
distance	O
from	O
the	O
Xj	O
.	O
In	O
this	O
case	O
,	O
the	O
distance	O
can	O
be	O
a	O
Euclidean	O
measure	O
in	O
the	O
vector	O
space	O
of	O
the	O
XJ	O
,	O
for	O
example	O
.	O
An	O
improved	O
decompression	O
accuracy	O
is	O
achieved	O
when	O
the	O
components	O
with	O
the	O
higher	O
ability	O
to	O
discriminate	O
are	O
weighted	O
more	O
heavily	O
in	O
order	O
to	O
determine	O
the	O
spacing	O
between	O
the	O
Xj	O
and	O
the	O
X	O
′	O
j	O
.	O
The	O
ability	O
to	O
discriminate	O
a	O
component	O
is	O
the	O
importance	O
of	O
this	O
component	O
for	O
deciding	O
on	O
the	O
assignment	O
(	O
classification	O
)	O
of	O
a	O
recorded	O
sound	O
to	O
the	O
HMM	O
prototype	O
to	O
which	O
the	O
component	O
belongs	O
.	O

The	O
object	O
could	O
possibly	O
also	O
be	O
achieved	O
,	O
furthermore	O
,	O
by	O
a	O
system	O
for	O
automatic	O
speech	O
recognition	O
which	O
has	O
a	O
neural	O
network	O
for	O
calculating	O
speech	O
patterns	O
,	O
for	O
example	O
HMM	O
prototypes	O
.	O
Furthermore	O
,	O
the	O
system	O
has	O
an	O
input	O
for	O
a	O
speech	O
signal	O
.	O
As	O
a	O
rule	O
,	O
this	O
is	O
a	O
transformed	O
recording	O
of	O
a	O
sound	O
.	O
In	O
order	O
to	O
recognize	O
the	O
input	O
speech	O
signal	O
,	O
a	O
recognizer	O
uses	O
the	O
output	O
values	O
of	O
the	O
neural	O
network	O
as	O
the	O
speech	O
pattern	O
.	O
The	O
results	O
of	O
the	O
recognizer	O
are	O
output	O
via	O
an	O
output	O
in	O
the	O
form	O
of	O
a	O
signal	O
which	O
corresponds	O
to	O
the	O
recognized	O
speech	O
signal	O
.	O
The	O
system	O
can	O
be	O
part	O
of	O
a	O
mobile	O
phone	O
,	O
a	O
handheld	O
computer	O
,	O
a	O
microcomputer	O
,	O
a	O
notebook	O
,	O
a	O
computer	O
or	O
the	O
like	O
.	O

The	O
system	O
also	O
includes	O
permanent	O
or	O
removable	O
storage	O
,	O
such	O
as	O
magnetic	O
and	O
optical	O
discs	O
,	O
RAM	O
,	O
ROM	O
,	O
etc	O
.	O
on	O
which	O
the	O
process	O
and	O
data	O
structures	O
of	O
the	O
present	O
invention	O
can	O
be	O
stored	O
and	O
distributed	O
.	O
The	O
processes	O
can	O
also	O
be	O
distributed	O
via	O
,	O
for	O
example	O
,	O
downloading	O
over	O
a	O
network	O
such	O
as	O
the	O
Internet	O
.	O

If	O
the	O
compressed	O
HMM	O
prototypes	O
Yj	O
mentioned	O
at	O
the	O
beginning	O
are	O
not	O
each	O
assigned	O
immediately	O
to	O
an	O
input	O
node	O
of	O
the	O
neural	O
network	O
operating	O
as	O
decoder	O
,	O
the	O
system	O
may	O
also	O
have	O
a	O
memory	O
for	O
storing	O
compressed	O
speech	O
patterns	O
Yj	O
for	O
example	O
for	O
storing	O
compressed	O
HMM	O
prototypes	O
.	O
The	O
Yj	O
serve	O
as	O
inputs	O
for	O
the	O
inputs	O
of	O
the	O
neural	O
network	O
.	O

BRIEF	O
DESCRIPTION	O
OF	O
THE	O
DRAWINGS	O
These	O
and	O
other	O
objects	O
and	O
advantages	O
of	O
the	O
present	O
invention	O
will	O
become	O
more	O
apparent	O
and	O
more	O
readily	O
appreciated	O
from	O
the	O
following	O
description	O
of	O
the	O
preferred	O
embodiments	O
,	O
taken	O
in	O
conjunction	O
with	O
the	O
accompanying	O
drawings	O
of	O
which	O
:	O

FIG	O
.	O
1	O
shows	O
a	O
schematic	O
of	O
the	O
cooperation	O
of	O
the	O
encoder	O
and	O
decoder	O
to	O
compress	O
HMM	O
prototypes	O
;	O

FIG	O
.	O
2	O
shows	O
an	O
illustration	O
in	O
accordance	O
with	O
FIG	O
.	O
1	O
including	O
bit	O
encoders	O
;	O
and	O

FIG	O
.	O
3	O
shows	O
a	O
system	O
for	O
automatic	O
voice	O
recognition	O
which	O
uses	O
compressed	O
HMM	O
prototypes	O
.	O

DETAILED	O
DESCRIPTION	O
OF	O
THE	O
PREFERRED	O
EMBODIMENT	O
Reference	O
will	O
now	O
be	O
made	O
in	O
detail	O
to	O
the	O
preferred	O
embodiments	O
of	O
the	O
present	O
invention	O
,	O
examples	O
of	O
which	O
are	O
illustrated	O
in	O
the	O
accompanying	O
drawings	O
,	O
wherein	O
like	O
reference	O
numerals	O
refer	O
to	O
like	O
elements	O
throughout	O
.	O

FIG	O
.	O
1	O
shows	O
an	O
HMM	O
prototype	O
which	O
is	O
denoted	O
by	O
Xj	O
,	O
j	O
=	O
1	O
,	O
.	O
.	O
.	O
J	O
,	O
J	O
being	O
a	O
natural	O
number	O
.	O
The	O
components	O
Xj1	O
,	O
Xj2	O
to	O
XjN	O
of	O
Xj	O
are	O
denoted	O
by	O
the	O
reference	O
10	O
.	O
N	O
is	O
also	O
a	O
natural	O
number	O
.	O
The	O
components	O
are	O
applied	O
to	O
inputs	O
12	O
of	O
the	O
neural	O
network	O
14	O
denoted	O
by	O
NN	O
.	O
The	O
neural	O
network	O
14	O
operates	O
as	O
an	O
encoder	O
.	O
It	O
generates	O
compressed	O
HMM	O
prototypes	O
Yjj	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
J	O
,	O
J	O
being	O
the	O
abovementioned	O
natural	O
number	O
.	O
Yj	O
has	O
the	O
components	O
Yj1	O
,	O
Yj2	O
to	O
YjM	O
M	O
being	O
a	O
natural	O
number	O
.	O
The	O
components	O
Yjm	O
are	O
marked	O
with	O
the	O
reference	O
numeral	O
16	O
.	O
The	O
components	O
Yjm	O
generated	O
by	O
the	O
neural	O
network	O
14	O
are	O
real	O
numbers	O
.	O
FIG	O
.	O
1	O
also	O
shows	O
a	O
second	O
neural	O
network	O
NN	O
18	O
,	O
which	O
operates	O
as	O
a	O
decoder	O
.	O
It	O
reconstructs	O
HMM	O
prototypes	O
X	O
′	O
j	O
with	O
the	O
components	O
X	O
′	O
j1	O
,	O
X	O
′	O
j2	O
to	O
X	O
′	O
jN	O
,	O
which	O
are	O
denoted	O
by	O
the	O
reference	O
numeral	O
20	O
,	O
at	O
the	O
output	O
nodes	O
21	O
of	O
the	O
neural	O
network	O
.	O

The	O
basis	O
of	O
the	O
compression	O
method	O
according	O
to	O
one	O
aspect	O
of	O
the	O
invention	O
is	O
coding	O
and	O
decoding	O
based	O
on	O
neural	O
networks	O
14	O
,	O
18	O
.	O
Each	O
HMM	O
prototype	O
Xj	O
is	O
firstly	O
subjected	O
to	O
encoding	O
by	O
the	O
neural	O
network	O
14	O
.	O
The	O
HMM	O
prototype	O
Xj	O
is	O
mapped	O
onto	O
a	O
compressed	O
HMM	O
prototype	O
Yj	O
.	O
Xj	O
has	O
N	O
components	O
;	O
Yj	O
has	O
M	O
components	O
,	O
idR	O
M	O
being	O
substantially	O
smaller	O
than	O
N	O
,	O
in	O
order	O
to	O
achieve	O
the	O
goal	O
of	O
the	O
compression	O
.	O

The	O
compressed	O
HMM	O
prototypes	O
in	O
the	O
form	O
of	O
the	O
Yj	O
can	O
be	O
stored	O
in	O
a	O
space-saving	O
fashion	O
in	O
an	O
electronic	O
memory	O
.	O
Carrying	O
out	O
speech	O
recognition	O
requires	O
reconstruction	O
of	O
the	O
original	O
HMM	O
prototypes	O
Xj	O
.	O
This	O
is	O
performed	O
with	O
the	O
aid	O
of	O
the	O
neural	O
network	O
18	O
.	O
The	O
compressed	O
HMM	O
prototypes	O
Yj	O
are	O
mapped	O
onto	O
reconstructed	O
HMM	O
prototypes	O
X	O
′	O
j	O
with	O
the	O
aid	O
of	O
the	O
neural	O
network	O
18	O
.	O

FIG	O
.	O
1	O
therefore	O
shows	O
an	O
autoassociative	O
network	O
or	O
an	O
associative	O
memory	O
.	O

Popular	O
neural	O
networks	O
such	O
as	O
the	O
neural	O
network	O
14	O
supply	O
as	O
output	O
real	O
numbers	O
for	O
the	O
components	O
of	O
the	O
compressed	O
HMM	O
prototypes	O
Yjm	O
.	O
Real	O
numbers	O
are	O
not	O
suitable	O
for	O
storing	O
in	O
an	O
electronic	O
memory	O
.	O
Consequently	O
,	O
there	O
is	O
also	O
connected	O
downstream	O
of	O
the	O
encoder	O
14	O
a	O
bit	O
encoder	O
22	O
(	O
see	O
FIG	O
.	O
2	O
)	O
which	O
converts	O
the	O
real	O
values	O
Yjm	O
into	O
values	O
YQjm	O
.	O
The	O
bit	O
encoder	O
does	O
not	O
carry	O
out	O
simple	O
analog-to-digital	O
conversion	O
.	O
Rather	O
,	O
it	O
can	O
be	O
used	O
to	O
select	O
suitably	O
which	O
bit	O
combination	O
is	O
to	O
be	O
assigned	O
to	O
which	O
real	O
value	O
,	O
and	O
how	O
many	O
bits	O
are	O
to	O
be	O
used	O
.	O

The	O
neural	O
network	O
18	O
preferably	O
used	O
for	O
the	O
decoding	O
is	O
a	O
multi-layer	O
perceptron	O
(	O
MLP	O
)	O
,	O
a	O
layer-oriented	O
feed	O
forward	O
network	O
with	O
a	O
suitable	O
intermeshing	O
between	O
the	O
individual	O
layers	O
.	O
The	O
sigmoid	O
function	O
Sc	O
(	O
x	O
)	O
or	O
tanh	O
(	O
x	O
)	O
is	O
used	O
as	O
activation	O
function	O
.	O
A	O
number	O
of	O
variable	O
parameters	O
must	O
be	O
selected	O
to	O
be	O
sufficiently	O
large	O
for	O
a	O
high	O
decoding	O
accuracy	O
.	O
This	O
can	O
always	O
be	O
achieved	O
by	O
suitable	O
selection	O
of	O
a	O
number	O
of	O
layers	O
,	O
or	O
by	O
a	O
suitable	O
number	O
of	O
neurons	O
in	O
the	O
hidden	O
layer	O
(	O
s	O
)	O
.	O
On	O
the	O
other	O
hand	O
a	O
large	O
number	O
of	O
neurons	O
or	O
hidden	O
layers	O
increases	O
the	O
requisite	O
storage	O
space	O
and	O
the	O
computer	O
power	O
required	O
for	O
decoding	O
.	O
In	O
the	O
preferred	O
exemplary	O
embodiment	O
,	O
a	O
single	O
hidden	O
layer	O
is	O
therefore	O
used	O
for	O
the	O
neural	O
network	O
.	O

The	O
neural	O
network	O
14	O
for	O
encoding	O
can	O
be	O
selected	O
with	O
any	O
desired	O
degree	O
of	O
complexity	O
,	O
since	O
it	O
need	O
not	O
be	O
stored	O
in	O
the	O
memory	O
location	O
to	O
be	O
minimized	O
.	O

In	O
addition	O
to	O
the	O
minimization	O
of	O
the	O
storage	O
requirement	O
,	O
the	O
deviations	O
between	O
the	O
Xj	O
and	O
the	O
X	O
′	O
j	O
should	O
be	O
kept	O
as	O
small	O
as	O
possible	O
.	O
Consequently	O
,	O
when	O
training	O
the	O
neural	O
network	O
18	O
,	O
a	O
suitable	O
distance	O
between	O
Xj	O
and	O
X	O
′	O
j	O
is	O
selected	O
as	O
optimization	O
criterion	O
.	O
In	O
this	O
case	O
,	O
the	O
distance	O
can	O
be	O
,	O
for	O
example	O
,	O
a	O
Euclidean	O
measure	O
in	O
the	O
vector	O
space	O
of	O
Xj	O
,	O
that	O
is	O
to	O
say	O
	O
Xj-X	O
′	O
⁢	O
⁢	O
j	O
	O
=	O
∑	O
k-1N	O
⁢	O
(	O
Xkj-Xk	O
′	O
⁢	O
⁢	O
j	O
)	O
2	O
Better	O
decompression	O
accuracy	O
is	O
achieved	O
when	O
the	O
components	O
with	O
the	O
higher	O
ability	O
to	O
discriminate	O
are	O
more	O
strongly	O
weighted	O
for	O
the	O
purpose	O
of	O
determining	O
the	O
distance	O
between	O
the	O
Xj	O
and	O
X	O
′	O
j	O
.	O
The	O
ability	O
to	O
discriminate	O
a	O
component	O
is	O
the	O
importance	O
of	O
this	O
component	O
for	O
the	O
decision	O
on	O
the	O
assignment	O
(	O
classification	O
)	O
of	O
a	O
recorded	O
sound	O
to	O
the	O
HMM	O
prototype	O
to	O
which	O
the	O
component	O
belongs	O
.	O
The	O
actual	O
and	O
final	O
goal	O
of	O
the	O
decoder	O
is	O
associated	O
not	O
with	O
the	O
fact	O
the	O
X	O
′	O
effectively	O
approximates	O
the	O
values	O
of	O
X	O
,	O
but	O
with	O
the	O
fact	O
that	O
the	O
error	O
rate	O
of	O
the	O
recognizer	O
in	O
the	O
case	O
of	O
automatic	O
speech	O
recognition	O
using	O
the	O
reconstructed	O
HMM	O
prototypes	O
X	O
′	O
j	O
rises	O
as	O
little	O
as	O
possible	O
by	O
comparison	O
with	O
the	O
uncoded	O
HMM	O
prototypes	O
XJ	O
.	O

In	O
each	O
case	O
of	O
the	O
use	O
of	O
“	O
linear	O
discriminant	O
analysis	O
”	O
(	O
LDA	O
)	O
for	O
generating	O
HMM	O
prototypes	O
starting	O
from	O
the	O
recorded	O
speech	O
data	O
,	O
the	O
components	O
Xj1	O
,	O
.	O
.	O
.	O
,	O
XjN	O
are	O
arranged	O
according	O
to	O
their	O
ability	O
to	O
discriminate	O
.	O
Consequently	O
,	O
a	O
good	O
approximation	O
of	O
the	O
components	O
for	O
the	O
values	O
Xjk	O
is	O
more	O
important	O
with	O
a	O
small	O
index	O
k	O
than	O
for	O
large	O
indices	O
k	O
.	O
In	O
the	O
preferred	O
exemplary	O
embodiment	O
,	O
it	O
is	O
the	O
functions	O
:	O
	O
Xj-X	O
′	O
⁢	O
⁢	O
j	O
	O
=	O
∑	O
k	O
=	O
1N	O
⁢	O
ak	O
⁡	O
(	O
Xkj-Xk	O
′	O
⁢	O
⁢	O
j	O
)	O
2	O
;	O
a1	O
≥	O
a2	O
≥	O
⁢	O
…	O
⁢	O
≥	O
aN-1	O
≥	O
aN	O
>	O
0	O
,	O
which	O
are	O
used	O
as	O
distance	O
,	O
ak	O
assuming	O
falling	O
values	O
with	O
rising	O
k	O
.	O

The	O
training	O
of	O
the	O
neural	O
network	O
18	O
operating	O
as	O
the	O
decoder	O
is	O
performed	O
by	O
the	O
Yj	O
at	O
the	O
inputs	O
and	O
the	O
Xj	O
at	O
the	O
outputs	O
.	O
The	O
X	O
′	O
j	O
generated	O
by	O
the	O
neural	O
network	O
are	O
examined	O
as	O
to	O
their	O
distance	O
from	O
the	O
Xj	O
and	O
the	O
weights	O
are	O
suitably	O
varied	O
in	O
order	O
to	O
reduce	O
the	O
distances	O
on	O
average	O
.	O

After	O
the	O
optimization	O
,	O
the	O
compressed	O
HMM	O
prototypes	O
Yj	O
can	O
be	O
stored	O
together	O
with	O
the	O
structure	O
and	O
the	O
weights	O
,	O
determined	O
during	O
training	O
,	O
of	O
the	O
neural	O
network	O
as	O
well	O
as	O
the	O
indices	O
thereof	O
.	O

If	O
a	O
relatively	O
simple	O
neural	O
network	O
18	O
is	O
used	O
for	O
decoding	O
,	O
information	O
must	O
be	O
stored	O
via	O
the	O
HMM	O
prototypes	O
Xj	O
essentially	O
in	O
the	O
compressed	O
HMM	O
prototypes	O
Yj	O
.	O
In	O
the	O
case	O
of	O
4000	O
to	O
10	O
000	O
HMM	O
prototypes	O
Xj	O
of	O
a	O
type-in	O
recognizer	O
,	O
the	O
same	O
number	O
of	O
compressed	O
HMM	O
prototypes	O
YJ	O
is	O
obtained	O
.	O
However	O
,	O
these	O
now	O
have	O
fewer	O
components	O
,	O
for	O
example	O
,	O
only	O
5	O
to	O
20	O
components	O
per	O
prototype	O
,	O
since	O
M	O
can	O
be	O
smaller	O
than	O
N.	O
Furthermore	O
,	O
each	O
of	O
these	O
components	O
has	O
fewer	O
bits	O
,	O
for	O
example	O
only	O
2	O
to	O
16	O
bits	O
.	O
The	O
result	O
of	O
this	O
is	O
a	O
storage	O
requirement	O
of	O
only	O
5	O
to	O
400	O
kilobytes	O
for	O
the	O
compressed	O
HMM	O
prototypes	O
.	O

The	O
storage	O
requirement	O
for	O
the	O
neural	O
network	O
is	O
,	O
by	O
contrast	O
,	O
of	O
virtually	O
no	O
importance	O
for	O
a	O
network	O
with	O
only	O
one	O
hidden	O
layer	O
.	O

Overall	O
,	O
compression	O
may	O
reduce	O
the	O
storage	O
requirement	O
by	O
a	O
factor	O
of	O
2	O
to	O
4	O
using	O
the	O
method	O
described	O
.	O

FIG	O
.	O
3	O
shows	O
a	O
system	O
for	O
automatic	O
speech	O
recognition	O
,	O
for	O
example	O
in	O
a	O
mobile	O
phone	O
.	O
It	O
contains	O
a	O
memory	O
24	O
for	O
storing	O
compressed	O
HMM	O
prototypes	O
Y1	O
to	O
Yj	O
.	O
The	O
system	O
also	O
has	O
a	O
neural	O
network	O
18	O
for	O
decoding	O
the	O
compressed	O
HMM	O
prototypes	O
,	O
that	O
is	O
to	O
say	O
for	O
reconstructing	O
HMM	O
prototypes	O
.	O
Also	O
shown	O
in	O
FIG	O
.	O
3	O
is	O
an	O
input	O
26	O
for	O
a	O
speech	O
signal	O
,	O
as	O
a	O
rule	O
a	O
transformed	O
recording	O
of	O
the	O
sound	O
.	O
In	O
order	O
to	O
recognize	O
the	O
input	O
speech	O
signal	O
,	O
a	O
recognizer	O
28	O
uses	O
as	O
a	O
prototype	O
the	O
output	O
values	O
of	O
the	O
neural	O
network	O
18	O
.	O
The	O
results	O
of	O
the	O
recognizer	O
28	O
are	O
output	O
via	O
an	O
output	O
30	O
in	O
the	O
form	O
of	O
a	O
signal	O
which	O
corresponds	O
to	O
the	O
recognized	O
speech	O
signal	O
.	O

The	O
invention	O
has	O
been	O
described	O
in	O
detail	O
with	O
particular	O
reference	O
to	O
preferred	O
embodiments	O
thereof	O
and	O
examples	O
,	O
but	O
it	O
will	O
be	O
understood	O
that	O
variations	O
and	O
modifications	O
can	O
be	O
effected	O
within	O
the	O
spirit	O
and	O
scope	O
of	O
the	O
invention	O
.	O

1	O
.	O
A	O
method	O
for	O
compressing	O
the	O
storage	O
space	O
required	O
by	O
Hidden	O
Markov	O
Model	O
(	O
HMM	O
)	O
prototypes	O
in	O
an	O
electronic	O
memory	O
,	O
comprising	O
:	O
prescribing	O
HMM	O
prototypes	O
;	O
mapping	O
the	O
HMM	O
prototypes	O
onto	O
compressed	O
HMM	O
prototypes	O
using	O
a	O
first	O
ancoder	O
;	O
and	O
converting	O
the	O
compressed	O
HMM	O
prototypes	O
into	O
binary	O
numbers	O
using	O
a	O
second	O
encoder	O
,	O
the	O
second	O
encoder	O
being	O
a	O
bit	O
encoder	O
,	O
the	O
HMM	O
prototypes	O
being	O
converted	O
to	O
binary	O
numbers	O
such	O
that	O
the	O
binary	O
numbers	O
having	O
as	O
few	O
bits	O
as	O
possible	O
,	O
and	O
compressed	O
HMM	O
prototypes	O
and	O
the	O
binary	O
numbers	O
being	O
formed	O
in	O
such	O
a	O
way	O
that	O
a	O
neural	O
network	O
can	O
map	O
the	O
binary	O
numbers	O
onto	O
reconstructed	O
HMM	O
prototypes	O
,	O
and	O
the	O
spacing	O
between	O
the	O
HMM	O
prototypes	O
and	O
the	O
reconstructed	O
HMM	O
prototypes	O
is	O
minimized	O
.	O

2	O
.	O
The	O
method	O
as	O
claimed	O
in	O
claim	O
1	O
,	O
wherein	O
the	O
first	O
encoder	O
is	O
a	O
second	O
neural	O
network	O
.	O

3	O
.	O
The	O
method	O
as	O
claimed	O
in	O
claim	O
1	O
,	O
wherein	O
the	O
reconstructed	O
HMM	O
prototypes	O
with	O
the	O
higher	O
ability	O
to	O
discriminate	O
are	O
weighted	O
more	O
heavily	O
in	O
order	O
to	O
determine	O
the	O
spacing	O
between	O
the	O
HMM	O
prototypes	O
and	O
the	O
reconstructed	O
HMM	O
prototypes	O
.	O

4	O
.	O
The	O
method	O
as	O
claimed	O
in	O
claim	O
2	O
,	O
wherein	O
the	O
reconstructed	O
HMM	O
prototypes	O
with	O
the	O
higher	O
ability	O
to	O
discriminate	O
are	O
weighted	O
more	O
heavily	O
in	O
order	O
to	O
determine	O
the	O
spacing	O
between	O
the	O
HMM	O
prototypes	O
and	O
the	O
reconstructed	O
HMM	O
prototypes	O
.	O

5	O
.	O
The	O
method	O
as	O
claimed	O
in	O
claim	O
1	O
wherein	O
the	O
binary	O
numbers	O
have	O
as	O
few	O
bits	O
as	O
possible	O
such	O
that	O
the	O
binary	O
numbers	O
occupy	O
fewer	O
bits	O
than	O
binary	O
numbers	O
obtained	O
from	O
a	O
direct	O
mapping	O
.	O

6	O
.	O
A	O
system	O
for	O
automatic	O
speech	O
recognition	O
,	O
comprising	O
:	O
a	O
first	O
encoder	O
to	O
map	O
Hidden	O
Markov	O
Model	O
(	O
HMM	O
)	O
prototypes	O
onto	O
compressed	O
HMM	O
prototypes	O
;	O
a	O
second	O
encoder	O
to	O
convert	O
the	O
compressed	O
HMM	O
prototypes	O
into	O
binary	O
numbers	O
,	O
the	O
second	O
encoder	O
being	O
a	O
bit	O
encoder	O
;	O
an	O
electronic	O
memory	O
storage	O
space	O
to	O
store	O
the	O
compressed	O
HMM	O
prototypes	O
;	O
a	O
neural	O
network	O
to	O
calculate	O
speech	O
patterns	O
and	O
to	O
map	O
the	O
compressed	O
HMM	O
prototypes	O
onto	O
reconstructed	O
HMM	O
prototypes	O
by	O
mapping	O
the	O
binary	O
numbers	O
onto	O
reconstructed	O
HMM	O
prototypes	O
;	O
an	O
input	O
to	O
calculate	O
a	O
speech	O
signal	O
;	O
a	O
recognizer	O
to	O
recognize	O
the	O
input	O
speech	O
signal	O
,	O
the	O
recognizer	O
using	O
the	O
speech	O
patterns	O
calculated	O
by	O
the	O
neural	O
network	O
;	O
and	O
an	O
output	O
to	O
produce	O
a	O
signal	O
which	O
corresponds	O
to	O
the	O
input	O
speech	O
signal	O
,	O
wherein	O
the	O
compressed	O
HMM	O
prototypes	O
and	O
the	O
neural	O
network	O
are	O
chosen	O
to	O
minimize	O
the	O
spacing	O
between	O
the	O
HMM	O
prototypes	O
and	O
the	O
reconstructed	O
HMM	O
prototypes	O
,	O
and	O
the	O
structure	O
and	O
parameters	O
of	O
the	O
encoders	O
and	O
of	O
the	O
neural	O
network	O
are	O
selected	O
in	O
such	O
a	O
way	O
that	O
the	O
binary	O
numbers	O
have	O
as	O
few	O
bits	O
as	O
possible	O
.	O

7	O
.	O
The	O
system	O
as	O
claimed	O
in	O
claim	O
6	O
,	O
wherein	O
the	O
memory	O
stores	O
compressed	O
speech	O
patterns	O
calculated	O
by	O
the	O
neural	O
network	O
.	O

8	O
.	O
The	O
system	O
as	O
claimed	O
in	O
claim	O
6	O
,	O
wherein	O
the	O
neural	O
network	O
comprises	O
a	O
single	O
hidden	O
layer	O
.	O

9	O
.	O
A	O
computer	O
readable	O
storage	O
medium	O
storing	O
a	O
program	O
to	O
control	O
a	O
computer	O
to	O
perform	O
a	O
process	O
for	O
compressing	O
the	O
storage	O
space	O
required	O
by	O
Hidden	O
Markov	O
Model	O
(	O
HMM	O
)	O
prototypes	O
,	O
the	O
process	O
comprising	O
:	O
prescribing	O
HMM	O
prototypes	O
(	O
Xj	O
)	O
being	O
prescribed	O
;	O
mapping	O
the	O
HMM	O
prototypes	O
onto	O
compressed	O
HMM	O
prototypes	O
using	O
a	O
first	O
encoder	O
;	O
and	O
converting	O
the	O
compressed	O
HMM	O
prototypes	O
into	O
binary	O
numbers	O
using	O
a	O
second	O
encoder	O
,	O
the	O
second	O
encoder	O
being	O
a	O
bit	O
encoder	O
,	O
the	O
HMM	O
prototypes	O
being	O
converted	O
to	O
binary	O
numbers	O
such	O
that	O
the	O
binary	O
numbers	O
having	O
as	O
few	O
bits	O
as	O
possible	O
,	O
and	O
the	O
compressed	O
HMM	O
prototypes	O
and	O
the	O
binary	O
numbers	O
being	O
formed	O
in	O
such	O
a	O
way	O
that	O
the	O
neural	O
network	O
can	O
map	O
the	O
binary	O
numbers	O
onto	O
reconstructed	O
HMM	O
prototypes	O
,	O
and	O
the	O
spacing	O
between	O
the	O
HMM	O
prototypes	O
and	O
the	O
reconstructed	O
HMM	O
prototypes	O
is	O
minimized	O
.	O

