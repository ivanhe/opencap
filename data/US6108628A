US	O
6108628	O
A	O
20000822	O

US	O
08931527	O
19970916	O

eng	O
eng	O

JP	O
08249972	O
A	O
19960920	O

8	O
-	O
249972	O

JP19960249972	O

20000822	O

20000822	O

7G	O
01L	O
15/14	O
A	O
7	O
G	O
01	O
L	O
15	O
14	O
A	O

G10L	O
15/10	O
20060101AFI20051220RMJP	O

20060101	O

A	O
G	O
10	O
L	O
15	O
10	O
F	O
I	O

20051220	O

JP	O

R	O
M	O

G10L	O
15/00	O
20060101C	O
I20051008RMEP	O

20060101	O

C	O
G	O
10	O
L	O
15	O
00	O
I	O

20051008	O

EP	O

R	O
M	O

G10L	O
15/08	O
20060101A	O
N20051008RMEP	O

20060101	O

A	O
G	O
10	O
L	O
15	O
08	O
N	O

20051008	O

EP	O

R	O
M	O

G10L	O
15/14	O
20060101A	O
I20051008RMEP	O

20060101	O

A	O
G	O
10	O
L	O
15	O
14	O
I	O

20051008	O

EP	O

R	O
M	O

G10L	O
15/18	O
20060101ALI20051220RMJP	O

20060101	O

A	O
G	O
10	O
L	O
15	O
18	O
L	O
I	O

20051220	O

JP	O

R	O
M	O

US	O

704/256	O
704	O
256	O

704/238	O
704	O
238	O

704/E15.028	O
704	O
E15	O
.	O
028	O

G10L	O
15/14M	O
G	O
10	O
L	O
15	O
14	O

M	O

S10L	O
15	O
:	O
08	O
S	O
10	O
L	O
15	O
08	O

S10L	O
15	O
:	O
18C2	O
S	O
10	O
L	O
15	O
18	O

C	O
2	O

US	O

704/256	O
704	O
256	O

US	O

704/245	O
704	O
245	O

US	O

704/243	O
704	O
243	O

US	O

704/238	O
704	O
238	O

US	O

704/200	O
704	O
200	O

US	O

704/240	O
704	O
240	O

US	O

704/241	O
704	O
241	O

US	O

704/231	O
704	O
231	O

US	O

704/249	O
704	O
249	O

US	O

704/254	O
704	O
254	O

US	O

704/255	O
704	O
255	O

32	O
Speech	O
recognition	O
method	O
and	O
apparatus	O
using	O
coarse	O
and	O
fine	O
output	O
probabilities	O
utilizing	O
an	O
unspecified	O
speaker	O
model	O

US	O
4837831	O
A	O
Gillick	O
et_al.	O

19890606	O

19861015	O

US	O

704/245	O
704	O
245	O

US	O
4914703	O
A	O
Gillick	O
19900403	O

19861205	O

US	O

704/245	O
704	O
245	O

US	O
5208863	O
A	O
Sakurai	O
et_al.	O

19930504	O

19901102	O

US	O

381/43	O
381	O
43	O

US	O
5220629	O
A	O
Kosaka	O
et_al.	O

19930615	O

19901105	O

US	O

381/52	O
381	O
52	O

US	O
5271088	O
A	O
Bahler	O
19931214	O

19930407	O

US	O

704/200	O
704	O
200	O

US	O
5369728	O
A	O
Kosaka	O
et_al.	O

19941129	O

19920609	O

US	O

395/2	O
.	O
63	O
395	O
2	O
.	O
63	O

US	O
5598507	O
A	O
Kimber	O
et_al.	O

19970128	O

19940412	O

US	O

704/246	O
704	O
246	O

US	O
5606643	O
A	O
Balasubramanian	O
et_al.	O

19970225	O

19940412	O

US	O

704/243	O
704	O
243	O

US	O
5608840	O
A	O
Tsuboka	O
19970304	O

19950607	O

US	O

704/236	O
704	O
236	O

US	O
5608841	O
A	O
Tsuboka	O
19970304	O

19930603	O

US	O

704/256	O
704	O
256	O

US	O
5621849	O
A	O
Sakurai	O
et_al.	O

19970415	O

19950111	O

US	O

395/2	O
.	O
5	O
395	O
2	O
.	O
5	O

US	O
5659662	O
A	O
Wilcox	O
et_al.	O

19970819	O

19960909	O

US	O

704/238	O
704	O
238	O

US	O
5787394	O
A	O
Bahl	O
et_al.	O

19980728	O

19951213	O

US	O

704/238	O
704	O
238	O

US	O
5839105	O
A	O
Ostendorf	O
et_al.	O

19981117	O

19961129	O

US	O

704/256	O
704	O
256	O

Kosaka	B-Citation
et_al.	I-Citation
,	I-Citation
Tre	I-Citation
Structured	I-Citation
Speaker	I-Citation
Clustering	I-Citation
for	I-Citation
fast	I-Citation
Speaker	I-Citation
Adaptation	I-Citation
Proceedings	I-Citation
of	I-Citation
ICCASSP	I-Citation
.	I-Citation
vol.	I-Citation
1	I-Citation
,	I-Citation
pp.	I-Citation
1245	I-Citation
1248	I-Citation
,	I-Citation
Apr.	I-Citation
1994	I-Citation
.	O

Kosaka	B-Citation
,	I-Citation
T	I-Citation
,	I-Citation
et_al.	I-Citation
,	I-Citation
Tree	I-Citation
Structured	I-Citation
Speaker	I-Citation
Clustering	I-Citation
For	I-Citation
Fast	I-Citation
Speaker	I-Citation
Adaption	I-Citation
,	I-Citation
Proceedings	I-Citation
of	I-Citation
ICASSP	I-Citation
,	I-Citation
vol.	I-Citation
1	I-Citation
,	I-Citation
Apr.	I-Citation
1994	I-Citation
,	I-Citation
pp.	I-Citation
1245	I-Citation
1248	I-Citation
.	O

G.	B-Citation
Rigoll	I-Citation
,	I-Citation
Speaker	I-Citation
Adaptation	I-Citation
for	I-Citation
Large	I-Citation
Vocabulary	I-Citation
Speech	I-Citation
Recognition	I-Citation
Systems	I-Citation
Using	I-Citation
Speaker	I-Citation
Markov	I-Citation
Models	I-Citation
,	I-Citation
Proceedings	I-Citation
of	I-Citation
ICASSP	I-Citation
,	I-Citation
vol.	I-Citation
1	I-Citation
No.	I-Citation
14	I-Citation
,	I-Citation
May	I-Citation
1989	I-Citation
,	I-Citation
pp.	I-Citation
5	I-Citation
9	I-Citation
.	O

Sugiyama	B-Citation
,	I-Citation
et_al.	I-Citation
,	I-Citation
Speech	I-Citation
Segmentation	I-Citation
and	I-Citation
Clustering	I-Citation
Problem	I-Citation
Based	I-Citation
on	I-Citation
an	I-Citation
Unknown	I-Citation
Multiple	I-Citation
Nu	I-Citation
Signal	I-Citation
Source	I-Citation
Model/An	I-Citation
Application	I-Citation
to	I-Citation
Segmented	I-Citation
Speech	I-Citation
Clustering	I-Citation
Based	I-Citation
on	I-Citation
Speaker	I-Citation
Features	I-Citation
,	I-Citation
Systems	I-Citation
&	I-Citation
Computers	I-Citation
in	I-Citation
Japan	I-Citation
,	I-Citation
vol.	I-Citation
25	I-Citation
,	I-Citation
No.	I-Citation
9	I-Citation
,	I-Citation
Aug.	I-Citation
1994	I-Citation
,	I-Citation
pp.	I-Citation
83	I-Citation
92	I-Citation
.	O

US	O
7565290	O
B2	O
20090721	O

20050624	O

US	O
7603273	O
B2	O
20091013	O

20060515	O

US	O
7529666	O
B1	O
20090505	O

20001030	O

US	O
7689416	O
B1	O
20100330	O

20040123	O

US	O
7439981	O
B2	O
20081021	O

20041021	O

US	O
7376566	O
B2	O
20080520	O

20040112	O

US	O
7315307	O
B2	O
20080101	O

20040520	O

US	O
7315308	O
B2	O
20080101	O

20040521	O

US	O
7239324	O
B2	O
20070703	O

20020215	O

US	O
7107214	O
B2	O
20060912	O

20050708	O

US	O
7024361	O
B2	O
20060404	O

20021107	O

US	O
7039588	O
B2	O
20060502	O

20040830	O

US	O
7047192	O
B2	O
20060516	O

20010627	O

US	O
7050974	O
B1	O
20060523	O

20000913	O

US	O
7054814	O
B2	O
20060530	O

20010329	O

US	O
7058580	O
B2	O
20060606	O

20041004	O

US	O
6985860	O
B2	O
20060110	O

20010830	O

US	O
7010477	O
B1	O
20060307	O

20010625	O

US	O
6980955	O
B2	O
20051227	O

20010328	O

US	O
6813606	O
B2	O
20041102	O

20001220	O

US	O
6684186	O
B2	O
20040127	O

19990126	O

US	O
6587820	O
B2	O
20030701	O

20011116	O

US	O
6526379	O
B1	O
20030225	O

19991129	O

US	O
7756707	O
B2	O
20100713	O

20050318	O

US	O
7844461	O
B2	O
20101130	O

20030602	O

Canon	O
Kabushiki	O
Kaisha	O

Tokyo	O
JP	O

Komori	O
Yasuhiro	O

Kawasaki	O
JP	O

Kosaka	O
Tetsuo	O

Zama	O
JP	O

Yamada	O
Masayuki	O

Kawasaki	O
JP	O

Fitzpatrick	O
,	O
Cella	O
,	O
Harper	O
&	O
Scinto	O

Dorvil	O
;	O
Richemond	O

DE	O
69726235	O
D1	O
20031224	O

19970918	O

JP	O
01097276	O
A	O
19890414	O

19960920	O

EP	O
831456	O
A3	O
19981014	O

19970918	O

EP	O
831456	O
A2	O
19980325	O

19970918	O

EP	O
831456	O
B1	O
20031119	O

19970918	O

DE	O
69726235	O
T2	O
20040819	O

19970918	O

JP	O
10097276	O
A	O
19980414	O

19960920	O

US	O
6108628	O
A	O
20000822	O

19970916	O

DE	O
69726235	O
D1	O
20031224	O

19970918	O

US	O
6108628	O
A	O
20000822	O

19970916	O

EP	O
831456	O
A3	O
19981014	O

19970918	O

EP	O
831456	O
A2	O
19980325	O

19970918	O

EP	O
831456	O
B1	O
20031119	O

19970918	O

JP	O
01097276	O
A	O
19890414	O

19960920	O

JP	O
10097276	O
A	O
19980414	O

19960920	O

DE	O
69726235	O
T2	O
20040819	O

19970918	O

A	O
high-speed	O
speech	O
recognition	O
method	O
with	O
a	O
high	O
recognition	O
rate	O
,	O
utilizing	O
speaker	O
models	O
,	O
includes	O
the	O
steps	O
of	O
executing	O
an	O
acoustic	O
process	O
on	O
the	O
input	O
speech	O
,	O
calculating	O
a	O
coarse	O
output	O
probability	O
utilizing	O
an	O
unspecified	O
speaker	O
model	O
,	O
and	O
calculating	O
a	O
fine	O
output	O
probability	O
utilizing	O
an	O
unspecified	O
speaker	O
model	O
and	O
clustered	O
speaker	O
models	O
,	O
for	O
the	O
states	O
estimated	O
,	O
by	O
the	O
result	O
of	O
coarse	O
calculation	O
,	O
to	O
contribute	O
to	O
the	O
results	O
of	O
recognition	O
.	O
Candidates	O
of	O
recognition	O
are	O
then	O
extracted	O
by	O
a	O
common	O
language	O
search	O
based	O
on	O
the	O
obtained	O
result	O
,	O
and	O
a	O
fine	O
language	O
search	O
is	O
conducted	O
on	O
the	O
thus	O
extracted	O
candidates	O
to	O
determine	O
the	O
result	O
of	O
recognition	O
.	O

19980316	O

AS	O
ASSIGNMENT	O
N	O
US	O
6108628A	O
CANON	O
KABUSHIKI	O
KAISHA	O
,	O
JAPAN	O
ASSIGNMENT	O
OF	O
ASSIGNORS	O
INTEREST;ASSIGNORS:KOMORI	O
,	O
YASUHIRO;KOSAKA	O
,	O
TETSUO;YAMADA	O
,	O
MASAYUKI;REEL/FRAME:009045/0123;SIGNING	O
DATES	O
FROM	O
19971017	O
TO	O
19971020	O

20011023	O

CC	O
CERTIFICATE	O
OF	O
CORRECTION	O
C	O
US	O
6108628A	O

20040121	O

FPAY	O
+	O
FEE	O
PAYMENT	O
N	O
US	O
6108628A	O
4	O

20080125	O

FPAY	O
+	O
FEE	O
PAYMENT	O
N	O
US	O
6108628A	O
8	O

BACKGROUND	O
OF	O
THE	O
INVENTION	O
1	O
.	O
Field	O
of	O
the	O
Invention	O
The	O
present	O
invention	O
relates	O
to	O
a	O
speech	O
recognition	O
method	O
and	O
an	O
apparatus	O
therefor	O
,	O
and	O
more	O
particularly	O
to	O
a	O
speech	O
recognition	O
method	O
for	O
recognizing	O
the	O
input	O
speech	O
utilizing	O
a	O
model	O
,	O
and	O
an	O
apparatus	O
therefor	O
.	O

2	O
.	O
Related	O
Background	O
Art	O
Among	O
the	O
conventional	O
speech	O
recognition	O
technologies	O
,	O
few	O
employ	O
models	O
of	O
plural	O
speaker	O
classes	O
,	O
and	O
,	O
even	O
in	O
case	O
such	O
models	O
are	O
employed	O
,	O
there	O
is	O
adopted	O
a	O
method	O
of	O
utilizing	O
models	O
divided	O
into	O
male	O
and	O
female	O
speakers	O
and	O
selecting	O
the	O
model	O
to	O
be	O
used	O
prior	O
to	O
the	O
execution	O
of	O
speech	O
recognition	O
.	O
Thus	O
,	O
there	O
has	O
not	O
been	O
a	O
method	O
of	O
utilizing	O
an	O
unspecified	O
speaker	O
model	O
or	O
utilizing	O
a	O
male	O
model	O
and	O
a	O
female	O
model	O
at	O
the	O
same	O
time	O
for	O
speech	O
recognition	O
,	O
and	O
there	O
has	O
not	O
existed	O
a	O
high-speed	O
process	O
utilizing	O
such	O
a	O
method	O
.	O

In	O
the	O
model	O
preparation	O
for	O
speech	O
recognition	O
,	O
it	O
is	O
generally	O
known	O
that	O
higher	O
performance	O
of	O
recognition	O
can	O
be	O
obtained	O
by	O
forming	O
details	O
in	O
the	O
Hidden	O
Markov	O
Model	O
(	O
HMM	O
)	O
in	O
the	O
direction	O
of	O
phoneme	O
environment	O
.	O
It	O
is	O
also	O
becoming	O
known	O
that	O
higher	O
performance	O
of	O
recognition	O
can	O
be	O
obtained	O
by	O
forming	O
details	O
in	O
the	O
direction	O
of	O
speaker	O
classes	O
,	O
represented	O
by	O
genders	O
.	O
However	O
,	O
while	O
the	O
load	O
of	O
recognition	O
process	O
increases	O
mainly	O
in	O
the	O
output	O
probability	O
calculation	O
of	O
HMM	O
in	O
case	O
of	O
the	O
detailed	O
model	O
formation	O
in	O
the	O
direction	O
of	O
phoneme	O
environment	O
,	O
the	O
load	O
increases	O
both	O
in	O
the	O
output	O
probability	O
calculation	O
and	O
in	O
the	O
language	O
search	O
in	O
case	O
of	O
the	O
detailed	O
model	O
formation	O
in	O
the	O
direction	O
of	O
speaker	O
classes	O
.	O
In	O
speech	O
recognition	O
,	O
it	O
is	O
desirable	O
that	O
speech	O
recognition	O
be	O
performed	O
in	O
real	O
time	O
with	O
a	O
high	O
recognition	O
rate	O
.	O
It	O
is	O
therefore	O
necessary	O
to	O
realize	O
real-time	O
speech	O
recognition	O
while	O
improving	O
the	O
recognition	O
rate	O
thereof	O
,	O
and	O
,	O
for	O
this	O
purpose	O
,	O
it	O
is	O
necessary	O
to	O
realize	O
a	O
high-speed	O
process	O
utilizing	O
speaker	O
class	O
models	O
.	O

SUMMARY	O
OF	O
THE	O
INVENTION	O
In	O
consideration	O
of	O
the	O
foregoing	O
,	O
the	O
present	O
invention	O
is	O
designed	O
to	O
enable	O
high-speed	O
speech	O
recognition	O
with	O
a	O
high	O
recognition	O
rate	O
,	O
by	O
analyzing	O
input	O
speech	O
,	O
determining	O
the	O
output	O
probability	O
of	O
models	O
,	O
namely	O
an	O
unspecified	O
speaker	O
model	O
and	O
plural	O
speaker	O
models	O
clustered	O
according	O
to	O
plural	O
speaker	O
classes	O
,	O
and	O
the	O
result	O
of	O
analysis	O
of	O
the	O
input	O
speech	O
,	O
and	O
determining	O
the	O
result	O
of	O
recognition	O
of	O
the	O
input	O
speech	O
based	O
on	O
the	O
thus	O
determined	O
output	O
probability	O
.	O

BRIEF	O
DESCRIPTION	O
OF	O
THE	O
DRAWINGS	O
FIG	O
.	O
1	O
is	O
a	O
functional	O
block	O
diagram	O
of	O
an	O
embodiment	O
of	O
the	O
present	O
invention	O
;	O
FIG	O
.	O
2	O
is	O
a	O
flow	O
chart	O
showing	O
the	O
process	O
flow	O
in	O
the	O
embodiment	O
of	O
the	O
present	O
invention	O
;	O
FIG	O
.	O
3	O
is	O
a	O
view	O
showing	O
a	O
conventional	O
process	O
utilizing	O
speaker	O
class	O
models	O
;	O
FIG	O
.	O
4	O
is	O
a	O
view	O
showing	O
a	O
high-speed	O
process	O
of	O
the	O
present	O
invention	O
utilizing	O
speaker	O
class	O
models	O
;	O
FIG	O
.	O
5	O
is	O
a	O
view	O
showing	O
the	O
comparison	O
of	O
process	O
times	O
;	O
FIG	O
.	O
6	O
is	O
a	O
view	O
showing	O
speaker	O
classes	O
having	O
a	O
hierarchical	O
structure	O
;	O
FIG	O
.	O
7	O
is	O
a	O
chart	O
showing	O
the	O
results	O
of	O
recognition	O
of	O
telephone	O
speech	O
,	O
utilizing	O
speaker	O
classes	O
;	O
and	O
FIG	O
.	O
8	O
is	O
a	O
block	O
diagram	O
showing	O
a	O
hardware	O
configuration	O
of	O
an	O
apparatus	O
embodying	O
the	O
present	O
invention	O
.	O

DESCRIPTION	O
OF	O
THE	O
PREFERRED	O
EMBODIMENTS	O
FIG	O
.	O
1	O
is	O
a	O
functional	O
block	O
diagram	O
of	O
an	O
apparatus	O
embodying	O
the	O
present	O
invention	O
.	O

In	O
FIG	O
.	O
1	O
there	O
are	O
provided	O
a	O
speech	O
input	O
device	O
101	O
including	O
a	O
microphone	O
or	O
an	O
A/D	O
converter	O
for	O
entering	O
the	O
speech	O
of	O
an	O
input	O
speaker	O
;	O
an	O
acoustic	O
process	O
unit	O
102	O
for	O
determining	O
speech	O
parameters	O
by	O
acoustic	O
analysis	O
;	O
an	O
output	O
probability	O
calculation	O
unit	O
103	O
for	O
calculating	O
a	O
common	O
coarse	O
output	O
probability	O
and	O
a	O
fine	O
output	O
probability	O
for	O
each	O
speaker	O
class	O
;	O
a	O
speaker	O
class	O
model	O
(	O
HMM	O
:	O
Hidden	O
Markov	O
Model	O
)	O
104	O
;	O
a	O
language	O
search	O
unit	O
105	O
for	O
a	O
common	O
coarse	O
language	O
search	O
and	O
a	O
fine	O
language	O
search	O
for	O
each	O
speaker	O
class	O
;	O
a	O
grammar/dictionary	O
unit	O
106	O
employed	O
in	O
the	O
language	O
processing	O
;	O
and	O
a	O
display	O
device	O
107	O
for	O
outputting	O
the	O
result	O
.	O

FIG	O
.	O
1	O
is	O
a	O
functional	O
block	O
diagram	O
of	O
a	O
speech	O
recognition	O
apparatus	O
embodying	O
the	O
present	O
invention	O
,	O
while	O
FIG	O
.	O
8	O
shows	O
the	O
hardware	O
configuration	O
of	O
such	O
speech	O
recognition	O
apparatus	O
and	O
the	O
functions	O
of	O
the	O
blocks	O
in	O
FIG	O
.	O
1	O
are	O
realized	O
by	O
the	O
components	O
shown	O
in	O
FIG	O
.	O
8	O
.	O

More	O
specifically	O
,	O
the	O
function	O
of	O
the	O
speech	O
input	O
device	O
101	O
is	O
realized	O
by	O
a	O
speech	O
input	O
device	O
86	O
,	O
and	O
the	O
functions	O
of	O
the	O
acoustic	O
process	O
unit	O
102	O
,	O
the	O
output	O
probability	O
calculation	O
unit	O
103	O
and	O
the	O
language	O
search	O
unit	O
105	O
are	O
realized	O
under	O
the	O
control	O
of	O
a	O
CPU	O
83	O
according	O
to	O
a	O
control	O
program	O
stored	O
in	O
a	O
ROM	O
81	O
or	O
a	O
RAM	O
82	O
.	O

The	O
speaker	O
class	O
HMM	O
model	O
104	O
and	O
the	O
grammar/dictionary	O
106	O
are	O
stored	O
in	O
the	O
ROM	O
81	O
or	O
the	O
RAM	O
82	O
.	O
The	O
control	O
program	O
,	O
the	O
HMM	O
and	O
the	O
dictionary	O
stored	O
in	O
the	O
RAM	O
82	O
and	O
the	O
parameters	O
required	O
in	O
various	O
processes	O
may	O
be	O
installed	O
from	O
a	O
CD-ROM	O
84	O
through	O
an	O
interface	O
(	O
I/F	O
)	O
85	O
or	O
from	O
another	O
terminal	O
(	O
not	O
shown	O
)	O
through	O
a	O
public	O
communication	O
line	O
.	O

The	O
display	O
device	O
107	O
can	O
be	O
realized	O
by	O
a	O
display	O
device	O
87	O
such	O
as	O
a	O
CRT	O
or	O
a	O
liquid	O
crystal	O
display	O
device	O
,	O
and	O
various	O
instruction	O
can	O
be	O
entered	O
by	O
input	O
means	O
88	O
,	O
such	O
as	O
a	O
keyboard	O
,	O
a	O
mouse	O
and/or	O
a	O
tablet	O
.	O

The	O
speech	O
recognition	O
apparatus	O
is	O
composed	O
of	O
the	O
above-mentioned	O
components	O
and	O
functions	O
according	O
to	O
the	O
flow	O
chart	O
shown	O
in	O
FIG	O
.	O
2	O
.	O
A	O
speech	O
cut	O
out	O
by	O
the	O
speech	O
input	O
device	O
201	O
(	O
corresponding	O
to	O
101	O
)	O
is	O
analyzed	O
into	O
speech	O
parameters	O
in	O
each	O
frame	O
by	O
the	O
acoustic	O
process	O
unit	O
202	O
(	O
corresponding	O
to	O
102	O
)	O
,	O
and	O
the	O
output	O
probability	O
calculation	O
unit	O
203	O
(	O
corresponding	O
to	O
103	O
)	O
calculates	O
the	O
output	O
probability	O
utilizing	O
the	O
HMM	O
204	O
(	O
corresponding	O
to	O
104	O
)	O
.	O
The	O
HMM	O
204	O
(	O
corresponding	O
to	O
104	O
)	O
stores	O
speaker	O
class	O
models	O
clustered	O
into	O
plural	O
speaker	O
classes	O
.	O
At	O
the	O
output	O
probability	O
calculation	O
in	O
203	O
,	O
the	O
output	O
probability	O
calculation	O
unit	O
at	O
first	O
calculates	O
a	O
common	O
coarse	O
output	O
probability	O
(	O
203-a	O
)	O
,	O
and	O
,	O
based	O
on	O
the	O
result	O
of	O
such	O
a	O
calculation	O
,	O
calculates	O
again	O
a	O
fine	O
output	O
probability	O
for	O
each	O
speaker	O
class	O
that	O
may	O
contribute	O
to	O
the	O
result	O
of	O
recognition	O
(	O
203-b	O
)	O
.	O
Then	O
a	O
common	O
output	O
probability	O
is	O
determined	O
from	O
these	O
output	O
probabilities	O
,	O
and	O
the	O
language	O
search	O
unit	O
205	O
(	O
corresponding	O
to	O
105	O
)	O
executes	O
a	O
common	O
language	O
search	O
based	O
on	O
the	O
grammar/dictionary	O
206	O
(	O
corresponding	O
to	O
106	O
)	O
and	O
the	O
common	O
output	O
probability	O
determined	O
above	O
,	O
thereby	O
determining	O
a	O
candidate	O
of	O
recognition	O
(	O
205-a	O
)	O
.	O
The	O
language	O
search	O
unit	O
205	O
(	O
corresponding	O
to	O
105	O
)	O
then	O
executes	O
a	O
fine	O
language	O
search	O
for	O
each	O
speaker	O
class	O
,	O
utilizing	O
the	O
fine	O
output	O
probability	O
for	O
each	O
speaker	O
class	O
,	O
thereby	O
determining	O
a	O
recognition	O
result	O
and	O
its	O
likelihood	O
(	O
205-b	O
)	O
.	O
These	O
results	O
are	O
outputted	O
as	O
the	O
results	O
of	O
recognition	O
on	O
207	O
(	O
corresponding	O
to	O
107	O
)	O
.	O

[	O
Method	O
of	O
preparation	O
of	O
high	O
definition	O
HMM	O
in	O
consideration	O
of	O
speaker	O
classes	O
]	O
In	O
the	O
following	O
there	O
will	O
be	O
explained	O
methods	O
of	O
preparation	O
of	O
speaker	O
classes	O
and	O
of	O
speaker	O
class	O
HMM	O
.	O

I.	O
Method	O
of	O
preparation	O
of	O
speaker	O
classes	O
In	O
the	O
following	O
there	O
will	O
be	O
explained	O
the	O
method	O
of	O
preparation	O
of	O
speaker	O
classes	O
.	O
In	O
a	O
speaker	O
class	O
,	O
speakers	O
having	O
acoustically	O
similar	O
features	O
are	O
clustered	O
.	O
The	O
similarity	O
of	O
the	O
acoustic	O
features	O
of	O
the	O
speakers	O
can	O
be	O
measured	O
by	O
various	O
methods	O
,	O
such	O
as	O
:	O
1	O
)	O
a	O
method	O
of	O
considering	O
the	O
acoustic	O
feature	O
of	O
each	O
speaker	O
as	O
a	O
distribution	O
,	O
preparing	O
distributions	O
for	O
the	O
respective	O
speakers	O
and	O
measuring	O
the	O
similarity	O
between	O
the	O
speakers	O
by	O
the	O
distance	O
between	O
such	O
distributions	O
;	O
2	O
)	O
a	O
method	O
of	O
representing	O
an	O
unspecified	O
speaker	O
space	O
by	O
plural	O
representative	O
points	O
or	O
distributions	O
,	O
determining	O
the	O
deviation	O
of	O
the	O
representative	O
points	O
of	O
each	O
speaker	O
in	O
the	O
unspecified	O
speaker	O
space	O
,	O
and	O
measuring	O
the	O
similarlity	O
between	O
the	O
speakers	O
by	O
such	O
deviation	O
;	O
and	O
3	O
)	O
a	O
method	O
of	O
preparing	O
partial	O
spaces	O
for	O
respective	O
speakers	O
in	O
consideration	O
of	O
their	O
sound	O
property	O
,	O
making	O
correspondence	O
between	O
such	O
partial	O
spaces	O
in	O
consideration	O
of	O
the	O
sound	O
property	O
and	O
measuring	O
the	O
similarity	O
between	O
the	O
speakers	O
by	O
the	O
sum	O
of	O
the	O
similarities	O
of	O
the	O
partial	O
spaces	O
.	O

The	O
method	O
(	O
1	O
)	O
can	O
be	O
realized	O
by	O
studying	O
the	O
continuous	O
HMM	O
of	O
one	O
distribution	O
for	O
one	O
state	O
for	O
each	O
speaker	O
,	O
utilizing	O
the	O
entire	O
speech	O
space	O
and	O
measuring	O
the	O
similarity	O
between	O
the	O
speakers	O
by	O
determining	O
the	O
distance	O
of	O
the	O
HMM	O
of	O
the	O
speakers	O
.	O
In	O
this	O
method	O
,	O
however	O
,	O
the	O
average	O
of	O
the	O
distribution	O
of	O
each	O
speaker	O
becomes	O
a	O
cepstrum	O
means	O
because	O
the	O
entire	O
speech	O
space	O
of	O
each	O
speaker	O
is	O
represented	O
by	O
one	O
distribution	O
,	O
so	O
that	O
the	O
difference	O
between	O
the	O
speakers	O
may	O
not	O
become	O
conspicuous	O
.	O
Consequently	O
,	O
this	O
method	O
cannot	O
be	O
considered	O
preferable	O
.	O

The	O
method	O
(	O
2	O
)	O
can	O
be	O
realized	O
by	O
preparing	O
a	O
code	O
book	O
(	O
for	O
example	O
of	O
a	O
code	O
word	O
size	O
of	O
1024	O
)	O
of	O
an	O
unspecified	O
speaker	O
(	O
namely	O
studying	O
the	O
discrete	O
distribution	O
HMM	O
of	O
one	O
state	O
of	O
1024	O
code	O
words	O
)	O
,	O
determining	O
the	O
probabilities	O
of	O
appearance	O
of	O
such	O
code	O
words	O
for	O
each	O
speaker	O
and	O
measuring	O
the	O
similarity	O
between	O
the	O
speakers	O
by	O
the	O
deviation	O
of	O
such	O
appearing	O
probabilities	O
.	O
This	O
method	O
is	O
preferable	O
to	O
the	O
method	O
(	O
1	O
)	O
in	O
that	O
the	O
speech	O
space	O
is	O
divided	O
into	O
partial	O
spaces	O
.	O
However	O
,	O
since	O
this	O
method	O
does	O
not	O
take	O
the	O
sound	O
property	O
of	O
the	O
speakers	O
into	O
consideration	O
,	O
the	O
measured	O
similarity	O
between	O
the	O
speakers	O
may	O
be	O
based	O
on	O
the	O
similarity	O
between	O
a	O
sound	O
of	O
a	O
speaker	O
and	O
another	O
sound	O
of	O
another	O
speaker	O
,	O
and	O
this	O
method	O
cannot	O
be	O
considered	O
preferable	O
in	O
consideration	O
of	O
such	O
a	O
possibility	O
.	O

The	O
method	O
(	O
3	O
)	O
can	O
be	O
realized	O
by	O
preparing	O
models	O
in	O
consideration	O
of	O
the	O
sound	O
property	O
for	O
each	O
speaker	O
,	O
and	O
measuring	O
the	O
similarity	O
between	O
the	O
speakers	O
by	O
the	O
sums	O
of	O
the	O
similarities	O
of	O
the	O
corresponding	O
models	O
.	O
For	O
example	O
phoneme	O
HMM	O
's	O
of	O
1	O
distribution	O
for	O
3	O
states	O
are	O
prepared	O
for	O
each	O
speaker	O
,	O
and	O
the	O
similarity	O
between	O
the	O
speakers	O
is	O
measured	O
by	O
determining	O
the	O
similarity	O
in	O
each	O
corresponding	O
state	O
of	O
each	O
corresponding	O
phoneme	O
of	O
the	O
speakers	O
and	O
calculating	O
the	O
sum	O
of	O
such	O
similarities	O
.	O
In	O
this	O
method	O
,	O
the	O
similarity	O
between	O
the	O
speakers	O
is	O
measured	O
in	O
consideration	O
of	O
the	O
entire	O
speech	O
space	O
of	O
the	O
speakers	O
while	O
making	O
correspondence	O
between	O
the	O
phoneme	O
partial	O
spaces	O
represented	O
by	O
the	O
phoneme	O
and	O
the	O
state	O
,	O
and	O
can	O
therefore	O
be	O
given	O
in	O
consideration	O
of	O
the	O
sound	O
feature	O
,	O
also	O
reflecting	O
the	O
detailed	O
difference	O
in	O
the	O
acoustic	O
feature	O
of	O
each	O
speaker	O
.	O
The	O
similarity	O
between	O
the	O
speakers	O
can	O
also	O
be	O
measured	O
in	O
a	O
more	O
detailed	O
manner	O
by	O
replacing	O
the	O
phoneme	O
model	O
with	O
a	O
more	O
detailed	O
HMM	O
dependent	O
on	O
the	O
phoneme	O
environment	O
.	O

In	O
consideration	O
of	O
the	O
foregoing	O
,	O
the	O
similarity	O
between	O
the	O
speakers	O
is	O
determined	O
by	O
the	O
above-explained	O
method	O
(	O
3	O
)	O
,	O
and	O
the	O
speaker	O
classes	O
are	O
prepared	O
according	O
to	O
such	O
similarity	O
.	O
In	O
the	O
following	O
there	O
will	O
be	O
explained	O
the	O
algorithm	O
for	O
preparing	O
the	O
speaker	O
classes	O
.	O

II	O
.	O
Algorithm	O
of	O
preparation	O
of	O
speaker	O
classes	O
1	O
)	O
At	O
first	O
phoneme	O
HMM	O
's	O
of	O
1	O
distribution	O
for	O
3	O
states	O
are	O
prepared	O
.	O

Considering	O
24	O
phonemes	O
excluding	O
the	O
soundless	O
state	O
,	O
each	O
speaker	O
is	O
represented	O
by	O
72	O
partial	O
spaces	O
(	O
=	O
24	O
phonemes.times.3	O
states	O
)	O
.	O
For	O
example	O
for	O
204	O
speakers	O
,	O
there	O
are	O
prepared	O
4	O
,	O
896	O
HMM	O
's	O
,	O
and	O
the	O
total	O
number	O
of	O
distributions	O
becomes	O
14	O
,	O
688	O
(	O
4,896.times.number	O
of	O
states	O
(	O
3	O
)	O
)	O
.	O

2	O
)	O
The	O
similarity	O
between	O
the	O
speakers	O
is	O
measured	O
by	O
the	O
phoneme	O
HMM	O
's	O
prepared	O
for	O
each	O
speaker	O
.	O

For	O
two	O
speakers	O
S.	O
sup	O
.	O
(	O
1	O
)	O
and	O
S.	O
sup	O
.	O
(	O
2	O
)	O
,	O
by	O
defining	O
states	O
.phi..sub.p	O
,	O
.phi..sub.q	O
for	O
a	O
corresponding	O
state	O
n	O
of	O
a	O
corresponding	O
phoneme	O
m	O
among	O
the	O
phoneme	O
HMM	O
's	O
(	O
24	O
kinds	O
)	O
,	O
the	O
similarity	O
between	O
such	O
states	O
is	O
represented	O
by	O
a	O
distance	O
d	O
(	O
.phi..sub.p	O
,	O
.phi..sub.q	O
)	O
,	O
wherein	O
.phi..sub.p	O
,	O
and	O
.phi..sub.q	O
are	O
represented	O
by	O
:	O
.phi..sub.p	O
=.phi..sub.s.sbsb.mn.spsb	O
.	O
(	O
1	O
)	O
,	O
.phi..sub.q	O
=.phi..sub.s.sbsb.mn.spsb	O
.	O
(	O
2	O
)	O
(	O
1	O
)	O
since	O
each	O
state	O
is	O
represented	O
by	O
one	O
distribution	O
,	O
the	O
distance	O
d	O
(	O
.phi..sub.p	O
,	O
.phi..sub.q	O
)	O
can	O
be	O
calculated	O
according	O
to	O
the	O
following	O
equation	O
(	O
2	O
)	O
,	O
employing	O
Bhattacharyya	O
distance	O
:	O
#	O
#	O
EQU1	O
#	O
#	O
wherein	O
.	O
mu	O
.	O
.	O
sub	O
.	O
i	O
and	O
.SIGMA..sub.i	O
respectively	O
stand	O
for	O
mean	O
value	O
and	O
dispersion	O
.	O

The	O
distances	O
of	O
all	O
the	O
states	O
of	O
all	O
the	O
corresponding	O
phonemes	O
of	O
the	O
speakers	O
are	O
determined	O
by	O
the	O
foregoing	O
equation	O
,	O
and	O
the	O
similarity	O
of	O
the	O
speakers	O
is	O
defined	O
by	O
the	O
distance	O
D	O
(	O
S.	O
sup	O
.	O
(	O
1	O
)	O
,	O
S.	O
sup	O
.	O
(	O
2	O
)	O
)	O
which	O
is	O
the	O
sum	O
of	O
the	O
above-mentioned	O
distances	O
.	O
The	O
distance	O
D	O
(	O
S.	O
sup	O
.	O
(	O
1	O
)	O
,	O
S.	O
sup	O
.	O
(	O
2	O
)	O
)	O
is	O
calculated	O
by	O
the	O
following	O
equation	O
(	O
3	O
)	O
:	O
#	O
#	O
EQU2	O
#	O
#	O
wherein	O
M	O
indicates	O
the	O
number	O
of	O
kinds	O
of	O
HMM	O
and	O
N	O
indicates	O
the	O
number	O
of	O
states	O
per	O
HMM	O
.	O

The	O
similarity	O
is	O
determined	O
as	O
explained	O
above	O
,	O
for	O
every	O
two	O
of	O
all	O
the	O
speakers	O
.	O

3	O
)	O
The	O
speakers	O
are	O
clustered	O
by	O
an	O
LBG	O
algorithm	O
,	O
based	O
on	O
the	O
similarities	O
of	O
all	O
the	O
speakers	O
.	O
The	O
LBG	O
algorithm	O
is	O
executed	O
in	O
the	O
following	O
procedure	O
:	O
1	O
.	O
There	O
is	O
selected	O
a	O
central	O
speaker	O
,	O
for	O
whom	O
the	O
sum	O
of	O
the	O
similarities	O
for	O
all	O
the	O
speakers	O
becomes	O
a	O
minimum	O
.	O
The	O
central	O
speaker	O
means	O
a	O
speaker	O
for	O
whom	O
the	O
sum	O
of	O
the	O
similarities	O
becomes	O
a	O
minimum	O
in	O
the	O
contemplated	O
class	O
;	O
2	O
.	O
There	O
is	O
determined	O
a	O
speaker	O
S.	O
sub	O
.	O
a	O
farthest	O
from	O
the	O
central	O
speaker	O
within	O
the	O
contemplated	O
class	O
;	O
3	O
.	O
There	O
is	O
determined	O
a	O
speaker	O
S.	O
sub	O
.	O
b	O
who	O
is	O
farthest	O
from	O
the	O
above-mentioned	O
far	O
speaker	O
S.	O
sub	O
.	O
a	O
within	O
the	O
contemplated	O
class	O
;	O
4	O
.	O
The	O
speakers	O
in	O
the	O
contemplated	O
class	O
are	O
divided	O
into	O
a	O
group	O
closer	O
to	O
the	O
speaker	O
S.	O
sub	O
.	O
a	O
and	O
another	O
closer	O
to	O
the	O
speaker	O
S.	O
sub	O
.	O
b	O
,	O
thereby	O
forming	O
two	O
speaker	O
classes	O
;	O
5	O
.	O
Central	O
speakers	O
S.	O
sub	O
.	O
a1	O
,	O
S.	O
sub	O
.	O
b1	O
are	O
renewed	O
respectively	O
for	O
the	O
thus	O
divided	O
two	O
speaker	O
classes	O
;	O
6	O
.	O
All	O
the	O
speakers	O
are	O
reclustered	O
by	O
assignment	O
to	O
the	O
closest	O
central	O
speakers	O
,	O
utilizing	O
all	O
the	O
currently	O
determined	O
central	O
speakers	O
(	O
the	O
number	O
of	O
which	O
is	O
same	O
as	O
the	O
number	O
of	O
currently	O
contemplated	O
speaker	O
classes	O
)	O
.	O
This	O
step	O
6	O
is	O
repeated	O
while	O
the	O
renewal	O
of	O
the	O
central	O
speakers	O
is	O
continued	O
,	O
but	O
the	O
sequence	O
proceeds	O
to	O
the	O
next	O
step	O
7	O
if	O
the	O
central	O
speakers	O
are	O
no	O
longer	O
renewed	O
.	O
This	O
step	O
is	O
terminated	O
when	O
a	O
desired	O
number	O
of	O
speaker	O
classes	O
is	O
obtained	O
;	O
and	O
7	O
.	O
Among	O
all	O
the	O
speaker	O
classes	O
,	O
there	O
is	O
determined	O
a	O
class	O
showing	O
the	O
largest	O
sum	O
of	O
the	O
similarities	O
for	O
the	O
central	O
speaker	O
,	O
and	O
the	O
foregoing	O
steps	O
2	O
,	O
3	O
,	O
4	O
,	O
5	O
and	O
6	O
are	O
executed	O
on	O
such	O
a	O
class	O
.	O

The	O
speaker	O
classes	O
are	O
prepared	O
as	O
explained	O
in	O
the	O
foregoing	O
.	O
The	O
prepared	O
speaker	O
classes	O
may	O
be	O
utilized	O
as	O
they	O
are	O
,	O
but	O
the	O
spreading	O
of	O
the	O
speakers	O
may	O
be	O
different	O
in	O
the	O
different	O
classes	O
,	O
according	O
to	O
the	O
above-mentioned	O
method	O
of	O
preparation	O
.	O
If	O
it	O
is	O
desirable	O
to	O
have	O
similar	O
levels	O
of	O
spreading	O
among	O
the	O
different	O
speaker	O
classes	O
,	O
it	O
is	O
possible	O
to	O
fetch	O
,	O
in	O
succession	O
,	O
a	O
closer	O
speaker	O
to	O
each	O
speaker	O
class	O
until	O
the	O
level	O
of	O
spreading	O
(	O
sum	O
of	O
similarities	O
to	O
the	O
central	O
speaker	O
)	O
of	O
the	O
class	O
showing	O
the	O
widest	O
spreading	O
(	O
i	O
.	O
e	O
.	O
having	O
the	O
largest	O
sum	O
of	O
the	O
similarities	O
to	O
the	O
central	O
speaker	O
)	O
becomes	O
similar	O
to	O
the	O
level	O
of	O
spreading	O
of	O
other	O
classes	O
.	O
Such	O
determination	O
of	O
the	O
speaker	O
classes	O
provides	O
uniform	O
spreading	O
of	O
the	O
speaker	O
classes	O
,	O
and	O
the	O
speaker	O
at	O
the	O
boundary	O
belongs	O
to	O
plural	O
speaker	O
classes	O
,	O
so	O
that	O
the	O
speech	O
recognition	O
can	O
be	O
relieved	O
from	O
the	O
significant	O
influence	O
resulting	O
from	O
the	O
error	O
in	O
the	O
determination	O
of	O
the	O
speaker	O
classes	O
.	O

III	O
.	O
Method	O
of	O
preparation	O
of	O
speaker	O
class	O
HMM	O
The	O
phoneme	O
environment-dependent	O
HMM	O
's	O
are	O
prepared	O
by	O
the	O
ordinary	O
EM	O
algorithm	O
,	O
utilizing	O
the	O
speech	O
data	O
of	O
the	O
speakers	O
belonging	O
to	O
each	O
of	O
thus	O
prepared	O
speaker	O
classes	O
.	O
For	O
example	O
,	O
in	O
4	O
speaker	O
classes	O
,	O
there	O
are	O
prepared	O
phoneme	O
environment-dependent	O
HMM	O
's	O
of	O
12	O
distributions	O
in	O
3	O
states	O
(	O
238	O
kinds	O
)	O
.	O

[	O
High-speed	O
speech	O
recognition	O
method	O
utilizing	O
speaker	O
class	O
HMM	O
]	O
In	O
the	O
following	O
there	O
will	O
be	O
explained	O
a	O
high-speed	O
speech	O
recognition	O
method	O
utilizing	O
speaker	O
class	O
HMM	O
.	O

At	O
first	O
there	O
will	O
be	O
explained	O
,	O
with	O
reference	O
to	O
FIG	O
.	O
3	O
,	O
a	O
conventional	O
speech	O
recognition	O
method	O
utilizing	O
speaker	O
class	O
HMM	O
.	O
In	O
this	O
case	O
,	O
there	O
are	O
basically	O
conducted	O
,	O
in	O
parallel	O
manner	O
,	O
the	O
speech	O
recognition	O
processes	O
by	O
the	O
kinds	O
(	O
N	O
)	O
of	O
the	O
speaker	O
class	O
HMM	O
'S	O
,	O
there	O
is	O
required	O
speech	O
processing	O
of	O
N	O
times	O
,	O
in	O
comparison	O
with	O
the	O
case	O
of	O
employing	O
only	O
one	O
speaker	O
class	O
,	O
namely	O
an	O
unspecified	O
speaker	O
class	O
HMM	O
.	O
Consequently	O
,	O
the	O
output	O
probability	O
calculation	O
and	O
the	O
language	O
search	O
required	O
are	O
also	O
N	O
times	O
.	O
If	O
the	O
calculations	O
of	O
such	O
amount	O
are	O
necessary	O
,	O
the	O
use	O
of	O
the	O
speaker	O
class	O
HMM	O
's	O
in	O
the	O
actual	O
speech	O
recognition	O
inevitably	O
necessitates	O
a	O
computer	O
of	O
a	O
very	O
high	O
speed	O
or	O
of	O
parallel	O
processing	O
,	O
in	O
order	O
to	O
realize	O
a	O
real-time	O
process	O
.	O
Such	O
use	O
therefore	O
,	O
becomes	O
expensive	O
and	O
is	O
practically	O
unrealistic	O
.	O

In	O
the	O
following	O
there	O
is	O
proposed	O
a	O
speech	O
recognition	O
method	O
utilizing	O
the	O
speaker	O
class	O
HMM	O
's	O
capable	O
of	O
significantly	O
reducing	O
the	O
amount	O
of	O
the	O
above-mentioned	O
calculations	O
.	O
The	O
proposed	O
method	O
is	O
illustrated	O
in	O
FIG	O
.	O
4	O
.	O
The	O
proposed	O
speech	O
recognition	O
process	O
is	O
featured	O
by	O
a	O
fact	O
that	O
the	O
unspecified	O
speaker	O
HMM	O
is	O
always	O
used	O
also	O
in	O
the	O
recognition	O
of	O
the	O
speaker	O
class	O
HMM	O
.	O
The	O
unspecified	O
speaker	O
HMM	O
corresponds	O
to	O
an	O
upper	O
speaker	O
class	O
of	O
all	O
the	O
speaker	O
class	O
HMM	O
's	O
.	O
It	O
is	O
intended	O
to	O
improve	O
the	O
efficiency	O
of	O
the	O
output	O
probability	O
calculation	O
and	O
the	O
language	O
search	O
,	O
by	O
employing	O
the	O
result	O
of	O
the	O
unspecified	O
speaker	O
HMM	O
as	O
the	O
estimated	O
value	O
of	O
each	O
speaker	O
class	O
HMM	O
.	O

The	O
proposed	O
high-speed	O
speech	O
recognition	O
method	O
utilizing	O
the	O
speaker	O
class	O
HMM	O
's	O
functions	O
in	O
the	O
following	O
manner	O
.	O

1	O
)	O
For	O
the	O
result	O
of	O
acoustic	O
analysis	O
,	O
the	O
estimated	O
value	O
of	O
the	O
state	O
output	O
probability	O
of	O
the	O
unspecified	O
speaker	O
HMM	O
(	O
SI	O
HMM	O
)	O
is	O
calculated	O
by	O
the	O
high-speed	O
output	O
probability	O
calculation	O
method	O
IDMM	O
+	O
SQ	O
,	O
utilizing	O
scaler	O
quantization	O
and	O
dimensionally	O
independent	O
output	O
probability	O
calculation	O
.	O

2	O
)	O
Assuming	O
that	O
the	O
upper	O
rank	O
of	O
the	O
output	O
probability	O
of	O
the	O
unspecified	O
speaker	O
HMM	O
,	O
estimated	O
by	O
IDMM	O
+	O
SQ	O
,	O
is	O
a	O
state	O
contributing	O
to	O
the	O
result	O
of	O
recognition	O
,	O
the	O
state	O
output	O
probability	O
of	O
each	O
speaker	O
class	O
HMM	O
is	O
re-calculated	O
,	O
utilizing	O
the	O
unspecified	O
speaker	O
HMM	O
and	O
each	O
speaker	O
class	O
HMM	O
,	O
to	O
obtain	O
a	O
fine	O
output	O
probability	O
.	O
In	O
this	O
operation	O
,	O
since	O
the	O
unspecified	O
speaker	O
HMM	O
constitutes	O
the	O
upper	O
class	O
of	O
the	O
speaker	O
class	O
HMM	O
's	O
a	O
relatively	O
high	O
output	O
probability	O
can	O
be	O
expected	O
in	O
the	O
unspecified	O
speaker	O
HMM	O
in	O
a	O
state	O
where	O
a	O
high	O
output	O
probability	O
of	O
the	O
speaker	O
class	O
HMM	O
is	O
anticipated	O
.	O
Consequently	O
the	O
output	O
probability	O
of	O
the	O
unspecified	O
speaker	O
HMM	O
,	O
estimated	O
by	O
IDMM	O
+	O
SQ	O
,	O
may	O
be	O
employed	O
as	O
the	O
state	O
output	O
probability	O
of	O
each	O
speaker	O
class	O
HMM	O
.	O

3	O
)	O
Subsequently	O
there	O
is	O
executed	O
a	O
forward	O
language	O
search	O
,	O
utilizing	O
the	O
total	O
output	O
probability	O
of	O
the	O
unspecified	O
speaker	O
HMM	O
.	O
In	O
this	O
case	O
,	O
the	O
language	O
search	O
is	O
not	O
executed	O
in	O
other	O
speaker	O
classes	O
.	O
In	O
the	O
present	O
speech	O
recognition	O
method	O
,	O
the	O
final	O
result	O
of	O
recognition	O
is	O
determined	O
by	O
a	O
backward	O
language	O
search	O
utilizing	O
a	O
tree-trellis-based	O
search	O
,	O
based	O
on	O
an	O
Astar	O
search	O
.	O
The	O
huristic	O
cost	O
of	O
the	O
Aster	O
search	O
utilizes	O
the	O
forward	O
score	O
of	O
the	O
unspecified	O
speaker	O
and	O
does	O
not	O
require	O
the	O
forward	O
Viterbi	O
search	O
for	O
each	O
speaker	O
class	O
.	O
In	O
this	O
case	O
,	O
the	O
huristic	O
cost	O
does	O
not	O
satisfy	O
the	O
condition	O
of	O
the	O
Astar	O
search	O
in	O
the	O
strict	O
sense	O
,	O
but	O
in	O
practice	O
the	O
difference	O
scarcely	O
matters	O
if	O
the	O
final	O
N-best	O
results	O
are	O
re-sorted	O
since	O
the	O
unspecified	O
speaker	O
HMM	O
,	O
constituting	O
an	O
upper	O
class	O
of	O
the	O
speaker	O
class	O
HMM	O
's	O
,	O
provides	O
a	O
relative	O
satisfactory	O
estimated	O
value	O
for	O
the	O
huristic	O
cost	O
of	O
the	O
speaker	O
class	O
HMM	O
's	O
.	O
The	O
final	O
N-best	O
results	O
have	O
to	O
be	O
re-sorted	O
in	O
any	O
case	O
,	O
since	O
the	O
results	O
among	O
plural	O
speaker	O
classes	O
are	O
employed	O
.	O

4	O
)	O
Then	O
the	O
final	O
result	O
of	O
recognition	O
is	O
determined	O
by	O
a	O
backward	O
language	O
search	O
for	O
each	O
speaker	O
class	O
.	O
In	O
this	O
operation	O
,	O
the	O
result	O
of	O
the	O
forward	O
language	O
search	O
of	O
the	O
unspecified	O
speaker	O
is	O
used	O
as	O
the	O
huristic	O
cost	O
of	O
each	O
speaker	O
class	O
,	O
as	O
explained	O
above	O
.	O
In	O
the	O
backward	O
Viterbi	O
search	O
,	O
there	O
is	O
employed	O
the	O
output	O
probability	O
for	O
each	O
speaker	O
class	O
,	O
estimated	O
in	O
the	O
step	O
(	O
2	O
)	O
.	O

5	O
)	O
The	O
results	O
of	O
recognition	O
,	O
determined	O
for	O
the	O
different	O
speaker	O
classes	O
,	O
are	O
re-sorted	O
,	O
and	O
the	O
result	O
of	O
the	O
highest	O
likelihood	O
is	O
taken	O
as	O
the	O
result	O
of	O
recognition	O
of	O
the	O
first	O
rank	O
.	O

In	O
the	O
above-explained	O
method	O
,	O
most	O
of	O
the	O
calculations	O
that	O
may	O
contribute	O
to	O
the	O
result	O
of	O
recognition	O
is	O
made	O
by	O
the	O
information	O
relating	O
to	O
each	O
speaker	O
class	O
.	O

FIG	O
.	O
5	O
schematically	O
shows	O
the	O
comparison	O
of	O
the	O
process	O
time	O
of	O
the	O
speech	O
recognition	O
employing	O
the	O
speaker	O
class	O
HMM	O
,	O
in	O
the	O
conventional	O
method	O
and	O
in	O
the	O
method	O
of	O
the	O
present	O
invention	O
,	O
taking	O
the	O
process	O
time	O
along	O
the	O
abscissa	O
.	O
The	O
uppermost	O
graph	O
shows	O
the	O
process	O
time	O
of	O
the	O
conventional	O
recognition	O
employing	O
only	O
one	O
speaker	O
class	O
(	O
unspecified	O
speaker	O
class	O
)	O
,	O
and	O
the	O
second	O
graph	O
shows	O
the	O
process	O
time	O
of	O
the	O
recognition	O
employing	O
an	O
unspecified	O
speaker	O
class	O
,	O
made	O
faster	O
by	O
IDMM	O
+	O
SQ	O
(	O
present	O
invention	O
)	O
.	O
The	O
third	O
graph	O
shows	O
the	O
process	O
time	O
of	O
the	O
conventional	O
recognition	O
employing	O
IDMM	O
+	O
SQ	O
and	O
the	O
speaker	O
class	O
HMM	O
's	O
of	O
3	O
speaker	O
classes	O
simply	O
in	O
a	O
parallel	O
manner	O
(	O
as	O
shown	O
in	O
FIG	O
.	O
3	O
)	O
,	O
while	O
the	O
lowermost	O
graph	O
shows	O
the	O
process	O
time	O
of	O
the	O
high-speed	O
speech	O
recognition	O
method	O
with	O
3	O
speaker	O
classes	O
,	O
utilizing	O
the	O
proposed	O
speaker	O
class	O
HMM	O
's	O
(	O
as	O
shown	O
in	O
FIG	O
.	O
4	O
)	O
.	O
The	O
process	O
time	O
required	O
for	O
the	O
output	O
probability	O
calculation	O
(	O
Bjot	O
)	O
and	O
the	O
forward/backward	O
language	O
search	O
is	O
variable	O
,	O
depending	O
on	O
the	O
task	O
constituting	O
the	O
object	O
of	O
recognition	O
and	O
on	O
the	O
performance	O
of	O
HMM	O
's	O
,	O
but	O
can	O
be	O
considered	O
to	O
be	O
represented	O
as	O
a	O
reasonable	O
length	O
in	O
the	O
contemplated	O
range	O
.	O
However	O
the	O
process	O
time	O
required	O
for	O
the	O
backward	O
language	O
search	O
,	O
represented	O
as	O
considerably	O
long	O
in	O
these	O
graphs	O
,	O
is	O
less	O
than	O
0	O
.	O
1	O
seconds	O
in	O
practice	O
.	O

As	O
a	O
result	O
,	O
in	O
comparison	O
with	O
the	O
conventional	O
method	O
of	O
calculating	O
the	O
speaker	O
class	O
HMM	O
's	O
simply	O
in	O
a	O
parallel	O
manner	O
and	O
executing	O
the	O
IDMM	O
+	O
SQ	O
calculation	O
and	O
the	O
forward	O
Viterbi	O
search	O
by	O
the	O
number	O
N	O
of	O
the	O
speaker	O
classes	O
,	O
the	O
proposed	O
method	O
requires	O
the	O
IDMM	O
+	O
SQ	O
calculation	O
for	O
the	O
unspecified	O
speaker	O
HMM	O
and	O
the	O
forward	O
search	O
only	O
once	O
,	O
so	O
that	O
the	O
advantage	O
of	O
the	O
proposed	O
method	O
becomes	O
larger	O
with	O
the	O
increase	O
in	O
the	O
number	O
N.	O
On	O
the	O
other	O
hand	O
,	O
the	O
amount	O
of	O
the	O
output	O
probability	O
re-calculation	O
for	O
the	O
speaker	O
classes	O
and	O
of	O
the	O
backward	O
language	O
search	O
,	O
increasing	O
with	O
the	O
number	O
N	O
of	O
the	O
speaker	O
classes	O
,	O
is	O
limited	O
in	O
the	O
entire	O
calculations	O
.	O
Consequently	O
the	O
method	O
of	O
the	O
present	O
invention	O
can	O
be	O
executed	O
,	O
in	O
the	O
entire	O
process	O
,	O
at	O
a	O
very	O
high	O
speed	O
.	O

As	O
a	O
result	O
,	O
there	O
is	O
provided	O
an	O
increased	O
possibility	O
of	O
realizing	O
a	O
real-time	O
process	O
without	O
relying	O
on	O
a	O
high-speed	O
computer	O
or	O
parallel	O
computers	O
,	O
and	O
a	O
practical	O
speech	O
recognition	O
can	O
be	O
realized	O
.	O

[	O
Experimental	O
results	O
on	O
speech	O
recognition	O
with	O
speaker	O
class	O
HMM	O
'S	O
]	O
The	O
results	O
of	O
an	O
experiment	O
conducted	O
with	O
plural	O
speaker	O
classes	O
are	O
shown	O
in	O
FIG	O
.	O
7	O
.	O
The	O
speech	O
recognition	O
was	O
experimented	O
with	O
(	O
a	O
)	O
an	O
unspecified	O
speaker	O
class	O
(	O
g1	O
)	O
,	O
(	O
2	O
)	O
male	O
and	O
female	O
speaker	O
classes	O
(	O
g2	O
)	O
,	O
and	O
(	O
3	O
)	O
8	O
speaker	O
classes	O
consisting	O
of	O
four	O
male	O
classes	O
and	O
four	O
female	O
classes	O
(	O
g8	O
)	O
.	O
Phoneme	O
environment-dependent	O
HMM	O
's	O
of	O
6	O
distributions	O
for	O
3	O
states	O
were	O
prepared	O
for	O
each	O
of	O
the	O
above-mentioned	O
speaker	O
classes	O
(	O
1	O
)	O
-	O
(	O
3	O
)	O
(	O
238	O
kinds	O
in	O
total	O
)	O
,	O
and	O
a	O
recognition	O
experiment	O
was	O
conducted	O
for	O
520	O
words	O
(	O
telephone	O
speeches	O
)	O
pronounced	O
by	O
twenty	O
male	O
and	O
female	O
speakers	O
.	O

The	O
experimental	O
results	O
in	O
FIG	O
.	O
7	O
indicate	O
the	O
effect	O
of	O
the	O
use	O
of	O
the	O
speaker	O
classes	O
.	O
According	O
to	O
these	O
results	O
,	O
the	O
case	O
utilizing	O
the	O
unspecified	O
speaker	O
class	O
in	O
combination	O
with	O
the	O
speaker	O
classes	O
suppressed	O
the	O
percentage	O
of	O
maximum	O
deterioration	O
and	O
increased	O
the	O
percentages	O
of	O
maximum	O
improvement	O
and	O
of	O
mean	O
improvement	O
.	O

In	O
the	O
foregoing	O
there	O
has	O
been	O
explained	O
a	O
case	O
of	O
employing	O
the	O
unspecified	O
speaker	O
class	O
and	O
the	O
male	O
and	O
female	O
speaker	O
classes	O
,	O
but	O
there	O
may	O
also	O
be	O
employed	O
a	O
larger	O
number	O
of	O
the	O
speaker	O
classes	O
.	O

Also	O
in	O
the	O
foregoing	O
there	O
has	O
been	O
explained	O
a	O
case	O
of	O
utilizing	O
the	O
unspecified	O
speaker	O
class	O
in	O
the	O
common	O
output	O
probability	O
calculation	O
,	O
but	O
there	O
may	O
also	O
be	O
employed	O
any	O
parameter	O
that	O
can	O
be	O
determined	O
from	O
the	O
output	O
probability	O
values	O
of	O
the	O
speaker	O
classes	O
.	O
For	O
example	O
,	O
there	O
may	O
be	O
employed	O
the	O
maximum	O
value	O
of	O
the	O
output	O
probabilities	O
of	O
the	O
speaker	O
class	O
HMM	O
's	O
.	O

Furthermore	O
,	O
in	O
the	O
foregoing	O
there	O
has	O
been	O
explained	O
a	O
case	O
of	O
utilizing	O
IDMM	O
+	O
SQ	O
in	O
the	O
calculation	O
of	O
the	O
coarse	O
output	O
probability	O
,	O
but	O
there	O
may	O
also	O
be	O
employed	O
a	O
method	O
of	O
employing	O
HMM	O
of	O
a	O
smaller	O
population	O
for	O
the	O
coarse	O
output	O
probability	O
calculation	O
and	O
employing	O
HMM	O
of	O
a	O
larger	O
population	O
for	O
the	O
fine	O
output	O
probability	O
calculation	O
,	O
or	O
a	O
method	O
of	O
employing	O
phoneme	O
HMM	O
for	O
the	O
coarse	O
output	O
probability	O
calculation	O
and	O
employing	O
phoneme	O
environment-dependent	O
HMM	O
for	O
the	O
fine	O
output	O
probability	O
calculation	O
.	O

Furthermore	O
,	O
in	O
the	O
foregoing	O
there	O
has	O
been	O
explained	O
a	O
case	O
of	O
doubling	O
the	O
number	O
of	O
the	O
speaker	O
classes	O
for	O
each	O
hierarchic	O
level	O
,	O
but	O
the	O
number	O
of	O
the	O
speaker	O
classes	O
may	O
be	O
increased	O
in	O
any	O
manner	O
.	O

Furthermore	O
,	O
in	O
the	O
foregoing	O
there	O
has	O
been	O
explained	O
a	O
case	O
of	O
clustering	O
the	O
speakers	O
in	O
such	O
a	O
manner	O
that	O
the	O
speakers	O
do	O
not	O
overlap	O
between	O
the	O
different	O
classes	O
,	O
but	O
the	O
clustering	O
may	O
also	O
be	O
made	O
so	O
as	O
to	O
allow	O
such	O
overlapping	O
.	O

1	O
.	O
A	O
speech	O
recognition	O
method	O
comprising	O
the	O
steps	O
of	O
:	O
entering	O
speech	O
;	O
calculating	O
a	O
coarse	O
output	O
probability	O
of	O
said	O
input	O
speech	O
,	O
utilizing	O
an	O
unspecified	O
speaker	O
model	O
;	O
estimating	O
a	O
state	O
that	O
is	O
likely	O
to	O
contribute	O
to	O
a	O
result	O
of	O
recognition	O
,	O
based	O
on	O
a	O
result	O
of	O
said	O
calculation	O
step	O
and	O
determining	O
a	O
fine	O
output	O
probability	O
of	O
said	O
input	O
speech	O
,	O
utilizing	O
said	O
unspecified	O
speaker	O
model	O
and	O
plural	O
speaker	O
models	O
clustered	O
into	O
plural	O
speaker	O
classes	O
for	O
the	O
estimated	O
states	O
;	O
and	O
determining	O
the	O
result	O
of	O
recognition	O
of	O
said	O
input	O
speech	O
,	O
based	O
on	O
said	O
fine	O
output	O
probability	O
.	O

2	O
.	O
A	O
speech	O
recognition	O
method	O
according	O
to	O
claim	O
1	O
,	O
wherein	O
said	O
speaker	O
classes	O
are	O
prepared	O
in	O
a	O
hierarchic	O
structure	O
in	O
such	O
a	O
manner	O
that	O
each	O
speaker	O
belongs	O
,	O
in	O
a	O
specified	O
hierarchic	O
level	O
,	O
to	O
plural	O
speaker	O
classes	O
or	O
to	O
a	O
speaker	O
class	O
.	O

3	O
.	O
A	O
speech	O
recognition	O
method	O
according	O
to	O
claim	O
1	O
,	O
wherein	O
said	O
speaker	O
classes	O
are	O
prepared	O
by	O
the	O
steps	O
of	O
:	O
preparing	O
models	O
respectively	O
corresponding	O
to	O
sound	O
properties	O
from	O
the	O
input	O
speech	O
;	O
determining	O
a	O
speaker	O
class	O
to	O
which	O
said	O
input	O
speech	O
belongs	O
,	O
according	O
to	O
the	O
distance	O
from	O
said	O
prepared	O
models	O
;	O
and	O
memorizing	O
the	O
model	O
of	O
said	O
input	O
speech	O
as	O
said	O
determined	O
speaker	O
class	O
.	O

4	O
.	O
A	O
speech	O
recognition	O
method	O
according	O
to	O
claim	O
3	O
,	O
wherein	O
said	O
model	O
prepared	O
for	O
each	O
sound	O
property	O
is	O
a	O
phoneme	O
Hidden	O
Markov	O
Model	O
.	O

5	O
.	O
A	O
speech	O
recognition	O
method	O
according	O
to	O
claim	O
3	O
,	O
wherein	O
said	O
models	O
for	O
respective	O
sound	O
properties	O
are	O
phoneme	O
models	O
,	O
and	O
the	O
sum	O
of	O
the	O
distances	O
between	O
the	O
models	O
,	O
in	O
mutually	O
corresponding	O
states	O
of	O
the	O
phoneme	O
models	O
used	O
for	O
calculating	O
said	O
distance	O
of	O
the	O
models	O
,	O
is	O
used	O
as	O
the	O
distance	O
between	O
the	O
models	O
for	O
determining	O
said	O
speaker	O
class	O
.	O

6	O
.	O
A	O
speech	O
recognition	O
method	O
according	O
to	O
claim	O
3	O
,	O
wherein	O
a	O
Bhattacharyya	O
distance	O
is	O
used	O
as	O
said	O
distance	O
between	O
the	O
models	O
.	O

7	O
.	O
A	O
speech	O
recognition	O
method	O
according	O
to	O
claim	O
3	O
,	O
wherein	O
a	O
Kullback	O
information	O
amount	O
is	O
used	O
as	O
said	O
distance	O
between	O
the	O
models	O
.	O

8	O
.	O
A	O
speech	O
recognition	O
method	O
according	O
to	O
claim	O
3	O
,	O
wherein	O
an	O
Euclid	O
distance	O
is	O
used	O
as	O
said	O
distance	O
between	O
the	O
models	O
.	O

9	O
.	O
A	O
speech	O
recognition	O
method	O
according	O
to	O
claim	O
1	O
,	O
wherein	O
:	O
a	O
language	O
search	O
is	O
conducted	O
according	O
to	O
the	O
result	O
of	O
calculation	O
of	O
said	O
fine	O
output	O
probability	O
and	O
a	O
judgment	O
according	O
to	O
predetermined	O
language	O
limitation	O
;	O
and	O
the	O
result	O
of	O
said	O
language	O
search	O
is	O
outputted	O
as	O
the	O
result	O
of	O
recognition	O
of	O
said	O
input	O
speech	O
.	O

10	O
.	O
A	O
speech	O
recognition	O
method	O
according	O
to	O
claim	O
9	O
,	O
wherein	O
,	O
in	O
said	O
output	O
probability	O
calculation	O
and	O
language	O
search	O
:	O
the	O
output	O
probability	O
calculation	O
of	O
a	O
portion	O
to	O
be	O
calculated	O
in	O
common	O
is	O
conducted	O
by	O
a	O
forward	O
search	O
;	O
and	O
the	O
result	O
of	O
recognition	O
of	O
said	O
input	O
speech	O
is	O
determined	O
by	O
executing	O
the	O
output	O
probability	O
calculation	O
in	O
portions	O
other	O
than	O
said	O
portion	O
to	O
be	O
calculated	O
in	O
common	O
by	O
a	O
backward	O
search	O
,	O
for	O
each	O
of	O
the	O
unspecified	O
speaker	O
model	O
and	O
the	O
models	O
of	O
the	O
clustered	O
speaker	O
classes	O
.	O

11	O
.	O
A	O
speech	O
recognition	O
method	O
according	O
to	O
claim	O
9	O
,	O
wherein	O
,	O
the	O
language	O
search	O
for	O
said	O
plural	O
speaker	O
class	O
models	O
comprises	O
the	O
steps	O
of	O
:	O
determining	O
a	O
predetermined	O
output	O
probability	O
based	O
on	O
the	O
output	O
probability	O
determined	O
at	O
each	O
time	O
of	O
plural	O
speaker	O
classes	O
;	O
and	O
executing	O
a	O
common	O
language	O
search	O
based	O
on	O
said	O
predetermined	O
output	O
probability	O
.	O

12	O
.	O
A	O
speech	O
recognition	O
method	O
according	O
to	O
claim	O
11	O
,	O
wherein	O
said	O
predetermined	O
output	O
probability	O
is	O
taken	O
as	O
the	O
output	O
probability	O
of	O
the	O
unspecified	O
speaker	O
.	O

13	O
.	O
A	O
speech	O
recognition	O
method	O
according	O
to	O
claim	O
11	O
,	O
wherein	O
said	O
predetermined	O
output	O
probability	O
is	O
taken	O
as	O
the	O
maximum	O
value	O
in	O
the	O
output	O
probabilities	O
of	O
the	O
speaker	O
classes	O
.	O

14	O
.	O
A	O
speech	O
recognition	O
method	O
according	O
to	O
claim	O
1	O
,	O
wherein	O
said	O
unspecified	O
speaker	O
model	O
is	O
taken	O
as	O
an	O
upper	O
hierarchic	O
model	O
of	O
said	O
speaker	O
models	O
.	O

15	O
.	O
A	O
speech	O
recognition	O
method	O
according	O
to	O
claim	O
1	O
,	O
wherein	O
a	O
fine	O
re-calculation	O
of	O
said	O
output	O
probability	O
is	O
executed	O
for	O
all	O
the	O
speaker	O
models	O
.	O

16	O
.	O
A	O
speech	O
recognition	O
method	O
according	O
to	O
claim	O
1	O
,	O
wherein	O
the	O
calculation	O
of	O
the	O
result	O
of	O
analysis	O
of	O
said	O
input	O
speech	O
and	O
of	O
the	O
output	O
probability	O
of	O
the	O
unspecified	O
speaker	O
model	O
is	O
executed	O
,	O
utilizing	O
a	O
scaler	O
quantization	O
and	O
dimensionally	O
independent	O
high-speed	O
output	O
probability	O
calculation	O
method	O
for	O
a	O
Hidden	O
Markov	O
Model	O
.	O

17	O
.	O
A	O
speech	O
recognition	O
apparatus	O
comprising	O
:	O
input	O
means	O
for	O
entering	O
speech	O
;	O
coarse	O
output	O
probability	O
calculation	O
means	O
for	O
calculating	O
a	O
coarse	O
output	O
probability	O
of	O
said	O
input	O
speech	O
,	O
utilizing	O
an	O
unspecified	O
speaker	O
model	O
;	O
fine	O
output	O
probability	O
calculation	O
means	O
for	O
estimating	O
a	O
state	O
that	O
is	O
likely	O
to	O
contribute	O
to	O
a	O
result	O
of	O
recognition	O
,	O
based	O
on	O
a	O
result	O
of	O
calculation	O
by	O
said	O
coarse	O
output	O
probability	O
calculation	O
means	O
and	O
determining	O
a	O
fine	O
output	O
probability	O
of	O
said	O
input	O
speech	O
,	O
utilizing	O
said	O
unspecified	O
speaker	O
model	O
and	O
plural	O
speaker	O
models	O
clustered	O
into	O
plural	O
speaker	O
classes	O
for	O
the	O
estimated	O
states	O
;	O
and	O
recognition	O
result	O
determination	O
means	O
for	O
determining	O
the	O
result	O
of	O
recognition	O
of	O
said	O
input	O
speech	O
based	O
on	O
said	O
fine	O
output	O
probability	O
.	O

18	O
.	O
A	O
speech	O
recognition	O
apparatus	O
according	O
to	O
claim	O
17	O
,	O
wherein	O
said	O
speaker	O
classes	O
are	O
prepared	O
in	O
a	O
hierarchic	O
structure	O
in	O
such	O
a	O
manner	O
that	O
each	O
speaker	O
belongs	O
,	O
in	O
a	O
specified	O
hierarchic	O
level	O
,	O
to	O
plural	O
speaker	O
classes	O
or	O
to	O
a	O
speaker	O
class	O
.	O

19	O
.	O
A	O
speech	O
recognition	O
apparatus	O
according	O
to	O
claim	O
17	O
,	O
further	O
comprising	O
:	O
sound	O
property	O
model	O
preparation	O
means	O
for	O
preparing	O
models	O
respectively	O
corresponding	O
to	O
sound	O
properties	O
from	O
the	O
input	O
speech	O
;	O
speaker	O
class	O
determination	O
means	O
for	O
determining	O
a	O
speaker	O
class	O
to	O
which	O
said	O
input	O
speech	O
belongs	O
,	O
according	O
to	O
the	O
distance	O
from	O
said	O
prepared	O
models	O
prepared	O
by	O
said	O
sound	O
property	O
model	O
preparation	O
means	O
;	O
and	O
speaker	O
model	O
preparation	O
means	O
for	O
memorizing	O
the	O
model	O
of	O
said	O
input	O
speech	O
as	O
the	O
speaker	O
class	O
determined	O
by	O
said	O
speaker	O
class	O
determination	O
means	O
,	O
thereby	O
preparing	O
a	O
speaker	O
model	O
for	O
the	O
input	O
speech	O
.	O

20	O
.	O
A	O
speech	O
recognition	O
apparatus	O
according	O
to	O
claim	O
19	O
,	O
wherein	O
said	O
model	O
prepared	O
for	O
each	O
sound	O
property	O
is	O
a	O
phoneme	O
Hidden	O
Markov	O
Model	O
.	O

21	O
.	O
A	O
speech	O
recognition	O
apparatus	O
according	O
to	O
claim	O
19	O
,	O
wherein	O
said	O
models	O
for	O
respective	O
sound	O
properties	O
are	O
phoneme	O
models	O
,	O
and	O
the	O
sum	O
of	O
the	O
distances	O
between	O
the	O
models	O
,	O
in	O
mutually	O
corresponding	O
states	O
of	O
the	O
phoneme	O
models	O
used	O
for	O
calculating	O
said	O
distance	O
of	O
the	O
models	O
,	O
is	O
used	O
as	O
the	O
distance	O
between	O
the	O
models	O
for	O
determining	O
said	O
speaker	O
class	O
.	O

22	O
.	O
A	O
speech	O
recognition	O
apparatus	O
according	O
to	O
claim	O
19	O
,	O
wherein	O
a	O
Bhattacharyya	O
distance	O
is	O
used	O
as	O
said	O
distance	O
between	O
the	O
models	O
.	O

23	O
.	O
A	O
speech	O
recognition	O
apparatus	O
according	O
to	O
claim	O
19	O
,	O
wherein	O
a	O
Kullback	O
information	O
amount	O
is	O
used	O
as	O
said	O
distance	O
between	O
the	O
models	O
.	O

24	O
.	O
A	O
speech	O
recognition	O
apparatus	O
according	O
to	O
claim	O
19	O
,	O
wherein	O
an	O
Euclid	O
distance	O
is	O
used	O
as	O
said	O
distance	O
between	O
the	O
models	O
.	O

25	O
.	O
A	O
speech	O
recognition	O
apparatus	O
according	O
to	O
claim	O
17	O
,	O
further	O
comprising	O
:	O
language	O
search	O
means	O
for	O
conducting	O
a	O
language	O
search	O
according	O
to	O
the	O
result	O
of	O
calculation	O
of	O
said	O
fine	O
output	O
probability	O
and	O
a	O
judgment	O
according	O
to	O
a	O
predetermined	O
language	O
limitation	O
;	O
wherein	O
said	O
recognition	O
result	O
determination	O
means	O
determines	O
the	O
result	O
of	O
searching	O
by	O
said	O
language	O
search	O
means	O
as	O
the	O
result	O
of	O
recognition	O
of	O
said	O
input	O
speech	O
.	O

26	O
.	O
A	O
speech	O
recognition	O
apparatus	O
according	O
to	O
claim	O
25	O
,	O
wherein	O
said	O
language	O
search	O
means	O
executes	O
the	O
output	O
probability	O
calculation	O
of	O
a	O
portion	O
to	O
be	O
calculated	O
in	O
common	O
by	O
a	O
forward	O
search	O
,	O
and	O
executes	O
the	O
output	O
probability	O
calculation	O
in	O
portions	O
other	O
than	O
said	O
portion	O
to	O
be	O
calculated	O
in	O
common	O
by	O
a	O
backward	O
search	O
,	O
for	O
each	O
of	O
the	O
unspecified	O
speaker	O
model	O
and	O
the	O
models	O
of	O
the	O
clustered	O
speaker	O
classes	O
.	O

27	O
.	O
A	O
speech	O
recognition	O
apparatus	O
according	O
to	O
claim	O
25	O
,	O
wherein	O
said	O
language	O
search	O
means	O
,	O
in	O
the	O
language	O
search	O
for	O
said	O
plural	O
speaker	O
class	O
models	O
,	O
determines	O
a	O
predetermined	O
output	O
probability	O
based	O
on	O
the	O
output	O
probability	O
determined	O
at	O
each	O
time	O
of	O
plural	O
speaker	O
classes	O
,	O
and	O
executes	O
a	O
common	O
language	O
search	O
,	O
based	O
on	O
said	O
predetermined	O
output	O
probability	O
.	O

28	O
.	O
A	O
speech	O
recognition	O
apparatus	O
according	O
to	O
claim	O
27	O
,	O
wherein	O
said	O
predetermined	O
output	O
probability	O
is	O
taken	O
as	O
the	O
output	O
probability	O
of	O
the	O
unspecified	O
speaker	O
.	O

29	O
.	O
A	O
speech	O
recognition	O
apparatus	O
according	O
to	O
claim	O
27	O
,	O
wherein	O
said	O
predetermined	O
output	O
probability	O
is	O
taken	O
as	O
the	O
maximum	O
value	O
in	O
the	O
output	O
probabilities	O
of	O
the	O
speaker	O
classes	O
.	O

30	O
.	O
A	O
speech	O
recognition	O
apparatus	O
according	O
to	O
claim	O
17	O
,	O
wherein	O
said	O
unspecified	O
speaker	O
model	O
is	O
taken	O
as	O
an	O
upper	O
hierarchic	O
model	O
of	O
said	O
speaker	O
models	O
.	O

31	O
.	O
A	O
speech	O
recognition	O
apparatus	O
according	O
to	O
claim	O
17	O
,	O
wherein	O
a	O
fine	O
re-calculation	O
of	O
said	O
output	O
probability	O
is	O
executed	O
for	O
all	O
the	O
speaker	O
models	O
.	O

32	O
.	O
A	O
speech	O
recognition	O
apparatus	O
according	O
to	O
claim	O
17	O
,	O
wherein	O
the	O
calculation	O
of	O
the	O
result	O
of	O
analysis	O
of	O
said	O
input	O
speech	O
and	O
of	O
the	O
output	O
probability	O
of	O
the	O
unspecified	O
speaker	O
model	O
is	O
executed	O
,	O
utilizing	O
a	O
scaler	O
quantization	O
and	O
dimensionally	O
independent	O
high-speed	O
output	O
probability	O
calculation	O
method	O
for	O
a	O
Hidden	O
Markov	O
Model	O
.	O

