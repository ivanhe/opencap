US	O
5907824	O
A	O
19990525	O

US	O
08794449	O
19970204	O

eng	O
eng	O

GB	O
9602700	O
A	O
19960209	O

9602700	O

GB19960002700	O

19990525	O

19990525	O

6G	O
10L	O
5/06	O
A	O
6	O
G	O
10	O
L	O
5	O
06	O
A	O

G10L	O
15/12	O
20060101AFI20060310RMJP	O

20060101	O

A	O
G	O
10	O
L	O
15	O
12	O
F	O
I	O

20060310	O

JP	O

R	O
M	O

G10L	O
15/00	O
20060101C	O
I20060722RMEP	O

20060101	O

C	O
G	O
10	O
L	O
15	O
00	O
I	O

20060722	O

EP	O

R	O
M	O

G10L	O
15/08	O
20060101A	O
I20060722RMEP	O

20060101	O

A	O
G	O
10	O
L	O
15	O
08	O
I	O

20060722	O

EP	O

R	O
M	O

G10L	O
15/28	O
20060101ALI20060310RMJP	O

20060101	O

A	O
G	O
10	O
L	O
15	O
28	O
L	O
I	O

20060310	O

JP	O

R	O
M	O

US	O

704/242	O
704	O
242	O

704/E15.014	O
704	O
E15	O
.	O
014	O

G10L	O
15/08	O
G	O
10	O
L	O
15	O
08	O

S10L	O
15	O
:	O
08S	O
S	O
10	O
L	O
15	O
08	O

S	O

US	O

704/241	O
704	O
241	O

US	O

704/242	O
704	O
242	O

US	O

704/236-240	O
704	O
236	O
-	O
240	O

US	O

704/232	O
704	O
232	O

US	O

704/255	O
704	O
255	O

55	O
Pattern	O
matching	O
system	O
which	O
uses	O
a	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
to	O
adjust	O
a	O
pruning	O
threshold	O

US	O
5007081	O
A	O
Schmuckal	O
et_al.	O

19910409	O

19890105	O

US	O

379/354	O
379	O
354	O

US	O
5345537	O
A	O
Tanaka	O
19940906	O

19911219	O

US	O

395/2	O
.	O
64	O
395	O
2	O
.	O
64	O

US	O
5577162	O
A	O
Yamazaki	O
19961119	O

19941011	O

US	O

704/232	O
704	O
232	O

US	O
5677990	O
A	O
Junqua	O
19971014	O

19950505	O

US	O

704/255	O
704	O
255	O

US	O
5706397	O
A	O
Chow	O
19980106	O

19951005	O

US	O

704/243	O
704	O
243	O

EP	O
38163	O
A1	O
19811021	O

19810407	O

EP	O
248377	O
A2	O
19871209	O

19870601	O

EP	O
392728	O
A2	O
19901017	O

19900404	O

EP	O
525640	O
A2	O
19930203	O

19920723	O

US	O
7630888	O
B2	O
20091208	O

20051018	O

US	O
6993479	O
B1	O
20060131	O

19980623	O

US	O
6859794	O
B2	O
20050222	O

20010302	O

US	O
6725196	O
B2	O
20040420	O

20010320	O

US	O
6556967	O
B1	O
20030429	O

19990312	O

US	O
6560575	O
B1	O
20030506	O

19990930	O

US	O
6327564	O
B1	O
20011204	O

19990305	O

US	O
6226610	O
B1	O
20010501	O

19990208	O

US	O
6240389	O
B1	O
20010529	O

19990208	O

Canon	O
Kabushiki	O
Kaisha	O

Tokyo	O
JP	O

Tzirkel-Hancock	O
Eli	O

Surrey	O
GB	O

Fitzpatrick	O
,	O
Cella	O
,	O
Harper	O
&	O
Scinto	O

Hudspeth	O
;	O
David	O
R.	O

Storm	O
;	O
Donald	O
L.	O

EP	O
789348	O
B1	O
20020123	O

19970207	O

EP	O
789348	O
A1	O
19970813	O

19970207	O

GB	O
9602700	O
D0	O
19960410	O

19960209	O

JP	O
09230888	O
A	O
19970905	O

19970210	O

DE	O
69709965	O
D1	O
20020314	O

19970207	O

US	O
5907824	O
A	O
19990525	O

19970204	O

US	O
5907824	O
A	O
19990525	O

19970204	O

EP	O
789348	O
B1	O
20020123	O

19970207	O

EP	O
789348	O
A1	O
19970813	O

19970207	O

GB	O
9602700	O
D0	O
19960410	O

19960209	O

JP	O
09230888	O
A	O
19970905	O

19970210	O

DE	O
69709965	O
D1	O
20020314	O

19970207	O

A	O
pattern	O
matching	O
method	O
for	O
matching	O
a	O
time	O
varying	O
input	O
signal	O
with	O
a	O
number	O
of	O
sequences	O
of	O
time	O
varying	O
reference	O
signals	O
.	O
The	O
method	O
includes	O
a	O
dynamic	O
programming	O
matching	O
process	O
which	O
processes	O
each	O
pattern	O
of	O
the	O
input	O
signal	O
in	O
sequence	O
and	O
which	O
propagates	O
a	O
plurality	O
of	O
dynamic	O
programming	O
paths	O
using	O
predetermined	O
dynamic	O
programming	O
constraints	O
,	O
controlling	O
the	O
matching	O
step	O
by	O
comparing	O
the	O
cumulative	O
value	O
associated	O
with	O
each	O
path	O
with	O
a	O
pruning	O
value	O
thereby	O
to	O
restrict	O
the	O
number	O
of	O
paths	O
that	O
were	O
propagated	O
from	O
a	O
preceding	O
time	O
point	O
,	O
when	O
the	O
preceding	O
input	O
pattern	O
was	O
being	O
processed	O
in	O
the	O
matching	O
step	O
,	O
from	O
being	O
propagated	O
further	O
during	O
the	O
processing	O
of	O
the	O
input	O
pattern	O
at	O
a	O
current	O
time	O
point	O
by	O
the	O
matching	O
step	O
,	O
determining	O
at	O
the	O
current	O
time	O
point	O
,	O
a	O
number	O
of	O
possible	O
paths	O
that	O
will	O
be	O
propagating	O
at	O
the	O
succeeding	O
time	O
point	O
,	O
prior	O
to	O
restriction	O
by	O
the	O
controlling	O
step	O
,	O
when	O
the	O
succeeding	O
input	O
pattern	O
will	O
by	O
processed	O
by	O
the	O
matching	O
step	O
,	O
and	O
altering	O
the	O
pruning	O
value	O
to	O
be	O
used	O
at	O
the	O
succeeding	O
time	O
point	O
in	O
dependence	O
upon	O
the	O
number	O
of	O
possible	O
paths	O
determined	O
by	O
the	O
determining	O
step	O
,	O
counting	O
the	O
number	O
of	O
paths	O
which	O
have	O
been	O
propagated	O
to	O
the	O
succeeding	O
input	O
pattern	O
,	O
wherein	O
the	O
altering	O
step	O
adjusts	O
the	O
value	O
of	O
the	O
variable	O
to	O
be	O
equal	O
to	O
a	O
set	O
maximum	O
value	O
if	O
the	O
variable	O
has	O
been	O
adjusted	O
to	O
be	O
greater	O
than	O
that	O
maximum	O
and	O
adjusts	O
the	O
value	O
of	O
the	O
variable	O
to	O
be	O
equal	O
to	O
a	O
set	O
minimum	O
value	O
if	O
the	O
variable	O
is	O
adjusted	O
to	O
be	O
less	O
than	O
that	O
minimum	O
value	O
.	O

19970710	O

AS	O
ASSIGNMENT	O
N	O
US	O
5907824A	O
CANON	O
KABUSHIKI	O
KAISHA	O
,	O
JAPAN	O
ASSIGNMENT	O
OF	O
ASSIGNORS	O
INTEREST;ASSIGNOR:TZIRKEL-HANCOCK	O
,	O
ELI;REEL/FRAME:008598/0143	O

19970626	O

20000118	O

CC	O
CERTIFICATE	O
OF	O
CORRECTION	O
C	O
US	O
5907824A	O

20000502	O

CC	O
CERTIFICATE	O
OF	O
CORRECTION	O
C	O
US	O
5907824A	O

20021101	O

FPAY	O
+	O
FEE	O
PAYMENT	O
N	O
US	O
5907824A	O
4	O

20061103	O

FPAY	O
+	O
FEE	O
PAYMENT	O
N	O
US	O
5907824A	O
8	O

20101028	O

FPAY	O
+	O
FEE	O
PAYMENT	O
N	O
US	O
5907824A	O
12	O

The	O
present	O
invention	O
relates	O
to	O
a	O
method	O
of	O
and	O
apparatus	O
for	O
pattern	O
matching	O
.	O
The	O
invention	O
has	O
particular	O
,	O
although	O
not	O
exclusive	O
relevance	O
to	O
the	O
adjustment	O
of	O
a	O
pruning	O
threshold	O
used	O
in	O
a	O
dynamic	O
programming	O
pattern	O
matching	O
technique	O
.	O
In	O
an	O
exemplary	O
embodiment	O
,	O
the	O
dynamic	O
programming	O
matching	O
technique	O
is	O
employed	O
in	O
a	O
speech	O
recognition	O
system	O
.	O

Speech	O
recognition	O
is	O
a	O
process	O
by	O
which	O
an	O
unknown	O
speech	O
utterance	O
is	O
identified	O
.	O
There	O
are	O
several	O
different	O
types	O
of	O
speech	O
recognition	O
systems	O
currently	O
available	O
which	O
can	O
be	O
categorised	O
in	O
several	O
ways	O
.	O
For	O
example	O
,	O
some	O
systems	O
are	O
speaker	O
dependent	O
,	O
whereas	O
others	O
are	O
speaker	O
independent	O
.	O
Some	O
systems	O
operate	O
for	O
a	O
large	O
vocabulary	O
of	O
words	O
(	O
>	O
10	O
,	O
000	O
words	O
)	O
while	O
others	O
only	O
operate	O
with	O
a	O
limited	O
sized	O
vocabulary	O
(	O
<	O
1000	O
words	O
)	O
.	O
Some	O
systems	O
can	O
only	O
recognise	O
isolated	O
words	O
whereas	O
others	O
can	O
recognise	O
phrases	O
comprising	O
a	O
series	O
of	O
connected	O
words	O
.	O

In	O
a	O
limited	O
vocabulary	O
system	O
,	O
speech	O
recognition	O
is	O
performed	O
by	O
comparing	O
features	O
of	O
an	O
unknown	O
utterance	O
with	O
features	O
of	O
known	O
words	O
which	O
are	O
stored	O
in	O
a	O
database	O
.	O
The	O
features	O
of	O
the	O
known	O
words	O
are	O
determined	O
during	O
a	O
training	O
session	O
in	O
which	O
one	O
or	O
more	O
samples	O
of	O
the	O
known	O
words	O
are	O
used	O
to	O
generate	O
reference	O
patterns	O
therefor	O
.	O

To	O
recognise	O
the	O
unknown	O
utterance	O
,	O
the	O
speech	O
recognition	O
apparatus	O
extracts	O
a	O
pattern	O
(	O
or	O
features	O
)	O
from	O
the	O
utterance	O
and	O
compares	O
it	O
against	O
each	O
reference	O
pattern	O
stored	O
in	O
a	O
database	O
.	O
One	O
way	O
of	O
comparing	O
the	O
pattern	O
representative	O
of	O
the	O
input	O
utterance	O
with	O
the	O
reference	O
patterns	O
is	O
to	O
use	O
a	O
dynamic	O
programming	O
matching	O
technique	O
,	O
which	O
provides	O
an	O
optimal	O
time	O
alignment	O
between	O
each	O
of	O
the	O
reference	O
patterns	O
and	O
the	O
pattern	O
extracted	O
from	O
the	O
unknown	O
utterance	O
.	O
This	O
is	O
achieved	O
by	O
locally	O
shrinking	O
or	O
expanding	O
the	O
time	O
axis	O
of	O
one	O
pattern	O
until	O
there	O
is	O
an	O
optimal	O
match	O
between	O
the	O
pairs	O
of	O
patterns	O
.	O
The	O
reference	O
pattern	O
or	O
sequence	O
of	O
reference	O
patterns	O
providing	O
the	O
best	O
match	O
identifies	O
the	O
word	O
or	O
words	O
most	O
likely	O
to	O
correspond	O
to	O
the	O
input	O
utterance	O
.	O

One	O
problem	O
with	O
the	O
dynamic	O
programming	O
matching	O
technique	O
is	O
that	O
it	O
is	O
computationally	O
expensive	O
,	O
since	O
it	O
involves	O
the	O
determination	O
of	O
many	O
possible	O
matchings	O
between	O
the	O
incoming	O
utterance	O
and	O
each	O
reference	O
model	O
.	O

During	O
the	O
matching	O
process	O
,	O
each	O
possible	O
matching	O
is	O
given	O
a	O
score	O
which	O
is	O
dependent	O
upon	O
the	O
closeness	O
of	O
the	O
match	O
.	O
One	O
method	O
used	O
to	O
limit	O
the	O
amount	O
of	O
computations	O
involved	O
in	O
the	O
dynamic	O
programming	O
matching	O
technique	O
is	O
to	O
stop	O
the	O
processing	O
of	O
badly	O
scoring	O
matchings	O
.	O
In	O
the	O
art	O
of	O
speech	O
recognition	O
,	O
this	O
technique	O
is	O
known	O
as	O
pruning	O
.	O
However	O
,	O
a	O
problem	O
with	O
using	O
the	O
pruning	O
technique	O
is	O
that	O
the	O
number	O
of	O
possible	O
matchings	O
varies	O
considerably	O
and	O
if	O
there	O
is	O
only	O
a	O
fixed	O
amount	O
of	O
memory	O
available	O
,	O
then	O
memory	O
overflow	O
may	O
arise	O
.	O

EP	O
0525640	O
(	O
Fujitsu	O
Limited	O
)	O
solves	O
this	O
problem	O
by	O
varying	O
the	O
threshold	O
to	O
ensure	O
that	O
the	O
number	O
of	O
possible	O
matchings	O
processed	O
at	O
each	O
time	O
point	O
lies	O
between	O
a	O
given	O
minimum	O
and	O
maximum	O
number	O
.	O
In	O
particular	O
,	O
the	O
pruning	O
threshold	O
is	O
varied	O
in	O
dependence	O
upon	O
a	O
predicted	O
number	O
of	O
possible	O
matchings	O
that	O
will	O
have	O
to	O
be	O
processed	O
at	O
the	O
next	O
time	O
point	O
.	O
The	O
predicted	O
number	O
is	O
derived	O
from	O
a	O
linear	O
extrapolation	O
of	O
the	O
number	O
of	O
possible	O
matchings	O
which	O
were	O
processed	O
at	O
a	O
current	O
time	O
point	O
and	O
the	O
number	O
of	O
possible	O
matchings	O
which	O
were	O
processed	O
at	O
a	O
proceeding	O
time	O
point	O
.	O
The	O
process	O
employed	O
in	O
EP	O
0525640	O
ensures	O
that	O
the	O
actual	O
number	O
of	O
possible	O
matchings	O
at	O
each	O
time	O
point	O
lies	O
between	O
the	O
given	O
minimum	O
and	O
maximum	O
number	O
by	O
counting	O
the	O
possible	O
matchings	O
for	O
a	O
given	O
threshold	O
and	O
adjusting	O
the	O
threshold	O
until	O
the	O
condition	O
is	O
satisfied	O
.	O

The	O
present	O
invention	O
addresses	O
the	O
same	O
problem	O
but	O
aims	O
to	O
provide	O
a	O
simpler	O
and	O
less	O
computationally	O
expensive	O
solution	O
.	O

According	O
to	O
one	O
aspect	O
,	O
the	O
present	O
invention	O
provides	O
a	O
method	O
of	O
and	O
apparatus	O
for	O
varying	O
the	O
pruning	O
threshold	O
used	O
in	O
a	O
matching	O
process	O
,	O
wherein	O
the	O
threshold	O
adjustment	O
factor	O
used	O
to	O
define	O
the	O
threshold	O
is	O
varied	O
in	O
dependence	O
upon	O
the	O
number	O
of	O
dynamic	O
programming	O
paths	O
that	O
would	O
have	O
to	O
be	O
processed	O
for	O
the	O
next	O
input	O
frame	O
if	O
there	O
was	O
no	O
pruning	O
.	O

An	O
embodiment	O
of	O
the	O
present	O
invention	O
provides	O
a	O
pattern	O
matching	O
method	O
for	O
matching	O
a	O
sequence	O
of	O
input	O
patterns	O
representative	O
of	O
an	O
input	O
signal	O
with	O
a	O
number	O
of	O
sequences	O
of	O
reference	O
patterns	O
,	O
each	O
sequence	O
being	O
representative	O
of	O
a	O
reference	O
signal	O
,	O
the	O
method	O
comprising	O
the	O
steps	O
of	O
:	O
matching	O
the	O
input	O
signal	O
with	O
each	O
reference	O
signal	O
by	O
using	O
a	O
process	O
which	O
processes	O
each	O
pattern	O
of	O
said	O
input	O
signal	O
in	O
sequence	O
and	O
which	O
determines	O
cumulative	O
values	O
;	O
controlling	O
said	O
matching	O
process	O
by	O
comparing	O
said	O
cumulative	O
values	O
with	O
a	O
pruning	O
value	O
thereby	O
to	O
restrict	O
the	O
number	O
of	O
possible	O
matchings	O
being	O
propagated	O
from	O
a	O
preceding	O
time	O
point	O
to	O
a	O
current	O
time	O
point	O
;	O
determining	O
the	O
number	O
of	O
possible	O
matchings	O
that	O
will	O
be	O
propagated	O
to	O
the	O
succeeding	O
time	O
point	O
,	O
prior	O
to	O
restriction	O
by	O
said	O
controlling	O
step	O
;	O
and	O
altering	O
the	O
pruning	O
value	O
used	O
at	O
said	O
succeeding	O
time	O
point	O
in	O
dependence	O
upon	O
the	O
number	O
of	O
possible	O
matchings	O
determined	O
by	O
said	O
determining	O
step	O
.	O
The	O
input	O
signal	O
may	O
be	O
representative	O
of	O
a	O
speech	O
signal	O
,	O
and	O
each	O
pattern	O
may	O
comprise	O
a	O
number	O
of	O
parameters	O
representative	O
of	O
the	O
acoustic	O
properties	O
of	O
the	O
input	O
speech	O
signal	O
during	O
a	O
corresponding	O
time	O
frame	O
.	O
An	O
upper	O
and	O
lower	O
limit	O
may	O
be	O
placed	O
on	O
the	O
amount	O
that	O
the	O
pruning	O
value	O
can	O
be	O
increased	O
or	O
decreased	O
at	O
each	O
time	O
point	O
.	O

In	O
a	O
preferred	O
embodiment	O
,	O
if	O
the	O
number	O
determined	O
by	O
the	O
determining	O
means	O
is	O
greater	O
than	O
a	O
matching	O
threshold	O
,	O
then	O
the	O
threshold	O
is	O
varied	O
in	O
dependence	O
upon	O
the	O
number	O
of	O
cumulative	O
values	O
determined	O
by	O
the	O
matching	O
means	O
for	O
the	O
current	O
input	O
pattern	O
.	O
Preferably	O
the	O
matching	O
step	O
propagates	O
the	O
possible	O
matchings	O
to	O
the	O
next	O
time	O
point	O
at	O
the	O
current	O
time	O
point	O
,	O
and	O
wherein	O
the	O
determining	O
step	O
determines	O
the	O
number	O
of	O
possible	O
matchings	O
that	O
are	O
propagated	O
in	O
the	O
matching	O
step	O
.	O

Various	O
embodiments	O
of	O
the	O
invention	O
will	O
now	O
be	O
described	O
,	O
by	O
way	O
of	O
example	O
only	O
,	O
with	O
reference	O
to	O
the	O
accompanying	O
drawings	O
in	O
which	O
:	O
FIG	O
.	O
1	O
is	O
a	O
schematic	O
view	O
of	O
a	O
computer	O
which	O
may	O
be	O
programmed	O
to	O
operate	O
an	O
embodiment	O
of	O
the	O
present	O
invention	O
;	O
FIG	O
.	O
2	O
is	O
a	O
schematic	O
overview	O
of	O
a	O
speech	O
recognition	O
system	O
;	O
FIG	O
.	O
3	O
is	O
a	O
block	O
diagram	O
of	O
the	O
preprocessor	O
incorporated	O
as	O
part	O
of	O
the	O
system	O
shown	O
in	O
FIG	O
.	O
2	O
which	O
illustrates	O
the	O
processing	O
steps	O
that	O
are	O
performed	O
on	O
the	O
input	O
speech	O
signal	O
;	O
FIG	O
.	O
4	O
is	O
a	O
diagrammatical	O
representation	O
of	O
the	O
division	O
of	O
the	O
input	O
speech	O
signal	O
S	O
(	O
t	O
)	O
into	O
a	O
series	O
of	O
time	O
frames	O
;	O
FIG	O
.	O
5	O
is	O
a	O
diagrammatical	O
representation	O
of	O
a	O
typical	O
speech	O
signal	O
for	O
a	O
single	O
time	O
frame	O
;	O
FIG	O
.	O
6	O
is	O
a	O
diagrammatical	O
representation	O
of	O
the	O
magnitude	O
response	O
of	O
the	O
discrete	O
Fourier	O
transform	O
of	O
the	O
speech	O
signal	O
shown	O
in	O
FIG	O
.	O
5	O
;	O
FIG	O
.	O
7	O
is	O
a	O
diagrammatical	O
representation	O
of	O
the	O
averaged	O
magnitude	O
response	O
output	O
of	O
a	O
mel	O
scale	O
filter	O
bank	O
;	O
FIG	O
.	O
8	O
is	O
a	O
diagrammatical	O
representation	O
of	O
the	O
log	O
magnitude	O
spectrum	O
of	O
the	O
output	O
from	O
the	O
mel	O
scale	O
filter	O
bank	O
;	O
FIG	O
.	O
9	O
is	O
a	O
diagrammatical	O
representation	O
of	O
the	O
cepstrum	O
of	O
the	O
logged	O
magnitude	O
spectrum	O
shown	O
in	O
FIG	O
.	O
8	O
;	O
FIG	O
.	O
10	O
is	O
a	O
schematic	O
diagram	O
of	O
the	O
reference	O
model	O
builder	O
used	O
during	O
a	O
training	O
process	O
;	O
FIG	O
.	O
11	O
is	O
a	O
flow	O
chart	O
which	O
illustrates	O
the	O
steps	O
taken	O
during	O
the	O
training	O
process	O
for	O
generating	O
word	O
models	O
for	O
use	O
in	O
the	O
speech	O
recognition	O
system	O
;	O
FIG	O
.	O
12	O
is	O
a	O
schematic	O
diagram	O
which	O
illustrates	O
the	O
manner	O
in	O
which	O
the	O
trailing	O
phrases	O
and	O
words	O
are	O
stored	O
during	O
the	O
training	O
process	O
;	O
FIG	O
.	O
13	O
is	O
a	O
schematic	O
representation	O
of	O
a	O
number	O
of	O
input	O
phrases	O
and	O
words	O
,	O
and	O
their	O
corresponding	O
sequences	O
of	O
parameter	O
frames	O
;	O
FIG	O
.	O
14	O
is	O
a	O
flow	O
chart	O
which	O
illustrates	O
the	O
steps	O
taken	O
in	O
determining	O
the	O
word	O
models	O
from	O
the	O
input	O
utterances	O
,	O
input	O
during	O
the	O
training	O
session	O
;	O
FIG	O
.	O
15	O
is	O
a	O
schematic	O
representation	O
of	O
training	O
words	O
and	O
their	O
corresponding	O
sequences	O
of	O
parameter	O
frames	O
which	O
have	O
had	O
their	O
ends	O
discarded	O
;	O
FIG	O
.	O
16	O
is	O
a	O
schematic	O
representation	O
of	O
the	O
alignment	O
between	O
parameter	O
frames	O
of	O
the	O
word	O
shown	O
in	O
FIG	O
.	O
15	O
and	O
parameter	O
frames	O
corresponding	O
to	O
the	O
input	O
phrases	O
in	O
which	O
that	O
word	O
appears	O
;	O
FIG	O
.	O
17a	O
is	O
a	O
schematic	O
representation	O
of	O
a	O
language	O
model	O
generated	O
during	O
the	O
training	O
process	O
for	O
a	O
number	O
of	O
example	O
input	O
phrases	O
;	O
FIG	O
.	O
17b	O
is	O
a	O
flow	O
chart	O
which	O
illustrates	O
the	O
manner	O
in	O
which	O
the	O
system	O
adds	O
a	O
new	O
phrase	O
to	O
the	O
language	O
model	O
;	O
FIG	O
.	O
18	O
is	O
a	O
schematic	O
representation	O
of	O
the	O
processing	O
performed	O
when	O
an	O
input	O
word	O
is	O
aligned	O
with	O
a	O
word	O
model	O
using	O
a	O
dynamic	O
processing	O
technique	O
;	O
FIG	O
.	O
19	O
is	O
a	O
schematic	O
representation	O
of	O
an	O
allowed	O
state	O
transition	O
sequence	O
from	O
one	O
input	O
frame	O
to	O
the	O
next	O
;	O
FIG	O
.	O
20	O
is	O
an	O
alternate	O
representation	O
of	O
the	O
allowed	O
state	O
transition	O
sequence	O
shown	O
in	O
FIG	O
.	O
19	O
;	O
FIG	O
.	O
21	O
is	O
a	O
flow	O
chart	O
which	O
illustrates	O
the	O
implementation	O
of	O
the	O
dynamic	O
programming	O
alignment	O
technique	O
used	O
in	O
the	O
first	O
embodiment	O
;	O
FIG	O
.	O
22	O
is	O
a	O
schematic	O
representation	O
of	O
a	O
word	O
model	O
and	O
a	O
current	O
active	O
list	O
and	O
new	O
active	O
list	O
associated	O
therewith	O
;	O
FIG	O
.	O
23	O
is	O
a	O
schematic	O
diagram	O
which	O
illustrates	O
a	O
number	O
of	O
example	O
dynamic	O
programming	O
paths	O
propagating	O
within	O
a	O
reference	O
model	O
;	O
FIG	O
.	O
24	O
is	O
a	O
flow	O
chart	O
which	O
illustrates	O
the	O
steps	O
involved	O
in	O
step	O
S47	O
shown	O
in	O
FIG	O
.	O
21	O
;	O
FIG	O
.	O
25	O
is	O
a	O
schematic	O
diagram	O
which	O
illustrates	O
the	O
manner	O
in	O
which	O
two	O
of	O
the	O
dynamic	O
programming	O
paths	O
shown	O
in	O
FIG	O
.	O
23	O
can	O
propagate	O
from	O
the	O
current	O
input	O
frame	O
to	O
the	O
next	O
;	O
FIG	O
.	O
26a	O
is	O
a	O
schematic	O
diagram	O
illustrating	O
the	O
contents	O
of	O
the	O
new	O
active	O
list	O
shown	O
in	O
FIG	O
.	O
22	O
after	O
the	O
first	O
state	O
in	O
the	O
current	O
active	O
list	O
for	O
the	O
word	O
model	O
shown	O
in	O
FIG	O
.	O
22	O
has	O
been	O
processed	O
;	O
FIG	O
.	O
26b	O
is	O
a	O
schematic	O
diagram	O
illustrating	O
the	O
contents	O
of	O
the	O
new	O
active	O
list	O
shown	O
in	O
FIG	O
.	O
22	O
after	O
the	O
second	O
state	O
in	O
the	O
current	O
active	O
list	O
for	O
the	O
word	O
model	O
shown	O
in	O
FIG	O
.	O
22	O
has	O
been	O
processed	O
;	O
FIG	O
.	O
27a	O
is	O
a	O
flow	O
chart	O
which	O
illustrates	O
part	O
of	O
the	O
processing	O
performed	O
in	O
step	O
S77	O
shown	O
in	O
FIG	O
.	O
24	O
;	O
FIG	O
.	O
27b	O
is	O
a	O
flow	O
chart	O
which	O
illustrates	O
the	O
remaining	O
steps	O
involved	O
in	O
step	O
S77	O
of	O
FIG	O
.	O
24	O
;	O
FIG	O
.	O
28	O
is	O
a	O
flow	O
chart	O
which	O
illustrates	O
the	O
processing	O
performed	O
in	O
step	O
S51	O
shown	O
in	O
FIG	O
.	O
21	O
;	O
FIG	O
.	O
29	O
is	O
a	O
schematic	O
representation	O
of	O
the	O
processing	O
performed	O
to	O
an	O
exemplary	O
node	O
N	O
during	O
the	O
processing	O
illustrated	O
in	O
FIG	O
.	O
28	O
;	O
FIG	O
.	O
30	O
is	O
a	O
flow	O
chart	O
which	O
illustrates	O
the	O
steps	O
involved	O
in	O
step	O
S57	O
shown	O
in	O
FIG	O
.	O
21	O
;	O
FIG	O
.	O
31	O
is	O
a	O
schematic	O
diagram	O
illustrating	O
the	O
entry	O
states	O
of	O
the	O
word	O
model	O
shown	O
in	O
FIG	O
.	O
22	O
;	O
FIG	O
.	O
32	O
is	O
a	O
flow	O
chart	O
which	O
illustrates	O
the	O
steps	O
performed	O
in	O
step	O
S65	O
shown	O
in	O
FIG	O
.	O
21	O
;	O
FIG	O
.	O
33	O
is	O
a	O
schematic	O
representation	O
of	O
the	O
sequence	O
of	O
parameter	O
frames	O
for	O
an	O
input	O
phrase	O
together	O
with	O
the	O
sequences	O
of	O
parameter	O
frames	O
for	O
the	O
words	O
contained	O
within	O
the	O
input	O
phrase	O
when	O
spoken	O
in	O
isolation	O
;	O
FIG	O
.	O
34	O
is	O
a	O
flow	O
chart	O
which	O
illustrates	O
the	O
steps	O
involved	O
in	O
adapting	O
the	O
word	O
models	O
to	O
a	O
different	O
user	O
using	O
a	O
first	O
substitution	O
technique	O
;	O
FIG	O
.	O
35	O
is	O
a	O
flow	O
chart	O
which	O
illustrates	O
the	O
steps	O
involved	O
in	O
adapting	O
the	O
word	O
models	O
to	O
a	O
different	O
user	O
using	O
a	O
second	O
substitution	O
technique	O
.	O

Embodiments	O
of	O
the	O
present	O
invention	O
can	O
be	O
implemented	O
in	O
computer	O
hardware	O
,	O
but	O
the	O
embodiment	O
to	O
be	O
described	O
is	O
implemented	O
in	O
software	O
which	O
is	O
run	O
in	O
conjunction	O
with	O
processing	O
hardware	O
such	O
as	O
a	O
personal	O
computer	O
,	O
workstation	O
,	O
photocopier	O
,	O
facsimile	O
machine	O
or	O
the	O
like	O
.	O

FIG	O
.	O
1	O
shows	O
a	O
personal	O
computer	O
(	O
PC	O
)	O
1	O
which	O
may	O
be	O
programmed	O
to	O
operate	O
an	O
embodiment	O
of	O
the	O
present	O
invention	O
.	O
A	O
keyboard	O
3	O
,	O
a	O
pointing	O
device	O
5	O
,	O
a	O
microphone	O
7	O
and	O
a	O
telephone	O
line	O
9	O
are	O
connected	O
to	O
the	O
PC	O
1	O
via	O
an	O
interface	O
11	O
.	O
The	O
keyboard	O
3	O
and	O
pointing	O
device	O
5	O
enable	O
the	O
system	O
to	O
be	O
controlled	O
by	O
a	O
user	O
.	O
The	O
microphone	O
7	O
converts	O
the	O
acoustic	O
speech	O
signal	O
of	O
the	O
user	O
into	O
an	O
equivalent	O
electrical	O
signal	O
and	O
supplies	O
this	O
to	O
the	O
PC	O
1	O
for	O
processing	O
.	O
In	O
this	O
embodiment	O
,	O
the	O
beginning	O
and	O
end	O
points	O
of	O
the	O
input	O
speech	O
to	O
be	O
processed	O
,	O
are	O
identified	O
by	O
the	O
user	O
holding	O
the	O
spacebar	O
on	O
the	O
keyboard	O
3	O
down	O
for	O
the	O
duration	O
of	O
the	O
input	O
utterance	O
.	O
In	O
this	O
manner	O
,	O
the	O
system	O
only	O
processes	O
the	O
input	O
utterance	O
to	O
be	O
identified	O
.	O
An	O
internal	O
modem	O
and	O
speech	O
receiving	O
circuit	O
(	O
not	O
shown	O
)	O
may	O
be	O
connected	O
to	O
the	O
telephone	O
line	O
9	O
so	O
that	O
the	O
PC	O
1	O
can	O
communicate	O
with	O
,	O
for	O
example	O
,	O
a	O
remote	O
computer	O
or	O
with	O
a	O
remote	O
user	O
.	O

The	O
programme	O
instructions	O
which	O
make	O
the	O
PC	O
1	O
operate	O
in	O
accordance	O
with	O
the	O
present	O
invention	O
may	O
be	O
supplied	O
for	O
use	O
with	O
an	O
existing	O
PC	O
1	O
on	O
a	O
storage	O
device	O
such	O
as	O
a	O
magnetic	O
disc	O
13	O
,	O
or	O
by	O
the	O
internal	O
modem	O
communicating	O
with	O
a	O
remote	O
computer	O
via	O
the	O
telephone	O
line	O
9	O
.	O

The	O
operation	O
of	O
the	O
limited	O
vocabulary	O
continuous	O
speech	O
recognition	O
system	O
of	O
this	O
embodiment	O
will	O
now	O
be	O
described	O
with	O
reference	O
to	O
FIG	O
.	O
2	O
.	O
Electrical	O
signals	O
representative	O
of	O
the	O
input	O
speech	O
from	O
,	O
for	O
example	O
,	O
the	O
microphone	O
7	O
are	O
applied	O
to	O
a	O
preprocessor	O
15	O
which	O
converts	O
the	O
input	O
speech	O
signal	O
into	O
a	O
sequence	O
of	O
parameter	O
frames	O
,	O
each	O
representing	O
a	O
corresponding	O
time	O
frame	O
of	O
the	O
input	O
speech	O
signal	O
.	O
The	O
sequence	O
of	O
parameter	O
frames	O
are	O
supplied	O
to	O
a	O
recognition	O
block	O
where	O
the	O
speech	O
is	O
recognised	O
by	O
comparing	O
the	O
input	O
sequence	O
of	O
parameter	O
frames	O
with	O
reference	O
models	O
or	O
word	O
models	O
19	O
,	O
each	O
model	O
comprising	O
a	O
sequence	O
of	O
parameter	O
frames	O
expressed	O
in	O
the	O
same	O
kind	O
of	O
parameters	O
as	O
those	O
of	O
the	O
input	O
speech	O
to	O
be	O
recognised	O
.	O

A	O
language	O
model	O
21	O
and	O
a	O
noise	O
model	O
23	O
are	O
also	O
provided	O
as	O
inputs	O
to	O
the	O
recognition	O
block	O
17	O
to	O
aid	O
in	O
the	O
recognition	O
process	O
.	O
The	O
noise	O
model	O
is	O
representative	O
of	O
silence	O
or	O
background	O
noise	O
and	O
,	O
in	O
this	O
embodiment	O
,	O
comprises	O
a	O
single	O
parameter	O
frame	O
of	O
the	O
same	O
type	O
as	O
those	O
of	O
the	O
input	O
speech	O
signal	O
to	O
be	O
recognised	O
.	O
The	O
language	O
model	O
21	O
is	O
used	O
to	O
constrain	O
the	O
allowed	O
sequence	O
of	O
words	O
output	O
from	O
the	O
recognition	O
block	O
17	O
so	O
as	O
to	O
conform	O
with	O
sequences	O
of	O
words	O
known	O
to	O
the	O
system	O
.	O
The	O
word	O
sequence	O
output	O
from	O
the	O
recognition	O
block	O
17	O
may	O
then	O
be	O
transcribed	O
for	O
use	O
in	O
,	O
for	O
example	O
,	O
a	O
word	O
processing	O
package	O
or	O
can	O
be	O
used	O
as	O
operator	O
commands	O
to	O
initiate	O
,	O
stop	O
or	O
modify	O
the	O
action	O
of	O
the	O
PC	O
1	O
.	O

A	O
more	O
detailed	O
explanation	O
will	O
now	O
be	O
given	O
of	O
the	O
apparatus	O
described	O
above	O
.	O

Preprocessor	O
The	O
preprocessor	O
will	O
now	O
be	O
described	O
with	O
the	O
aid	O
of	O
FIGS	O
.	O
3	O
to	O
10	O
.	O

The	O
functions	O
of	O
the	O
preprocessor	O
15	O
are	O
to	O
extract	O
the	O
information	O
required	O
from	O
the	O
speech	O
and	O
to	O
reduce	O
the	O
amount	O
of	O
data	O
that	O
has	O
to	O
be	O
processed	O
.	O
There	O
are	O
many	O
known	O
methods	O
of	O
preprocessing	O
speech	O
in	O
the	O
field	O
of	O
speech	O
analysis	O
and	O
the	O
following	O
method	O
is	O
given	O
by	O
way	O
of	O
example	O
only	O
and	O
should	O
not	O
be	O
construed	O
as	O
limiting	O
in	O
any	O
way	O
.	O
In	O
this	O
embodiment	O
the	O
preprocessor	O
15	O
is	O
designed	O
to	O
extract	O
"	O
formant	O
"	O
related	O
information	O
.	O
Formants	O
are	O
defined	O
as	O
being	O
the	O
resonant	O
frequencies	O
of	O
the	O
vocal	O
tract	O
of	O
the	O
user	O
,	O
which	O
change	O
as	O
the	O
shape	O
of	O
the	O
vocal	O
tract	O
changes	O
.	O

FIG	O
.	O
3	O
shows	O
a	O
block	O
diagram	O
of	O
the	O
preprocessing	O
that	O
is	O
performed	O
on	O
the	O
input	O
speech	O
signal	O
.	O
Input	O
speech	O
S	O
(	O
t	O
)	O
from	O
the	O
microphone	O
7	O
or	O
the	O
telephone	O
line	O
9	O
is	O
supplied	O
to	O
filter	O
block	O
61	O
,	O
which	O
removes	O
frequencies	O
within	O
the	O
input	O
speech	O
signal	O
that	O
contain	O
little	O
meaningful	O
information	O
.	O
In	O
speech	O
signals	O
,	O
most	O
of	O
the	O
meaningful	O
information	O
is	O
contained	O
below	O
4	O
KHz	O
.	O
Therefore	O
,	O
filter	O
block	O
61	O
removes	O
all	O
frequencies	O
above	O
4	O
KHz	O
.	O
The	O
filtered	O
speech	O
signal	O
is	O
then	O
converted	O
into	O
digital	O
samples	O
by	O
the	O
analogue-to-digital	O
converter	O
(	O
ADC	O
)	O
63	O
.	O
To	O
adhere	O
to	O
the	O
Nyquist	O
sampling	O
criterion	O
,	O
ADC	O
63	O
samples	O
the	O
filtered	O
signal	O
at	O
a	O
rate	O
of	O
8000	O
times	O
per	O
second	O
.	O
In	O
this	O
embodiment	O
,	O
the	O
whole	O
input	O
speech	O
utterance	O
is	O
converted	O
into	O
digital	O
samples	O
and	O
stored	O
in	O
a	O
buffer	O
(	O
not	O
shown	O
)	O
,	O
prior	O
to	O
the	O
subsequent	O
steps	O
in	O
the	O
processing	O
of	O
the	O
speech	O
signals	O
.	O

After	O
the	O
input	O
speech	O
has	O
been	O
sampled	O
it	O
is	O
divided	O
into	O
overlapping	O
equal	O
length	O
frames	O
in	O
block	O
65	O
.	O
The	O
reason	O
for	O
this	O
division	O
of	O
the	O
input	O
speech	O
into	O
frames	O
will	O
now	O
be	O
described	O
in	O
more	O
detail	O
.	O
As	O
mentioned	O
above	O
,	O
during	O
continuous	O
speech	O
the	O
formant	O
related	O
information	O
changes	O
continuously	O
,	O
the	O
rate	O
of	O
change	O
being	O
directly	O
related	O
to	O
the	O
rate	O
of	O
movement	O
of	O
the	O
speech	O
articulators	O
which	O
is	O
limited	O
by	O
physiological	O
constraints	O
.	O
Therefore	O
,	O
in	O
order	O
to	O
track	O
the	O
changing	O
formant	O
frequencies	O
,	O
the	O
speech	O
signal	O
must	O
be	O
analysed	O
over	O
short	O
time	O
periods	O
or	O
frames	O
,	O
this	O
method	O
being	O
known	O
in	O
the	O
art	O
of	O
speech	O
analysis	O
as	O
a	O
"	O
short	O
time	O
"	O
analysis	O
of	O
speech	O
.	O
There	O
are	O
two	O
considerations	O
that	O
have	O
to	O
be	O
addressed	O
when	O
performing	O
a	O
short	O
time	O
analysis	O
:	O
(	O
i	O
)	O
what	O
rate	O
should	O
the	O
time	O
frames	O
be	O
extracted	O
from	O
the	O
speech	O
signal	O
,	O
and	O
(	O
ii	O
)	O
how	O
large	O
a	O
time	O
frame	O
should	O
be	O
used	O
.	O

The	O
first	O
consideration	O
depends	O
on	O
the	O
rate	O
of	O
movement	O
of	O
the	O
speech	O
articulators	O
i	O
.	O
e	O
.	O
the	O
frames	O
should	O
be	O
sufficiently	O
close	O
to	O
ensure	O
that	O
important	O
events	O
are	O
not	O
missed	O
and	O
to	O
ensure	O
that	O
there	O
is	O
reasonable	O
continuity	O
.	O
In	O
this	O
embodiment	O
,	O
a	O
frame	O
is	O
extracted	O
once	O
every	O
10	O
milliseconds	O
.	O
The	O
second	O
consideration	O
is	O
determined	O
by	O
a	O
compromise	O
between	O
the	O
time	O
frame	O
being	O
short	O
enough	O
so	O
that	O
the	O
speech	O
signal	O
's	O
properties	O
during	O
the	O
frame	O
are	O
constant	O
,	O
and	O
the	O
frame	O
being	O
long	O
enough	O
to	O
give	O
sufficient	O
frequency	O
detail	O
so	O
that	O
the	O
formants	O
can	O
be	O
distinguished	O
.	O
In	O
the	O
present	O
embodiment	O
,	O
the	O
frames	O
are	O
20	O
milliseconds	O
in	O
length	O
which	O
,	O
with	O
the	O
above	O
sampling	O
rate	O
,	O
corresponds	O
to	O
160	O
samples	O
per	O
frame	O
.	O

If	O
these	O
frames	O
are	O
generated	O
by	O
extracting	O
the	O
frames	O
directly	O
from	O
the	O
speech	O
samples	O
,	O
considerable	O
frequency	O
distortion	O
results	O
.	O
Therefore	O
,	O
to	O
reduce	O
such	O
distortions	O
,	O
a	O
smoothed	O
window	O
function	O
should	O
be	O
used	O
.	O
There	O
are	O
many	O
such	O
windows	O
available	O
including	O
Hamming	O
,	O
Hanning	O
,	O
Blackman	O
,	O
Bartlett	O
and	O
Kaiser	O
all	O
of	O
which	O
will	O
be	O
known	O
to	O
those	O
skilled	O
in	O
the	O
art	O
of	O
speech	O
analysis	O
.	O
In	O
the	O
present	O
embodiment	O
,	O
a	O
Hamming	O
window	O
is	O
used	O
,	O
this	O
being	O
represented	O
by	O
the	O
following	O
equation	O
:	O
W	O
(	O
n	O
)	O
=	O
0	O
.	O
54	O
-	O
0	O
.	O
46	O
cos	O
2	O
.	O
pi	O
.	O
n/	O
(	O
N.	O
sub	O
.	O
S	O
-	O
1	O
)	O
!	O
(	O
1	O
)	O
where	O
N.	O
sub	O
.	O
S	O
is	O
the	O
number	O
of	O
samples	O
in	O
the	O
window	O
,	O
i	O
.	O
e	O
.	O
160	O
samples	O
.	O

FIG	O
.	O
4	O
shows	O
in	O
more	O
detail	O
the	O
short	O
time	O
analysis	O
operation	O
that	O
is	O
carried	O
out	O
in	O
the	O
present	O
embodiment	O
.	O
The	O
speech	O
signal	O
in	O
frame	O
1	O
,	O
i	O
.	O
e	O
.	O
between	O
time	O
instant	O
"	O
a	O
"	O
and	O
time	O
instant	O
"	O
b	O
"	O
,	O
is	O
multiplied	O
by	O
the	O
window	O
function	O
given	O
in	O
equation	O
(	O
1	O
)	O
.	O
Further	O
,	O
due	O
to	O
the	O
choice	O
of	O
the	O
frame	O
rate	O
and	O
the	O
frame	O
length	O
,	O
the	O
next	O
frame	O
,	O
frame	O
2	O
,	O
starts	O
midway	O
between	O
frame	O
1	O
at	O
time	O
instant	O
"	O
c	O
"	O
etc	O
.	O

Once	O
a	O
frame	O
of	O
input	O
speech	O
signal	O
has	O
been	O
extracted	O
,	O
the	O
magnitude	O
of	O
the	O
discrete	O
Fourier	O
transform	O
(	O
DFT	O
)	O
of	O
the	O
frame	O
is	O
calculated	O
in	O
block	O
67	O
,	O
i	O
.	O
e	O
.	O
.vertline.S.sup.k	O
(	O
f	O
)	O
.	O
vertline	O
.	O
where	O
f	O
is	O
the	O
discrete	O
frequency	O
variable	O
.	O
Only	O
the	O
magnitude	O
information	O
is	O
required	O
,	O
since	O
many	O
aspects	O
of	O
this	O
preprocessor	O
are	O
designed	O
to	O
simulate	O
the	O
operation	O
of	O
the	O
human	O
auditory	O
system	O
,	O
which	O
is	O
relatively	O
insensitive	O
to	O
the	O
phase	O
of	O
the	O
input	O
speech	O
signal	O
.	O
FIG	O
.	O
5	O
shows	O
a	O
typical	O
speech	O
signal	O
for	O
a	O
single	O
frame	O
S.	O
sup	O
.	O
k	O
(	O
r	O
)	O
comprising	O
160	O
samples	O
,	O
i	O
.	O
e	O
.	O
r	O
=	O
0	O
,	O
1	O
,	O
.	O
.	O
.	O
159	O
.	O
To	O
enable	O
an	O
efficient	O
Fast	O
Fourier	O
Transform	O
(	O
FFT	O
)	O
algorithm	O
to	O
be	O
used	O
in	O
the	O
calculation	O
of	O
the	O
DFT	O
,	O
the	O
number	O
of	O
samples	O
within	O
the	O
frame	O
S.	O
sup	O
.	O
k	O
(	O
r	O
)	O
needs	O
to	O
be	O
increased	O
to	O
a	O
power	O
of	O
2	O
.	O
One	O
method	O
of	O
achieving	O
this	O
is	O
by	O
adding	O
96	O
zero	O
's	O
at	O
the	O
end	O
of	O
the	O
160	O
samples	O
to	O
give	O
256	O
samples	O
.	O
This	O
technique	O
is	O
known	O
as	O
"	O
padding	O
with	O
zeros	O
"	O
and	O
is	O
well	O
known	O
in	O
the	O
art	O
of	O
speech	O
analysis	O
,	O
and	O
will	O
not	O
be	O
described	O
further	O
.	O

In	O
computing	O
the	O
DFT	O
of	O
S.	O
sup	O
.	O
k	O
(	O
r	O
)	O
,	O
only	O
the	O
first	O
128	O
samples	O
of	O
the	O
spectrum	O
need	O
to	O
be	O
computed	O
,	O
since	O
speech	O
is	O
a	O
real	O
signal	O
and	O
so	O
the	O
second	O
128	O
samples	O
will	O
be	O
a	O
mirror	O
image	O
of	O
the	O
first	O
128	O
samples	O
.	O
FIG	O
.	O
6	O
shows	O
the	O
first	O
128	O
samples	O
of	O
the	O
magnitude	O
of	O
the	O
DFT	O
.vertline.S.sup.k	O
(	O
f	O
)	O
.	O
vertline	O
.	O
of	O
the	O
speech	O
signal	O
in	O
frame	O
S.	O
sup	O
.	O
k	O
(	O
r	O
)	O
shown	O
in	O
FIG	O
.	O
5	O
,	O
the	O
last	O
sample	O
of	O
which	O
occurs	O
at	O
a	O
frequency	O
of	O
half	O
the	O
sampling	O
frequency	O
,	O
i	O
.	O
e	O
.	O
4	O
KHz	O
.	O

As	O
mentioned	O
earlier	O
,	O
the	O
purpose	O
of	O
preprocessor	O
15	O
is	O
to	O
reduce	O
the	O
data	O
rate	O
and	O
to	O
emphasise	O
particular	O
components	O
of	O
the	O
input	O
speech	O
signal	O
.	O
The	O
data	O
rate	O
has	O
been	O
reduced	O
slightly	O
by	O
the	O
DFT	O
,	O
since	O
there	O
are	O
now	O
only	O
128	O
samples	O
per	O
frame	O
.	O
One	O
method	O
of	O
reducing	O
the	O
data	O
rate	O
further	O
is	O
to	O
split	O
the	O
spectrum	O
into	O
a	O
number	O
of	O
equal	O
frequency	O
bands	O
and	O
to	O
average	O
the	O
samples	O
within	O
each	O
band	O
,	O
i	O
.	O
e	O
.	O
pass	O
the	O
samples	O
shown	O
in	O
FIG	O
.	O
6	O
through	O
a	O
filter	O
bank	O
.	O

Studies	O
on	O
the	O
human	O
auditory	O
system	O
have	O
shown	O
that	O
the	O
ear	O
frequency	O
resolution	O
decreases	O
with	O
increasing	O
frequency	O
.	O
Therefore	O
,	O
a	O
logarithmically	O
spaced	O
filter	O
bank	O
,	O
i	O
.	O
e	O
.	O
one	O
in	O
which	O
there	O
are	O
more	O
frequency	O
bands	O
in	O
the	O
low	O
frequency	O
region	O
compared	O
to	O
the	O
high	O
frequency	O
region	O
,	O
is	O
preferable	O
to	O
a	O
linearly	O
spaced	O
filter	O
bank	O
since	O
a	O
logarithmically	O
spaced	O
filter	O
bank	O
retains	O
more	O
perceptually	O
meaningful	O
information	O
.	O

In	O
the	O
present	O
embodiment	O
,	O
a	O
mel	O
spaced	O
filter	O
bank	O
69	O
having	O
nineteen	O
bands	O
is	O
used	O
.	O
The	O
mel	O
scale	O
is	O
well	O
known	O
in	O
the	O
art	O
of	O
speech	O
analysis	O
,	O
and	O
is	O
a	O
logarithmic	O
scale	O
that	O
attempts	O
to	O
map	O
the	O
perceived	O
frequency	O
of	O
a	O
tone	O
onto	O
a	O
linear	O
scale	O
.	O
FIG	O
.	O
7	O
shows	O
the	O
output	O
.vertline.S.sup.k	O
(	O
f	O
'	O
)	O
.	O
vertline	O
.	O
of	O
the	O
mel	O
spaced	O
filter	O
bank	O
69	O
,	O
when	O
the	O
samples	O
shown	O
in	O
FIG	O
.	O
6	O
are	O
passed	O
through	O
the	O
bank	O
69	O
.	O
The	O
resulting	O
envelope	O
100	O
of	O
the	O
magnitude	O
spectrum	O
is	O
considerably	O
smoother	O
due	O
to	O
the	O
averaging	O
effect	O
of	O
the	O
filter	O
bank	O
69	O
,	O
although	O
less	O
smooth	O
at	O
the	O
lower	O
frequencies	O
due	O
to	O
the	O
logarithmic	O
spacing	O
of	O
the	O
filter	O
bank	O
.	O

The	O
formant	O
related	O
information	O
is	O
then	O
extracted	O
from	O
the	O
speech	O
using	O
blocks	O
71	O
,	O
73	O
and	O
75	O
of	O
FIG	O
.	O
3	O
,	O
by	O
a	O
process	O
which	O
will	O
now	O
be	O
explained	O
.	O

It	O
is	O
possible	O
to	O
model	O
the	O
speech	O
signal	O
S	O
(	O
t	O
)	O
of	O
a	O
user	O
in	O
terms	O
of	O
an	O
excitation	O
signal	O
E	O
(	O
t	O
)	O
and	O
a	O
filter	O
V	O
(	O
t	O
)	O
,	O
where	O
the	O
excitation	O
signal	O
E	O
(	O
t	O
)	O
represents	O
the	O
airflow	O
entering	O
the	O
vocal	O
tract	O
,	O
and	O
the	O
filter	O
V	O
(	O
t	O
)	O
represents	O
the	O
filtration	O
effect	O
of	O
the	O
vocal	O
tract	O
.	O
Consequently	O
,	O
the	O
magnitude	O
of	O
the	O
frequency	O
spectrum	O
.vertline.S	O
(	O
f	O
)	O
.	O
vertline	O
.	O
of	O
the	O
speech	O
signal	O
is	O
given	O
by	O
the	O
multiplication	O
of	O
the	O
magnitude	O
of	O
the	O
frequency	O
spectrum	O
.vertline.E	O
(	O
f	O
)	O
.	O
vertline	O
.	O
of	O
the	O
excitation	O
signal	O
with	O
the	O
magnitude	O
of	O
the	O
spectrum	O
.vertline.V	O
(	O
f	O
)	O
.	O
vertline	O
.	O
of	O
the	O
vocal	O
tract	O
filter	O
,	O
i	O
.	O
e	O
.	O

.vertline.S	O
(	O
f	O
)	O
=.vertline.E	O
(	O
f	O
)	O
.vertline..multidot..vertline.V	O
(	O
f	O
)	O
.	O
vertline	O
.	O
(	O
2	O
)	O
One	O
method	O
,	O
known	O
as	O
the	O
cepstral	O
method	O
,	O
of	O
extracting	O
the	O
vocal	O
tract	O
information	O
from	O
the	O
input	O
speech	O
will	O
now	O
be	O
described	O
.	O
This	O
method	O
involves	O
separating	O
the	O
vocal	O
tract	O
filter	O
magnitude	O
response	O
.vertline.V	O
(	O
f	O
)	O
.	O
vertline	O
.	O
from	O
the	O
excitation	O
magnitude	O
response	O
.vertline.E	O
(	O
f	O
)	O
.	O
vertline	O
.	O
by	O
taking	O
the	O
logarithm	O
of	O
the	O
speech	O
magnitude	O
response	O
.vertline.S	O
(	O
f	O
)	O
.	O
vertline	O
.	O
,	O
which	O
results	O
in	O
the	O
excitation	O
and	O
vocal	O
tract	O
filter	O
characteristics	O
becoming	O
additive	O
,	O
i	O
.	O
e	O
.	O

log.vertline.S	O
(	O
f	O
)	O
.vertline.=log.vertline.E	O
(	O
f	O
)	O
.vertline.+log.vertline.V	O
(	O
f	O
)	O
.	O
v	O
ertline	O
.	O
(	O
3	O
)	O
FIG	O
.	O
8	O
shows	O
the	O
envelope	O
of	O
the	O
logged	O
output	O
from	O
the	O
mel	O
filter	O
bank	O
69	O
,	O
i	O
.	O
e	O
.	O
log	O
.vertline.S.sup.k	O
(	O
f	O
'	O
)	O
I	O
,	O
which	O
shows	O
graphically	O
the	O
additive	O
nature	O
of	O
two	O
components	O
101	O
and	O
103	O
.	O
Component	O
101	O
is	O
representative	O
of	O
the	O
vocal	O
tract	O
characteristics	O
,	O
i	O
.	O
e	O
.	O
log	O
.vertline.V	O
(	O
f	O
)	O
.	O
vertline	O
.	O
,	O
and	O
component	O
103	O
is	O
representative	O
of	O
the	O
excitation	O
characteristics	O
,	O
i	O
.	O
e	O
.	O
log	O
.vertline.E	O
(	O
f	O
)	O
.	O
vertline	O
.	O
.	O
The	O
peaks	O
in	O
component	O
101	O
occur	O
at	O
the	O
formant	O
frequencies	O
of	O
the	O
vocal	O
tract	O
and	O
the	O
equally	O
spaced	O
peaks	O
in	O
component	O
103	O
occur	O
at	O
the	O
harmonic	O
frequencies	O
of	O
the	O
pitch	O
of	O
the	O
speaker	O
.	O

The	O
vocal	O
tract	O
characteristics	O
101	O
can	O
be	O
extracted	O
from	O
the	O
excitation	O
characteristics	O
103	O
,	O
by	O
performing	O
a	O
Discrete	O
Cosine	O
Transform	O
(	O
DCT	O
)	O
on	O
the	O
samples	O
output	O
from	O
block	O
71	O
,	O
and	O
then	O
filtering	O
the	O
result	O
.	O

FIG	O
.	O
9	O
shows	O
the	O
output	O
of	O
the	O
DCT	O
block	O
73	O
,	O
which	O
is	O
known	O
as	O
the	O
cepstrum	O
C.	O
sup	O
.	O
k	O
(	O
m	O
)	O
.	O
The	O
independent	O
variable	O
(	O
x-axis	O
of	O
FIG	O
.	O
9	O
)	O
of	O
the	O
cepstrum	O
has	O
dimensions	O
of	O
time	O
and	O
is	O
given	O
the	O
name	O
"	O
quefrency	O
"	O
.	O
The	O
strongly	O
periodic	O
component	O
103	O
shown	O
in	O
FIG	O
.	O
8	O
becomes	O
a	O
peak	O
105	O
in	O
the	O
cepstrum	O
at	O
a	O
location	O
equivalent	O
to	O
the	O
pitch	O
period	O
T	O
of	O
the	O
speaker	O
.	O
The	O
slowly	O
varying	O
component	O
101	O
shown	O
in	O
FIG	O
.	O
8	O
,	O
is	O
transformed	O
onto	O
a	O
number	O
of	O
small	O
peaks	O
107	O
near	O
the	O
origin	O
of	O
the	O
cepstrum	O
,	O
the	O
position	O
and	O
amplitude	O
of	O
which	O
are	O
dependent	O
on	O
the	O
formants	O
.	O

As	O
the	O
vocal	O
tract	O
characteristics	O
and	O
the	O
excitation	O
characteristics	O
of	O
speech	O
appear	O
in	O
separate	O
parts	O
of	O
the	O
quefrency	O
scale	O
,	O
they	O
can	O
be	O
separated	O
from	O
one	O
another	O
by	O
a	O
filtering	O
process	O
,	O
or	O
,	O
in	O
cepstral	O
terminology	O
by	O
a	O
so	O
called	O
"	O
liftering	O
"	O
process	O
.	O
The	O
cepstrum	O
C.	O
sup	O
.	O
k	O
(	O
m	O
)	O
shown	O
in	O
FIG	O
.	O
9	O
is	O
made	O
up	O
of	O
a	O
set	O
of	O
discrete	O
cepstral	O
coefficients	O
(	O
C.	O
sub	O
.	O
0	O
,	O
C.	O
sub	O
.	O
1	O
,	O
.	O
.	O
.	O
C.	O
sub	O
.	O
18	O
)	O
,	O
and	O
therefore	O
the	O
liftering	O
could	O
be	O
achieved	O
by	O
means	O
of	O
a	O
simple	O
rectangular	O
window	O
.	O
However	O
,	O
in	O
order	O
to	O
de-emphasise	O
parts	O
of	O
the	O
spectrum	O
that	O
are	O
considered	O
to	O
be	O
less	O
reliable	O
,	O
a	O
more	O
gradual	O
windowing	O
function	O
is	O
preferred	O
.	O
In	O
the	O
present	O
embodiment	O
,	O
the	O
following	O
window	O
function	O
is	O
used	O
in	O
liftering	O
block	O
75	O
:	O
#	O
#	O
EQU1	O
#	O
#	O
where	O
N.	O
sub	O
.	O
C	O
is	O
the	O
desired	O
number	O
of	O
cepstral	O
coefficients	O
output	O
per	O
frame	O
from	O
the	O
liftering	O
block	O
75	O
,	O
which	O
in	O
the	O
present	O
embodiment	O
is	O
twelve	O
.	O

In	O
addition	O
to	O
the	O
twelve	O
cepstral	O
coefficients	O
mentioned	O
above	O
,	O
the	O
power	O
of	O
the	O
speech	O
signal	O
within	O
each	O
frame	O
,	O
i	O
.	O
e	O
.	O
the	O
"	O
frame	O
power	O
"	O
is	O
also	O
calculated	O
.	O
This	O
is	O
an	O
important	O
feature	O
since	O
it	O
can	O
be	O
used	O
,	O
among	O
other	O
things	O
,	O
to	O
indicate	O
whether	O
or	O
not	O
the	O
input	O
speech	O
signal	O
during	O
the	O
frame	O
corresponds	O
to	O
a	O
voiced	O
speech	O
signal	O
.	O
The	O
frame	O
power	O
is	O
calculated	O
in	O
frame	O
power	O
block	O
81	O
shown	O
in	O
FIG	O
.	O
3	O
using	O
a	O
conventional	O
method	O
well	O
known	O
in	O
the	O
art	O
of	O
speech	O
analysis	O
.	O
To	O
achieve	O
independence	O
of	O
variable	O
recording	O
conditions	O
,	O
variable	O
loudness	O
etc	O
,	O
the	O
power	O
determined	O
in	O
block	O
81	O
is	O
normalised	O
in	O
power	O
normalising	O
block	O
83	O
to	O
give	O
a	O
power	O
coefficient	O
p.	O
sup	O
.	O
k	O
which	O
is	O
combined	O
with	O
the	O
cepstral	O
coefficients	O
output	O
from	O
the	O
liftering	O
block	O
75	O
.	O
The	O
power	O
is	O
normalised	O
in	O
block	O
83	O
by	O
determining	O
the	O
maximum	O
power	O
(	O
dB	O
)	O
across	O
the	O
utterance	O
stored	O
in	O
the	O
buffer	O
(	O
not	O
shown	O
)	O
,	O
subtracting	O
this	O
from	O
the	O
power	O
of	O
each	O
frame	O
and	O
multiplying	O
the	O
result	O
by	O
a	O
normalisation	O
constant	O
.	O

Whereas	O
in	O
the	O
present	O
embodiment	O
,	O
the	O
power	O
of	O
the	O
input	O
speech	O
signal	O
during	O
each	O
frame	O
is	O
determined	O
,	O
other	O
values	O
indicative	O
of	O
the	O
input	O
speech	O
signal	O
during	O
each	O
frame	O
could	O
be	O
used	O
.	O
For	O
example	O
,	O
a	O
measure	O
of	O
the	O
average	O
magnitude	O
of	O
the	O
input	O
speech	O
signal	O
during	O
a	O
frame	O
could	O
be	O
determined	O
and	O
normalised	O
.	O

In	O
summary	O
,	O
the	O
preprocessor	O
15	O
outputs	O
,	O
for	O
each	O
time	O
frame	O
,	O
a	O
set	O
of	O
coefficients--twelve	O
cepstral	O
coefficients	O
and	O
one	O
power	O
coefficient	O
.	O
For	O
convenience	O
,	O
the	O
coefficients	O
that	O
represent	O
frame	O
k	O
will	O
be	O
referred	O
to	O
as	O
parameter	O
frame	O
f	O
.	O
sub	O
.	O
k	O
,	O
and	O
the	O
coefficients	O
that	O
represent	O
the	O
subsequent	O
frame	O
will	O
be	O
referred	O
to	O
as	O
parameter	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
etc	O
.	O

Buffer	O
The	O
parameter	O
frames	O
f	O
.	O
sub	O
.	O
k	O
output	O
from	O
preprocessor	O
15	O
are	O
applied	O
to	O
the	O
buffer	O
16	O
shown	O
in	O
FIG	O
.	O
2	O
.	O
In	O
the	O
present	O
embodiment	O
,	O
the	O
buffer	O
16	O
is	O
large	O
enough	O
to	O
store	O
all	O
the	O
parameter	O
frames	O
generated	O
for	O
the	O
speech	O
stored	O
in	O
the	O
buffer	O
(	O
not	O
shown	O
)	O
which	O
stores	O
the	O
digital	O
samples	O
output	O
from	O
ADC	O
63	O
for	O
the	O
input	O
speech	O
.	O
After	O
the	O
entire	O
input	O
utterance	O
has	O
been	O
processed	O
by	O
the	O
preprocessor	O
15	O
,	O
the	O
parameter	O
frames	O
stored	O
in	O
buffer	O
16	O
are	O
fed	O
to	O
the	O
recognition	O
block	O
17	O
in	O
the	O
order	O
that	O
they	O
are	O
received	O
,	O
where	O
the	O
input	O
utterance	O
is	O
recognised	O
.	O

Reference	O
Models	O
As	O
mentioned	O
above	O
,	O
in	O
order	O
to	O
determine	O
which	O
words	O
are	O
represented	O
by	O
the	O
output	O
signals	O
from	O
the	O
preprocessor	O
15	O
,	O
these	O
signals	O
are	O
compared	O
with	O
stored	O
reference	O
models	O
which	O
model	O
the	O
words	O
already	O
known	O
to	O
the	O
system	O
and	O
the	O
acoustic	O
environment	O
surrounding	O
the	O
system	O
.	O
Each	O
model	O
associated	O
with	O
a	O
particular	O
word	O
comprises	O
a	O
sequence	O
of	O
parameter	O
frames	O
of	O
the	O
same	O
type	O
of	O
parameter	O
frames	O
output	O
from	O
the	O
preprocessor	O
15	O
described	O
above	O
.	O
However	O
,	O
to	O
differentiate	O
between	O
the	O
frames	O
in	O
the	O
word	O
models	O
and	O
the	O
frames	O
in	O
the	O
input	O
utterance	O
to	O
be	O
recognised	O
,	O
the	O
frames	O
in	O
the	O
word	O
models	O
will	O
be	O
referred	O
to	O
as	O
states	O
.	O

One	O
feature	O
of	O
the	O
speech	O
recognition	O
system	O
according	O
to	O
this	O
embodiment	O
is	O
that	O
it	O
can	O
be	O
supplied	O
to	O
the	O
end	O
user	O
with	O
no	O
word	O
models	O
,	O
environment	O
(	O
or	O
noise	O
)	O
model	O
or	O
language	O
model	O
pre-stored	O
therein	O
.	O
This	O
allows	O
the	O
user	O
the	O
freedom	O
to	O
train	O
the	O
system	O
to	O
recognise	O
the	O
phrases	O
he	O
wants	O
,	O
without	O
the	O
system	O
being	O
overburdened	O
with	O
pre-stored	O
words	O
which	O
may	O
not	O
be	O
useful	O
for	O
the	O
user	O
's	O
purpose	O
.	O
Further	O
,	O
as	O
will	O
be	O
seen	O
from	O
the	O
following	O
description	O
,	O
the	O
particular	O
training	O
method	O
described	O
is	O
particularly	O
adapted	O
to	O
this	O
situation	O
because	O
it	O
allows	O
for	O
new	O
phrases	O
to	O
be	O
learnt	O
by	O
the	O
system	O
without	O
the	O
need	O
for	O
a	O
time	O
consuming	O
training	O
session	O
.	O
In	O
addition	O
,	O
since	O
the	O
reference	O
models	O
correspond	O
to	O
whole	O
words	O
and	O
not	O
phonemes	O
,	O
the	O
system	O
will	O
work	O
for	O
any	O
language	O
or	O
even	O
any	O
mixture	O
of	O
languages	O
.	O
The	O
training	O
process	O
will	O
now	O
be	O
described	O
in	O
more	O
detail	O
with	O
reference	O
to	O
FIGS	O
.	O
10	O
to	O
17	O
.	O

Training	O
FIG	O
.	O
10	O
is	O
a	O
schematic	O
diagram	O
which	O
illustrates	O
the	O
build/update	O
module	O
91	O
which	O
is	O
used	O
in	O
the	O
training	O
process	O
.	O
In	O
particular	O
,	O
the	O
build/update	O
module	O
91	O
receives	O
sequences	O
of	O
parameter	O
frames	O
f	O
.	O
sub	O
.	O
k	O
representative	O
of	O
a	O
word	O
or	O
words	O
to	O
be	O
learnt	O
by	O
the	O
system	O
,	O
and	O
user	O
information	O
,	O
represented	O
by	O
arrow	O
92	O
,	O
indicative	O
of	O
the	O
text	O
corresponding	O
to	O
the	O
input	O
spoken	O
word	O
or	O
words	O
.	O
If	O
sufficient	O
information	O
has	O
been	O
input	O
into	O
the	O
build/update	O
module	O
91	O
then	O
it	O
generates	O
word	O
models	O
corresponding	O
to	O
the	O
input	O
words	O
and	O
updates	O
the	O
language	O
model	O
21	O
.	O
In	O
this	O
embodiment	O
,	O
both	O
the	O
word	O
models	O
and	O
the	O
language	O
model	O
are	O
stored	O
in	O
a	O
high	O
volume	O
data	O
storage	O
unit	O
,	O
such	O
as	O
a	O
hard	O
disc	O
93	O
.	O

The	O
manner	O
in	O
which	O
the	O
noise	O
model	O
23	O
is	O
determined	O
in	O
this	O
embodiment	O
will	O
now	O
be	O
described	O
.	O
Firstly	O
,	O
the	O
user	O
indicates	O
that	O
he	O
wishes	O
to	O
build	O
a	O
new	O
or	O
change	O
the	O
existing	O
noise	O
model	O
23	O
.	O
In	O
response	O
,	O
the	O
system	O
prompts	O
the	O
user	O
to	O
input	O
sound	O
representative	O
of	O
silence	O
.	O
This	O
is	O
achieved	O
by	O
the	O
user	O
holding	O
down	O
the	O
spacebar	O
on	O
the	O
keyboard	O
3	O
while	O
remaining	O
silent	O
.	O
At	O
the	O
end	O
of	O
the	O
period	O
of	O
silence	O
,	O
the	O
user	O
must	O
then	O
utter	O
a	O
word	O
so	O
that	O
the	O
system	O
can	O
normalise	O
the	O
power	O
coefficient	O
of	O
the	O
generated	O
parameter	O
frames	O
representative	O
of	O
the	O
silence	O
.	O
If	O
the	O
user	O
does	O
not	O
utter	O
a	O
word	O
at	O
the	O
end	O
of	O
the	O
period	O
of	O
silence	O
then	O
the	O
power	O
coefficient	O
for	O
the	O
noise	O
model	O
23	O
will	O
be	O
unrealistically	O
high	O
,	O
and	O
misrecognition	O
errors	O
may	O
result	O
.	O
Finally	O
,	O
in	O
order	O
to	O
determine	O
the	O
noise	O
model	O
23	O
,	O
the	O
system	O
averages	O
the	O
parameter	O
frames	O
generated	O
for	O
the	O
period	O
of	O
silence	O
to	O
produce	O
a	O
single	O
parameter	O
frame	O
which	O
is	O
used	O
as	O
the	O
noise	O
model	O
23	O
.	O

The	O
speech	O
recognition	O
system	O
of	O
this	O
embodiment	O
is	O
designed	O
to	O
recognise	O
continuously	O
spoken	O
words	O
,	O
i	O
.	O
e	O
.	O
words	O
embedded	O
within	O
phrases	O
.	O
In	O
order	O
to	O
achieve	O
good	O
recognition	O
results	O
,	O
the	O
reference	O
models	O
(	O
or	O
continuous	O
word	O
models	O
)	O
should	O
be	O
derived	O
from	O
example	O
phrases	O
which	O
contain	O
the	O
words	O
of	O
interest	O
.	O
Unfortunately	O
,	O
it	O
is	O
not	O
an	O
easy	O
task	O
to	O
identify	O
the	O
beginning	O
and	O
end	O
points	O
of	O
a	O
word	O
within	O
a	O
continuously	O
spoken	O
phrase	O
.	O
An	O
overview	O
of	O
the	O
way	O
in	O
which	O
the	O
present	O
embodiment	O
generates	O
a	O
continuous	O
word	O
model	O
will	O
now	O
be	O
given	O
.	O
Firstly	O
,	O
the	O
system	O
determines	O
a	O
model	O
for	O
the	O
word	O
from	O
an	O
isolated	O
utterance	O
of	O
that	O
word	O
.	O
This	O
model	O
will	O
be	O
referred	O
to	O
as	O
the	O
"	O
isolated	O
word	O
model	O
"	O
although	O
,	O
as	O
those	O
skilled	O
in	O
the	O
art	O
of	O
speech	O
recognition	O
will	O
realise	O
from	O
the	O
following	O
description	O
,	O
these	O
isolated	O
word	O
models	O
may	O
not	O
correspond	O
to	O
conventional	O
isolated	O
word	O
models	O
well	O
known	O
in	O
the	O
art	O
.	O
The	O
system	O
then	O
uses	O
the	O
isolated	O
word	O
models	O
to	O
generate	O
the	O
continuous	O
word	O
models	O
by	O
comparing	O
the	O
isolated	O
word	O
models	O
with	O
example	O
phrases	O
containing	O
the	O
corresponding	O
words	O
.	O

To	O
generate	O
the	O
isolated	O
word	O
model	O
,	O
the	O
word	O
must	O
be	O
input	O
into	O
the	O
system	O
via	O
the	O
microphone	O
7	O
or	O
the	O
telephone	O
line	O
in	O
isolation	O
.	O
As	O
described	O
above	O
,	O
the	O
space	O
bar	O
is	O
used	O
to	O
identify	O
each	O
incoming	O
utterance	O
.	O
Therefore	O
,	O
the	O
sequence	O
of	O
parameter	O
frames	O
representative	O
of	O
the	O
isolated	O
utterance	O
of	O
the	O
word	O
will	O
comprise	O
parameter	O
frames	O
at	O
the	O
beginning	O
and	O
end	O
thereof	O
which	O
correspond	O
to	O
silence	O
.	O
The	O
system	O
then	O
compares	O
the	O
utterance	O
of	O
the	O
isolated	O
word	O
with	O
example	O
phrases	O
which	O
contain	O
that	O
word	O
.	O
This	O
comparison	O
identifies	O
approximate	O
beginning	O
and	O
end	O
points	O
of	O
the	O
word	O
within	O
the	O
isolated	O
utterance	O
.	O
These	O
beginning	O
and	O
end	O
points	O
are	O
then	O
averaged	O
and	O
the	O
isolated	O
word	O
model	O
for	O
the	O
word	O
is	O
determined	O
by	O
extracting	O
the	O
sequence	O
of	O
parameter	O
frames	O
which	O
lies	O
between	O
the	O
averaged	O
beginning	O
and	O
end	O
points	O
.	O
By	O
determining	O
the	O
isolated	O
word	O
model	O
in	O
this	O
way	O
,	O
not	O
only	O
should	O
the	O
silence	O
at	O
the	O
beginning	O
and	O
end	O
of	O
the	O
word	O
be	O
removed	O
,	O
but	O
parts	O
of	O
the	O
word	O
which	O
are	O
not	O
pronounced	O
during	O
continuous	O
speech	O
will	O
also	O
be	O
removed	O
.	O
Therefore	O
,	O
the	O
isolated	O
word	O
model	O
may	O
not	O
correspond	O
to	O
a	O
conventional	O
isolated	O
word	O
model	O
,	O
which	O
is	O
determined	O
by	O
removing	O
the	O
silence	O
from	O
the	O
beginning	O
and	O
ends	O
of	O
the	O
input	O
utterance	O
,	O
and	O
will	O
be	O
more	O
representative	O
of	O
the	O
word	O
when	O
spoken	O
in	O
continuous	O
speech	O
.	O

Once	O
the	O
isolated	O
word	O
model	O
has	O
been	O
determined	O
,	O
it	O
is	O
aligned	O
with	O
the	O
example	O
phrases	O
which	O
contain	O
that	O
word	O
in	O
order	O
to	O
identify	O
the	O
location	O
of	O
the	O
word	O
within	O
the	O
phrase	O
.	O
Finally	O
,	O
the	O
reference	O
or	O
continuous	O
word	O
model	O
is	O
determined	O
by	O
extracting	O
and	O
combining	O
the	O
speech	O
from	O
the	O
locations	O
identified	O
in	O
the	O
phrases	O
.	O
The	O
way	O
in	O
which	O
the	O
system	O
generates	O
the	O
word	O
models	O
will	O
now	O
be	O
described	O
in	O
more	O
detai	O
.	O

When	O
the	O
user	O
wishes	O
to	O
teach	O
the	O
system	O
one	O
or	O
more	O
new	O
phrases	O
,	O
the	O
user	O
initiates	O
the	O
subroutine	O
shown	O
in	O
FIG	O
.	O
11	O
.	O
In	O
step	O
S1	O
the	O
user	O
enters	O
the	O
text	O
of	O
the	O
new	O
word	O
or	O
phrase	O
into	O
the	O
system	O
via	O
the	O
keyboard	O
3	O
.	O
The	O
system	O
then	O
checks	O
whether	O
that	O
word	O
or	O
phrase	O
is	O
already	O
known	O
,	O
and	O
if	O
it	O
is	O
not	O
then	O
in	O
step	O
S3	O
,	O
it	O
prompts	O
the	O
user	O
to	O
enter	O
the	O
same	O
word	O
or	O
phrase	O
via	O
the	O
microphone	O
7	O
,	O
and	O
associates	O
the	O
utterance	O
with	O
the	O
corresponding	O
text	O
input	O
in	O
step	O
S1	O
.	O
Next	O
in	O
step	O
S5	O
the	O
PC	O
1	O
uses	O
all	O
the	O
text	O
which	O
has	O
been	O
previously	O
entered	O
,	O
to	O
check	O
whether	O
any	O
of	O
the	O
words	O
within	O
the	O
phrase	O
have	O
been	O
input	O
(	O
in	O
isolation	O
)	O
already	O
,	O
and	O
prompts	O
the	O
user	O
to	O
input	O
,	O
in	O
isolation	O
via	O
the	O
microphone	O
7	O
,	O
those	O
words	O
that	O
have	O
not	O
been	O
entered	O
before	O
.	O

After	O
step	O
S5	O
,	O
the	O
user	O
decides	O
whether	O
to	O
enter	O
another	O
new	O
word	O
or	O
phrase	O
in	O
step	O
S7	O
,	O
and	O
returns	O
to	O
step	O
S1	O
if	O
he	O
does	O
.	O
On	O
the	O
other	O
hand	O
,	O
if	O
the	O
user	O
decides	O
not	O
to	O
input	O
any	O
more	O
phrases	O
,	O
then	O
the	O
processing	O
moves	O
to	O
step	O
S9	O
where	O
reference	O
models	O
are	O
generated	O
for	O
unknown	O
words	O
which	O
are	O
included	O
in	O
at	O
least	O
two	O
phrases	O
input	O
into	O
the	O
system	O
.	O
For	O
example	O
,	O
if	O
no	O
training	O
phrases	O
have	O
been	O
input	O
,	O
and	O
the	O
system	O
has	O
no	O
pre-stored	O
reference	O
models	O
,	O
and	O
the	O
user	O
decides	O
to	O
input	O
the	O
phrases	O
"	O
get	O
an	O
image	O
"	O
and	O
"	O
get	O
the	O
earth	O
"	O
,	O
and	O
then	O
decides	O
in	O
step	O
S7	O
that	O
he	O
does	O
not	O
wish	O
to	O
enter	O
any	O
more	O
phrases	O
,	O
then	O
the	O
system	O
will	O
only	O
be	O
able	O
to	O
generate	O
a	O
word	O
model	O
for	O
the	O
word	O
"	O
get	O
"	O
,	O
since	O
it	O
is	O
the	O
only	O
word	O
that	O
is	O
in	O
both	O
of	O
the	O
input	O
phrases	O
.	O
If	O
on	O
the	O
other	O
hand	O
the	O
user	O
inputs	O
the	O
phrase	O
"	O
get	O
an	O
image	O
"	O
twice	O
,	O
then	O
the	O
system	O
will	O
be	O
able	O
to	O
generate	O
a	O
reference	O
model	O
for	O
each	O
word	O
in	O
the	O
phrase	O
.	O
Taking	O
the	O
first	O
example	O
mentioned	O
above	O
further	O
,	O
if	O
the	O
user	O
decides	O
to	O
input	O
the	O
phrase	O
"	O
get	O
the	O
earth	O
"	O
in	O
a	O
second	O
training	O
session	O
after	O
inputting	O
the	O
first	O
two	O
phrases	O
,	O
then	O
the	O
system	O
will	O
not	O
prompt	O
the	O
user	O
for	O
the	O
words	O
"	O
get	O
"	O
or	O
"	O
the	O
"	O
in	O
step	O
S5	O
since	O
these	O
words	O
will	O
have	O
been	O
input	O
in	O
isolation	O
already	O
.	O
Further	O
,	O
the	O
system	O
will	O
now	O
be	O
able	O
to	O
generate	O
a	O
reference	O
model	O
for	O
the	O
word	O
"	O
the	O
"	O
since	O
it	O
now	O
appears	O
in	O
two	O
phrases	O
which	O
have	O
been	O
input	O
into	O
the	O
system	O
.	O
In	O
this	O
way	O
,	O
the	O
training	O
is	O
incremental	O
and	O
can	O
be	O
trained	O
at	O
the	O
convenience	O
of	O
the	O
user	O
.	O

Referring	O
to	O
FIG	O
.	O
12	O
,	O
each	O
phrase	O
input	O
in	O
the	O
above	O
manner	O
is	O
given	O
a	O
phrase	O
number	O
P	O
and	O
is	O
stored	O
in	O
a	O
phrase	O
array	O
115	O
on	O
the	O
hard	O
disc	O
93	O
.	O
Similarly	O
,	O
each	O
isolated	O
word	O
that	O
is	O
input	O
is	O
given	O
a	O
word	O
number	O
W	O
and	O
is	O
stored	O
in	O
a	O
word	O
array	O
117	O
on	O
the	O
hard	O
disc	O
93	O
.	O
As	O
shown	O
in	O
FIG	O
.	O
12	O
,	O
each	O
phrase	O
P	O
in	O
the	O
phrase	O
array	O
115	O
has	O
an	O
associated	O
sequence	O
of	O
parameter	O
frames	O
123	O
,	O
the	O
sequence	O
of	O
words	O
125	O
that	O
form	O
the	O
phrase	O
and	O
a	O
status	O
flag	O
127	O
.	O
Each	O
word	O
in	O
the	O
sequence	O
of	O
words	O
125	O
has	O
an	O
associated	O
text	O
129	O
of	O
the	O
word	O
,	O
the	O
phrase	O
number	O
P	O
,	O
the	O
word	O
number	O
131	O
(	O
i	O
.	O
e	O
.	O
the	O
position	O
of	O
the	O
word	O
within	O
the	O
phrase	O
)	O
,	O
the	O
time	O
boundaries	O
133	O
of	O
the	O
word	O
within	O
the	O
phrase	O
and	O
a	O
word	O
index	O
135	O
which	O
points	O
to	O
the	O
corresponding	O
isolated	O
word	O
W	O
in	O
the	O
word	O
array	O
117	O
.	O
Each	O
isolated	O
word	O
W	O
in	O
the	O
word	O
array	O
117	O
has	O
an	O
associated	O
sequence	O
of	O
parameter	O
frames	O
137	O
,	O
a	O
phrase	O
index	O
139	O
which	O
points	O
back	O
to	O
those	O
phrases	O
in	O
which	O
that	O
word	O
can	O
be	O
found	O
and	O
a	O
status	O
flag	O
141	O
.	O

Initially	O
,	O
when	O
the	O
isolated	O
words	O
and	O
phrases	O
are	O
being	O
entered	O
into	O
the	O
system	O
,	O
the	O
status	O
flags	O
127	O
and	O
141	O
associated	O
with	O
each	O
word	O
or	O
phrase	O
are	O
labelled	O
FLEXI	O
to	O
indicate	O
that	O
they	O
have	O
not	O
been	O
processed	O
,	O
and	O
the	O
time	O
boundaries	O
133	O
,	O
associated	O
with	O
each	O
word	O
within	O
the	O
sequence	O
of	O
words	O
in	O
the	O
phrase	O
,	O
are	O
set	O
to	O
UNKNOWN	O
.	O

The	O
generation	O
of	O
the	O
word	O
models	O
for	O
the	O
unknown	O
words	O
performed	O
in	O
step	O
S9	O
of	O
FIG	O
.	O
11	O
will	O
now	O
be	O
briefly	O
described	O
with	O
reference	O
to	O
FIGS	O
.	O
12	O
to	O
16	O
,	O
using	O
as	O
an	O
example	O
the	O
training	O
phrases	O
"	O
get	O
an	O
image	O
"	O
which	O
has	O
been	O
input	O
twice	O
,	O
and	O
"	O
get	O
the	O
earth	O
"	O
which	O
has	O
been	O
input	O
once	O
.	O
Therefore	O
,	O
there	O
will	O
be	O
three	O
elements	O
P1	O
,	O
P2	O
and	O
P3	O
in	O
the	O
phrase	O
array	O
115	O
,	O
one	O
for	O
each	O
utterance	O
of	O
the	O
phrase	O
"	O
get	O
an	O
image	O
"	O
and	O
one	O
for	O
the	O
utterance	O
of	O
the	O
phrase	O
"	O
get	O
the	O
earth	O
"	O
.	O
Additionally	O
,	O
there	O
will	O
be	O
five	O
elements	O
W1	O
,	O
W2	O
,	O
W3	O
,	O
W4	O
and	O
W5	O
in	O
the	O
words	O
array	O
117	O
,	O
one	O
for	O
each	O
of	O
the	O
different	O
words	O
that	O
make	O
up	O
the	O
two	O
phrases	O
.	O
As	O
described	O
above	O
,	O
a	O
sequence	O
of	O
parameter	O
frames	O
corresponding	O
to	O
each	O
phrase	O
and	O
corresponding	O
to	O
each	O
of	O
the	O
different	O
words	O
will	O
be	O
stored	O
in	O
the	O
corresponding	O
elements	O
in	O
the	O
phrase	O
array	O
115	O
and	O
word	O
array	O
117	O
.	O

FIG	O
.	O
13	O
shows	O
speech	O
signals	O
151	O
and	O
153	O
which	O
represent	O
the	O
two	O
utterances	O
of	O
the	O
phrase	O
"	O
get	O
an	O
image	O
"	O
and	O
speech	O
signal	O
155	O
which	O
represents	O
the	O
utterance	O
of	O
the	O
phrase	O
"	O
get	O
the	O
earth	O
"	O
.	O
FIG	O
.	O
13	O
also	O
shows	O
the	O
speech	O
signals	O
157	O
,	O
159	O
and	O
161	O
which	O
represent	O
the	O
isolated	O
utterances	O
of	O
the	O
words	O
"	O
get	O
"	O
,	O
"	O
an	O
"	O
and	O
"	O
image	O
"	O
respectively	O
.	O
FIG	O
.	O
13	O
also	O
shows	O
the	O
two	O
sequences	O
of	O
parameter	O
frames	O
152	O
and	O
154	O
which	O
correspond	O
to	O
the	O
two	O
utterances	O
of	O
the	O
phrase	O
"	O
get	O
an	O
image	O
"	O
,	O
the	O
sequence	O
of	O
parameter	O
frames	O
156	O
corresponding	O
to	O
the	O
utterance	O
of	O
the	O
phrase	O
"	O
get	O
the	O
earth	O
"	O
and	O
the	O
sequences	O
of	O
parameter	O
frames	O
158	O
,	O
160	O
and	O
162	O
corresponding	O
to	O
the	O
utterances	O
of	O
the	O
isolated	O
words	O
"	O
get	O
"	O
,	O
"	O
an	O
"	O
and	O
"	O
image	O
"	O
respectively	O
.	O
Representations	O
of	O
the	O
words	O
"	O
the	O
"	O
and	O
"	O
earth	O
"	O
are	O
not	O
shown	O
in	O
FIG	O
.	O
13	O
,	O
since	O
word	O
models	O
for	O
these	O
words	O
cannot	O
be	O
generated	O
as	O
they	O
do	O
not	O
appear	O
in	O
two	O
or	O
more	O
phrases	O
.	O

FIG	O
.	O
14	O
shows	O
in	O
more	O
detail	O
the	O
steps	O
required	O
to	O
generate	O
a	O
word	O
model	O
for	O
each	O
of	O
the	O
unknown	O
words	O
.	O
In	O
particular	O
,	O
in	O
step	O
S21	O
the	O
sequences	O
of	O
parameter	O
frames	O
corresponding	O
to	O
the	O
input	O
phrases	O
that	O
contain	O
the	O
unknown	O
words	O
are	O
aligned	O
with	O
the	O
sequences	O
of	O
parameter	O
frames	O
corresponding	O
to	O
the	O
unknown	O
words	O
when	O
spoken	O
in	O
isolation	O
,	O
using	O
a	O
flexible	O
dynamic	O
programming	O
alignment	O
process	O
which	O
accommodates	O
the	O
initial	O
lack	O
of	O
knowledge	O
of	O
the	O
start	O
and	O
end	O
points	O
of	O
the	O
unknown	O
words	O
.	O
In	O
particular	O
,	O
a	O
dynamic	O
programming	O
alignment	O
process	O
is	O
used	O
that	O
does	O
not	O
constrain	O
where	O
the	O
optimum	O
alignment	O
path	O
of	O
each	O
word	O
must	O
begin	O
or	O
end	O
.	O
This	O
flexible	O
dynamic	O
programming	O
alignment	O
process	O
will	O
be	O
described	O
in	O
more	O
detail	O
later	O
after	O
dynamic	O
programming	O
alignment	O
has	O
been	O
discussed	O
.	O

The	O
result	O
of	O
the	O
flexible	O
dynamic	O
programming	O
alignment	O
is	O
the	O
identification	O
of	O
an	O
approximate	O
start	O
and	O
end	O
point	O
of	O
each	O
unknown	O
word	O
within	O
the	O
sequence	O
of	O
parameter	O
frames	O
for	O
that	O
unknown	O
word	O
.	O
For	O
example	O
,	O
when	O
the	O
sequence	O
of	O
parameter	O
frames	O
152	O
corresponding	O
to	O
the	O
first	O
utterance	O
of	O
the	O
phrase	O
"	O
get	O
an	O
image	O
"	O
is	O
aligned	O
with	O
the	O
sequence	O
of	O
parameter	O
frames	O
158	O
corresponding	O
to	O
the	O
utterance	O
of	O
the	O
unknown	O
word	O
"	O
get	O
"	O
,	O
a	O
start	O
and	O
end	O
point	O
of	O
that	O
word	O
within	O
the	O
sequence	O
of	O
parameter	O
frames	O
158	O
are	O
identified	O
from	O
the	O
alignment	O
results	O
.	O
As	O
mentioned	O
above	O
,	O
the	O
parameter	O
frames	O
before	O
the	O
start	O
point	O
and	O
after	O
the	O
end	O
point	O
correspond	O
to	O
background	O
noise	O
,	O
or	O
parts	O
of	O
the	O
word	O
which	O
are	O
not	O
pronounced	O
in	O
the	O
example	O
phrases	O
,	O
and	O
can	O
therefore	O
be	O
removed	O
.	O

The	O
alignment	O
performed	O
in	O
step	O
S21	O
for	O
the	O
example	O
training	O
phrases	O
will	O
identify	O
three	O
sets	O
of	O
start	O
and	O
end	O
points	O
for	O
the	O
word	O
"	O
get	O
"	O
(	O
since	O
the	O
word	O
"	O
get	O
"	O
appears	O
in	O
three	O
phrases	O
)	O
and	O
two	O
sets	O
of	O
start	O
and	O
end	O
points	O
for	O
the	O
words	O
"	O
an	O
"	O
and	O
"	O
image	O
"	O
(	O
since	O
the	O
words	O
"	O
an	O
"	O
and	O
"	O
image	O
"	O
appear	O
in	O
two	O
phrases	O
)	O
.	O
In	O
step	O
S23	O
an	O
average	O
start	O
and	O
end	O
point	O
for	O
each	O
unknown	O
word	O
are	O
determined	O
and	O
the	O
frames	O
before	O
the	O
average	O
start	O
frame	O
and	O
after	O
the	O
average	O
end	O
frame	O
are	O
discarded	O
.	O
For	O
example	O
,	O
if	O
after	O
step	O
S21	O
for	O
the	O
word	O
"	O
get	O
"	O
the	O
start	O
points	O
identified	O
using	O
the	O
three	O
phrases	O
151	O
,	O
153	O
and	O
155	O
are	O
frame	O
f.sub.8.sup.W1	O
,	O
frame	O
f.sub.9.sup.W1	O
and	O
frame	O
f.sub.13.sup.W1	O
,	O
then	O
the	O
average	O
is	O
frame	O
f.sub.10.sup.W1	O
(	O
8	O
+	O
9	O
+	O
13	O
!	O
/3	O
)	O
and	O
all	O
frames	O
in	O
the	O
sequence	O
of	O
parameter	O
frames	O
158	O
before	O
frame	O
f.sub.10.sup.W1	O
are	O
discarded	O
.	O
A	O
similar	O
procedure	O
is	O
used	O
for	O
the	O
end	O
points	O
,	O
except	O
that	O
it	O
is	O
the	O
frames	O
beyond	O
the	O
end	O
frame	O
which	O
are	O
discarded	O
.	O
The	O
resulting	O
sequence	O
of	O
parameter	O
frames	O
for	O
each	O
word	O
is	O
the	O
isolated	O
word	O
model	O
mentioned	O
above	O
for	O
that	O
word	O
.	O

FIG	O
.	O
15	O
shows	O
the	O
speech	O
signals	O
157	O
'	O
,	O
159	O
'	O
and	O
161	O
'	O
and	O
the	O
corresponding	O
sequences	O
of	O
parameter	O
frames	O
of	O
the	O
isolated	O
word	O
models	O
158	O
'	O
,	O
160	O
'	O
and	O
162	O
'	O
for	O
the	O
words	O
"	O
get	O
"	O
,	O
"	O
an	O
"	O
and	O
"	O
image	O
"	O
respectively	O
.	O
At	O
this	O
stage	O
in	O
the	O
processing	O
,	O
the	O
status	O
flag	O
141	O
,	O
shown	O
in	O
FIG	O
.	O
12	O
,	O
for	O
each	O
word	O
processed	O
is	O
changed	O
from	O
FLEXI	O
to	O
CHOPPED	O
to	O
signify	O
that	O
the	O
unknown	O
words	O
have	O
had	O
the	O
frames	O
from	O
the	O
beginning	O
and	O
ends	O
removed	O
.	O

Next	O
in	O
step	O
S25	O
shown	O
in	O
FIG	O
.	O
14	O
,	O
the	O
sequences	O
of	O
parameter	O
frames	O
corresponding	O
to	O
the	O
input	O
phrases	O
are	O
aligned	O
with	O
the	O
sequences	O
of	O
parameter	O
frames	O
of	O
the	O
isolated	O
word	O
models	O
for	O
the	O
words	O
in	O
those	O
phrases	O
.	O
For	O
example	O
,	O
the	O
sequences	O
of	O
parameter	O
frames	O
152	O
,	O
154	O
and	O
156	O
corresponding	O
to	O
the	O
utterances	O
of	O
phrases	O
in	O
which	O
the	O
word	O
"	O
get	O
"	O
appears	O
are	O
aligned	O
with	O
the	O
sequence	O
of	O
parameter	O
frames	O
of	O
the	O
isolated	O
word	O
model	O
158	O
'	O
for	O
the	O
word	O
"	O
get	O
"	O
.	O
FIG	O
.	O
16	O
shows	O
the	O
resulting	O
alignment	O
achieved	O
between	O
the	O
sequences	O
152	O
,	O
154	O
and	O
156	O
and	O
the	O
sequence	O
158	O
'	O
,	O
where	O
the	O
dashed	O
lines	O
represent	O
the	O
alignment	O
between	O
the	O
frames	O
.	O
As	O
shown	O
,	O
it	O
is	O
established	O
that	O
frames	O
f.sub.2.sup.P1	O
and	O
f.sub.3.sup.P1	O
are	O
aligned	O
with	O
frame	O
f.sub.10.sup.W1	O
,	O
and	O
frames	O
f.sub.4.sup.P1	O
and	O
f.sub.5.sup.P1	O
are	O
aligned	O
with	O
frame	O
f.sub.11.sup.W1	O
etc	O
.	O

Next	O
in	O
step	O
S27	O
shown	O
in	O
FIG	O
.	O
14	O
,	O
a	O
reference	O
model	O
for	O
the	O
unknown	O
word	O
is	O
generated	O
by	O
replacing	O
the	O
individual	O
frames	O
of	O
the	O
isolated	O
word	O
model	O
with	O
the	O
average	O
of	O
the	O
aligned	O
frames	O
from	O
the	O
sequences	O
of	O
parameter	O
frames	O
corresponding	O
to	O
the	O
phrases	O
.	O
For	O
example	O
,	O
for	O
the	O
sequence	O
of	O
parameter	O
frames	O
of	O
the	O
isolated	O
word	O
model	O
158	O
'	O
shown	O
in	O
FIG	O
.	O
16	O
,	O
frame	O
f.sub.10.sup.W1	O
is	O
replaced	O
by	O
the	O
average	O
of	O
frames	O
f.sub.2.sup.P1	O
,	O
f.sub.3.sup.P1,f.sub.1.sup.P2	O
and	O
f.sub.2.sup.P3	O
,	O
whilst	O
frame	O
f.sub.11.sup.W1	O
is	O
replaced	O
by	O
the	O
average	O
of	O
frames	O
f.sub.4.sup.P1	O
,	O
f.sub.5.sup.P1	O
,	O
f.sub.2.sup.P2	O
,	O
f.sub.3.sup.P2	O
and	O
f.sub.3.sup.P3	O
etc	O
.	O
In	O
the	O
event	O
that	O
there	O
are	O
no	O
frames	O
of	O
a	O
phrase	O
aligned	O
with	O
one	O
of	O
the	O
frames	O
of	O
the	O
isolated	O
word	O
model	O
,	O
then	O
that	O
particular	O
frame	O
is	O
replaced	O
by	O
a	O
frame	O
derived	O
by	O
interpolating	O
between	O
or	O
extrapolating	O
from	O
neighbouring	O
replaced	O
frames	O
.	O
Therefore	O
,	O
for	O
the	O
sequence	O
of	O
parameter	O
frames	O
158	O
'	O
shown	O
in	O
FIG	O
.	O
16	O
,	O
frame	O
f.sub.12.sup.W1	O
is	O
not	O
aligned	O
with	O
any	O
of	O
the	O
frames	O
in	O
the	O
sequences	O
of	O
parameter	O
frames	O
152	O
,	O
154	O
or	O
156	O
,	O
and	O
is	O
replaced	O
by	O
a	O
frame	O
derived	O
by	O
interpolating	O
between	O
the	O
substituted	O
frames	O
for	O
f.sub.11.sup.W1	O
and	O
f.sub.13.sup.W1	O
.	O
Alternatively	O
,	O
the	O
frames	O
of	O
the	O
isolated	O
word	O
model	O
which	O
are	O
not	O
aligned	O
with	O
any	O
frames	O
of	O
the	O
phrase	O
can	O
be	O
discarded	O
.	O

The	O
reference	O
word	O
models	O
generated	O
in	O
step	O
S27	O
are	O
ready	O
for	O
use	O
in	O
the	O
speech	O
recognition	O
part	O
of	O
the	O
system	O
,	O
which	O
will	O
be	O
described	O
further	O
below	O
.	O
Therefore	O
,	O
the	O
status	O
flag	O
141	O
of	O
each	O
word	O
that	O
has	O
been	O
processed	O
is	O
changed	O
from	O
CHOPPED	O
to	O
IN-USE	O
.	O

Once	O
a	O
reference	O
word	O
model	O
has	O
been	O
created	O
for	O
all	O
the	O
words	O
in	O
a	O
phrase	O
,	O
then	O
that	O
phrase	O
can	O
be	O
added	O
to	O
the	O
language	O
model	O
21	O
shown	O
in	O
FIG	O
.	O
2	O
.	O
In	O
this	O
embodiment	O
,	O
the	O
language	O
model	O
21	O
is	O
similar	O
to	O
a	O
Bigram	O
model	O
,	O
and	O
comprises	O
a	O
mesh	O
of	O
interconnected	O
nodes	O
,	O
where	O
the	O
interconnections	O
represent	O
the	O
words	O
known	O
to	O
the	O
system	O
.	O
It	O
does	O
not	O
,	O
however	O
,	O
contain	O
any	O
grammatical	O
rules	O
concerning	O
,	O
for	O
example	O
,	O
correct	O
English	O
language	O
usage	O
.	O
It	O
only	O
constrains	O
which	O
words	O
can	O
follow	O
others	O
based	O
on	O
the	O
phrases	O
known	O
to	O
it	O
.	O
FIG	O
.	O
17a	O
illustrates	O
the	O
language	O
model	O
21	O
derived	O
when	O
the	O
following	O
phrases	O
have	O
been	O
learnt	O
by	O
the	O
system	O
:	O
get	O
an	O
image--phrase	O
1	O
get	O
the	O
earth--phrase	O
2	O
get	O
the	O
fjord--phrase	O
3	O
get	O
the	O
map--phrase	O
4	O
get	O
the	O
coin--phrase	O
5	O
save	O
an	O
image--phrase	O
6	O
load	O
an	O
image--phrase	O
7	O
make	O
it	O
smaller--phrase	O
8	O
make	O
it	O
larger--phrase	O
9	O
make	O
it	O
brighter--phrase	O
10	O
make	O
it	O
more	O
red--phrase	O
11	O
make	O
it	O
more	O
yellow--phrase	O
12	O
make	O
it	O
more	O
green--phrase	O
13	O
make	O
it	O
more	O
cyan--phrase	O
14	O
make	O
it	O
more	O
blue--phrase	O
15	O
make	O
it	O
more	O
magenta--phrase	O
16	O
quit--phrase	O
17	O
As	O
shown	O
in	O
FIG	O
.	O
17a	O
there	O
is	O
a	O
start	O
node	O
N.	O
sub	O
.	O
0	O
,	O
an	O
end	O
node	O
N.	O
sub	O
.	O
n	O
and	O
eight	O
intermediate	O
nodes	O
N.	O
sub	O
.	O
1	O
to	O
N.	O
sub	O
.	O
8	O
.	O
For	O
an	O
input	O
phrase	O
to	O
be	O
recognised	O
the	O
system	O
must	O
find	O
a	O
path	O
from	O
the	O
start	O
node	O
N.	O
sub	O
.	O
0	O
to	O
the	O
end	O
node	O
N.	O
sub	O
.	O
n	O
.	O
The	O
system	O
is	O
,	O
however	O
,	O
reasonably	O
flexible	O
in	O
that	O
once	O
trained	O
and	O
the	O
user	O
inputs	O
the	O
phrase	O
"	O
make	O
smaller	O
"	O
instead	O
of	O
"	O
make	O
it	O
smaller	O
"	O
the	O
system	O
will	O
still	O
recognise	O
the	O
input	O
phrase	O
.	O
The	O
system	O
will	O
not	O
,	O
however	O
,	O
recognise	O
a	O
phrase	O
that	O
is	O
input	O
if	O
that	O
phrase	O
is	O
not	O
known	O
to	O
the	O
system	O
even	O
if	O
the	O
individual	O
words	O
in	O
the	O
phrase	O
are	O
known	O
,	O
i	O
.	O
e	O
.	O
for	O
the	O
language	O
model	O
given	O
above	O
,	O
if	O
the	O
user	O
says	O
"	O
save	O
the	O
image	O
"	O
the	O
system	O
will	O
not	O
recognise	O
this	O
input	O
even	O
though	O
it	O
knows	O
the	O
words	O
"	O
save	O
"	O
,	O
"	O
the	O
"	O
and	O
"	O
image	O
"	O
.	O

The	O
language	O
model	O
21	O
is	O
created	O
by	O
extracting	O
the	O
necessary	O
word	O
sequence	O
constraints	O
from	O
the	O
text	O
input	O
in	O
step	O
S3	O
in	O
FIG	O
.	O
11	O
and	O
is	O
updated	O
after	O
each	O
new	O
phrase	O
has	O
been	O
input	O
provided	O
there	O
is	O
a	O
word	O
model	O
for	O
each	O
of	O
the	O
words	O
in	O
the	O
phrase	O
.	O
The	O
way	O
in	O
which	O
the	O
language	O
model	O
21	O
is	O
updated	O
will	O
now	O
be	O
described	O
with	O
reference	O
to	O
FIG	O
.	O
17b	O
.	O

When	O
a	O
new	O
input	O
phrase	O
has	O
been	O
input	O
and	O
a	O
word	O
model	O
for	O
each	O
word	O
in	O
the	O
phrase	O
has	O
been	O
determined	O
,	O
the	O
system	O
identifies	O
in	O
step	O
S30	O
,	O
whether	O
the	O
first	O
word	O
in	O
the	O
phrase	O
is	O
already	O
connected	O
to	O
the	O
output	O
of	O
the	O
start	O
node	O
N.	O
sub	O
.	O
0	O
.	O
If	O
it	O
is	O
,	O
then	O
the	O
processing	O
proceeds	O
to	O
step	O
S32	O
.	O
If	O
on	O
the	O
other	O
hand	O
,	O
the	O
first	O
word	O
is	O
not	O
already	O
connected	O
to	O
the	O
output	O
of	O
the	O
start	O
node	O
N.	O
sub	O
.	O
0	O
,	O
then	O
a	O
new	O
output	O
from	O
the	O
start	O
node	O
N.	O
sub	O
.	O
0	O
is	O
added	O
,	O
in	O
step	O
S31	O
,	O
for	O
the	O
first	O
word	O
.	O

The	O
processing	O
then	O
proceeds	O
to	O
step	O
S32	O
where	O
the	O
system	O
initialises	O
a	O
word	O
loop	O
counter	O
w	O
,	O
which	O
is	O
used	O
to	O
count	O
through	O
all	O
the	O
words	O
in	O
the	O
phrase	O
.	O
The	O
processing	O
then	O
proceeds	O
to	O
step	O
S33	O
where	O
the	O
system	O
determines	O
whether	O
or	O
not	O
word	O
w	O
is	O
the	O
last	O
word	O
in	O
the	O
phrase	O
.	O
If	O
it	O
is	O
not	O
,	O
then	O
the	O
processing	O
proceeds	O
to	O
step	O
S34	O
where	O
the	O
system	O
determines	O
whether	O
or	O
not	O
word	O
w	O
is	O
connected	O
to	O
the	O
input	O
of	O
a	O
node	O
(	O
except	O
the	O
end	O
node	O
N.	O
sub	O
.	O
n	O
)	O
.	O
If	O
it	O
is	O
,	O
then	O
the	O
processing	O
proceeds	O
to	O
step	O
S36	O
where	O
the	O
system	O
checks	O
to	O
see	O
if	O
the	O
next	O
word	O
w	O
+	O
1	O
is	O
connected	O
to	O
the	O
output	O
of	O
the	O
node	O
that	O
has	O
word	O
w	O
as	O
an	O
input	O
.	O
If	O
on	O
the	O
other	O
hand	O
,	O
at	O
step	O
S34	O
,	O
the	O
system	O
determines	O
that	O
word	O
w	O
is	O
not	O
connected	O
to	O
the	O
input	O
of	O
any	O
node	O
,	O
then	O
the	O
processing	O
proceeds	O
to	O
step	O
S35	O
where	O
a	O
new	O
node	O
is	O
created	O
and	O
word	O
w	O
is	O
connected	O
to	O
the	O
input	O
of	O
that	O
new	O
node	O
.	O
The	O
processing	O
then	O
proceeds	O
to	O
step	O
S36	O
described	O
above	O
.	O

If	O
the	O
system	O
determines	O
,	O
in	O
step	O
S36	O
,	O
that	O
the	O
next	O
word	O
w	O
+	O
l	O
is	O
not	O
connected	O
to	O
the	O
output	O
of	O
the	O
node	O
that	O
has	O
word	O
w	O
as	O
an	O
input	O
,	O
then	O
the	O
processing	O
proceeds	O
to	O
step	O
S37	O
where	O
the	O
next	O
word	O
w	O
+	O
1	O
is	O
added	O
as	O
an	O
output	O
of	O
that	O
node	O
.	O
If	O
on	O
the	O
other	O
hand	O
the	O
system	O
determines	O
,	O
in	O
step	O
S36	O
,	O
that	O
the	O
next	O
word	O
w	O
+	O
1	O
is	O
already	O
connected	O
to	O
the	O
output	O
of	O
the	O
node	O
that	O
has	O
word	O
w	O
as	O
an	O
input	O
,	O
then	O
nothing	O
happens	O
and	O
the	O
processing	O
proceeds	O
to	O
step	O
S38	O
where	O
the	O
word	O
counter	O
w	O
is	O
incremented	O
.	O
The	O
processing	O
then	O
returns	O
to	O
step	O
S33	O
and	O
a	O
similar	O
procedure	O
is	O
carried	O
out	O
for	O
the	O
next	O
word	O
in	O
the	O
phrase	O
.	O
If	O
the	O
system	O
determines	O
at	O
step	O
S33	O
that	O
word	O
w	O
is	O
the	O
last	O
word	O
in	O
the	O
phrase	O
,	O
then	O
the	O
processing	O
proceeds	O
to	O
step	O
S39	O
where	O
the	O
system	O
determines	O
whether	O
or	O
not	O
the	O
last	O
word	O
is	O
already	O
connected	O
to	O
the	O
input	O
of	O
the	O
end	O
node	O
N.	O
sub	O
.	O
n	O
.	O
If	O
it	O
is	O
not	O
connected	O
to	O
the	O
input	O
of	O
the	O
end	O
node	O
N.	O
sub	O
.	O
n	O
then	O
the	O
processing	O
proceeds	O
to	O
step	O
S40	O
where	O
the	O
system	O
connects	O
the	O
last	O
word	O
in	O
the	O
phrase	O
to	O
the	O
input	O
of	O
the	O
end	O
node	O
N.	O
sub	O
.	O
n	O
.	O
If	O
the	O
last	O
word	O
is	O
already	O
connected	O
to	O
the	O
last	O
node	O
N.	O
sub	O
.	O
n	O
,	O
or	O
once	O
the	O
last	O
word	O
has	O
been	O
connected	O
to	O
the	O
last	O
node	O
N.	O
sub	O
.	O
n	O
in	O
step	O
S40	O
,	O
then	O
the	O
processing	O
is	O
complete	O
and	O
the	O
phrase	O
now	O
forms	O
part	O
of	O
the	O
language	O
model	O
21	O
.	O

One	O
feature	O
of	O
the	O
training	O
process	O
is	O
that	O
the	O
system	O
can	O
be	O
taught	O
the	O
phrases	O
individually	O
or	O
it	O
can	O
be	O
taught	O
a	O
number	O
of	O
phrases	O
at	O
once	O
.	O
Further	O
,	O
if	O
a	O
new	O
phrase	O
is	O
input	O
and	O
the	O
system	O
already	O
has	O
word	O
models	O
for	O
some	O
of	O
the	O
words	O
in	O
that	O
phrase	O
,	O
then	O
it	O
only	O
needs	O
to	O
generate	O
word	O
models	O
for	O
the	O
unknown	O
words	O
before	O
it	O
can	O
update	O
the	O
language	O
model	O
21	O
.	O

Dynamic	O
Programming	O
(	O
DP	O
)	O
In	O
the	O
processing	O
performed	O
in	O
steps	O
S21	O
and	O
S25	O
of	O
FIG	O
.	O
14	O
,	O
an	O
alignment	O
procedure	O
was	O
used	O
to	O
align	O
the	O
parameter	O
frames	O
of	O
the	O
phrases	O
with	O
the	O
parameter	O
frames	O
of	O
the	O
words	O
.	O
In	O
order	O
to	O
align	O
the	O
two	O
sequences	O
of	O
parameter	O
frames	O
in	O
an	O
effective	O
manner	O
,	O
the	O
alignment	O
process	O
must	O
be	O
able	O
to	O
compensate	O
for	O
the	O
different	O
rates	O
at	O
which	O
the	O
word	O
is	O
spoken	O
,	O
for	O
example	O
when	O
the	O
word	O
is	O
spoken	O
in	O
isolation	O
and	O
when	O
the	O
word	O
is	O
embedded	O
within	O
the	O
continuously	O
spoken	O
phrase	O
.	O
The	O
dynamic	O
programming	O
(	O
DP	O
)	O
alignment	O
process	O
mentioned	O
above	O
is	O
one	O
way	O
which	O
can	O
match	O
one	O
word	O
onto	O
another	O
in	O
a	O
way	O
which	O
applies	O
the	O
optimum	O
non-linear	O
time-scale	O
distortion	O
to	O
achieve	O
the	O
best	O
match	O
at	O
all	O
points	O
.	O

An	O
overview	O
of	O
the	O
DP	O
matching	O
process	O
will	O
now	O
be	O
given	O
with	O
reference	O
to	O
FIGS	O
.	O
18	O
-	O
20	O
.	O
FIG	O
.	O
18	O
shows	O
along	O
the	O
abscissa	O
a	O
sequence	O
of	O
parameter	O
frames	O
representative	O
of	O
an	O
input	O
word	O
,	O
and	O
along	O
the	O
ordinate	O
a	O
sequence	O
of	O
parameter	O
frames	O
representative	O
of	O
a	O
word	O
model	O
.	O
Comparing	O
this	O
example	O
with	O
the	O
processing	O
performed	O
in	O
step	O
S25	O
in	O
FIG	O
.	O
14	O
,	O
the	O
sequence	O
of	O
parameter	O
frames	O
representative	O
of	O
the	O
input	O
word	O
may	O
represent	O
part	O
of	O
the	O
sequence	O
of	O
parameter	O
frames	O
corresponding	O
to	O
one	O
of	O
the	O
input	O
phrases	O
,	O
and	O
the	O
sequence	O
of	O
parameter	O
frames	O
representative	O
of	O
the	O
word	O
model	O
may	O
represent	O
the	O
sequence	O
of	O
frames	O
representing	O
one	O
of	O
the	O
chopped	O
words	O
.	O

To	O
find	O
the	O
total	O
difference	O
between	O
the	O
word	O
model	O
and	O
the	O
input	O
word	O
,	O
it	O
is	O
necessary	O
to	O
find	O
the	O
sum	O
of	O
all	O
distances	O
between	O
the	O
individual	O
pairs	O
of	O
frames	O
along	O
whichever	O
path	O
between	O
the	O
bottom	O
left	O
and	O
top	O
right	O
corners	O
in	O
FIG	O
.	O
18	O
that	O
gives	O
the	O
smallest	O
cumulative	O
distance	O
.	O
This	O
definition	O
will	O
ensure	O
that	O
corresponding	O
frames	O
of	O
similar	O
words	O
are	O
correctly	O
aligned	O
.	O
One	O
way	O
of	O
calculating	O
this	O
total	O
distance	O
is	O
to	O
consider	O
all	O
possible	O
paths	O
and	O
add	O
the	O
value	O
of	O
d	O
(	O
k	O
,	O
j	O
)	O
(	O
the	O
distance	O
between	O
frame	O
k	O
and	O
frame	O
j	O
)	O
for	O
each	O
point	O
along	O
each	O
one	O
.	O
The	O
distance	O
measured	O
between	O
the	O
two	O
words	O
is	O
then	O
taken	O
to	O
be	O
the	O
lowest	O
value	O
obtained	O
for	O
the	O
cumulative	O
distance	O
.	O
Although	O
this	O
method	O
gives	O
the	O
correct	O
answer	O
,	O
the	O
number	O
of	O
valid	O
paths	O
becomes	O
so	O
large	O
that	O
the	O
computation	O
is	O
impossible	O
for	O
any	O
practical	O
speech	O
recognition	O
system	O
.	O

Dynamic	O
programming	O
is	O
a	O
mathematical	O
technique	O
which	O
finds	O
the	O
cumulative	O
distance	O
along	O
the	O
optimum	O
path	O
without	O
having	O
to	O
calculate	O
the	O
distance	O
along	O
all	O
possible	O
paths	O
.	O
The	O
number	O
of	O
paths	O
along	O
which	O
the	O
cumulative	O
distance	O
is	O
determined	O
can	O
be	O
reduced	O
further	O
by	O
placing	O
certain	O
constraints	O
on	O
the	O
DP	O
process	O
.	O
For	O
example	O
,	O
it	O
can	O
be	O
assumed	O
that	O
the	O
optimum	O
path	O
will	O
always	O
go	O
forward	O
with	O
a	O
non-negative	O
slope	O
,	O
otherwise	O
one	O
of	O
the	O
words	O
will	O
be	O
a	O
time	O
reversed	O
version	O
of	O
the	O
other	O
.	O
Another	O
constraint	O
that	O
can	O
be	O
placed	O
on	O
the	O
DP	O
process	O
is	O
to	O
limit	O
the	O
maximum	O
amount	O
of	O
time	O
compression/expansion	O
of	O
the	O
input	O
word	O
relative	O
to	O
the	O
reference	O
word	O
.	O
In	O
this	O
embodiment	O
,	O
this	O
constraint	O
is	O
realised	O
by	O
limiting	O
the	O
number	O
of	O
frames	O
that	O
can	O
be	O
skipped	O
or	O
repeated	O
in	O
the	O
matching	O
process	O
.	O
For	O
example	O
,	O
in	O
FIG	O
.	O
19	O
the	O
frame	O
sequence	O
is	O
constrained	O
such	O
that	O
if	O
frame	O
f	O
.	O
sub	O
.	O
k	O
is	O
matched	O
to	O
frame	O
f.sub.j.sup.m	O
then	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
can	O
be	O
matched	O
with	O
frame	O
f.sub.j.sup.m	O
,	O
f.sub.j+1.sup.m	O
,	O
f.sub.j+2.sup.m	O
or	O
f.sub.j+3.sup.m	O
.	O
Therefore	O
,	O
if	O
parameter	O
frame	O
f	O
.	O
sub	O
.	O
k	O
of	O
the	O
input	O
word	O
and	O
parameter	O
frame	O
f.sub.j.sup.m	O
of	O
the	O
word	O
model	O
lie	O
on	O
the	O
optimum	O
path	O
then	O
the	O
above	O
constraint	O
necessitates	O
that	O
the	O
immediately	O
preceding	O
point	O
on	O
the	O
optimum	O
path	O
must	O
be	O
either	O
(	O
k-1	O
,	O
j	O
)	O
,	O
(	O
k-1	O
,	O
j-1	O
)	O
,	O
(	O
k-1	O
,	O
j-2	O
)	O
or	O
(	O
k-1	O
,	O
j-3	O
)	O
,	O
as	O
illustrated	O
in	O
FIG	O
.	O
20	O
.	O

FIG	O
.	O
18	O
shows	O
the	O
"	O
valid	O
paths	O
"	O
which	O
are	O
propagated	O
up	O
to	O
frame	O
f	O
.	O
sub	O
.	O
k-1	O
which	O
represent	O
possible	O
matchings	O
between	O
the	O
input	O
word	O
and	O
the	O
word	O
model	O
.	O
When	O
frame	O
f	O
.	O
sub	O
.	O
k	O
is	O
applied	O
to	O
the	O
recognition	O
unit	O
17	O
each	O
valid	O
path	O
has	O
the	O
local	O
distance	O
between	O
current	O
frame	O
f	O
.	O
sub	O
.	O
k	O
and	O
the	O
frame	O
of	O
the	O
word	O
model	O
that	O
is	O
at	O
the	O
end	O
of	O
that	O
valid	O
path	O
added	O
to	O
its	O
cumulative	O
distance	O
.	O
If	O
a	O
number	O
of	O
valid	O
paths	O
meet	O
at	O
the	O
same	O
point	O
then	O
the	O
valid	O
path	O
with	O
the	O
lowest	O
cumulative	O
distance	O
is	O
continued	O
and	O
the	O
others	O
are	O
discarded	O
.	O
For	O
example	O
,	O
in	O
FIG	O
.	O
18	O
path	O
SA	O
,	O
B	O
and	O
C	O
meet	O
at	O
point	O
(	O
k	O
,	O
j	O
)	O
and	O
the	O
path	O
(	O
A	O
,	O
B	O
or	O
C	O
)	O
with	O
the	O
lowest	O
cumulative	O
distance	O
is	O
continued	O
whereas	O
the	O
other	O
two	O
are	O
discarded	O
.	O

Therefore	O
,	O
if	O
D	O
(	O
k	O
,	O
j	O
)	O
is	O
the	O
cumulative	O
distance	O
along	O
a	O
valid	O
path	O
from	O
the	O
beginning	O
of	O
the	O
word	O
to	O
the	O
point	O
(	O
k	O
,	O
j	O
)	O
,	O
i	O
.	O
e	O
.	O
:	O
#	O
#	O
EQU2	O
#	O
#	O
Then	O
,	O
with	O
the	O
above	O
constraints	O
it	O
follows	O
that	O
:	O
D	O
(	O
k	O
,	O
j	O
)	O
=	O
d	O
(	O
k	O
,	O
j	O
)	O
+	O
minD	O
(	O
k-1	O
,	O
j	O
)	O
,	O
D	O
(	O
k-1	O
,	O
j-1	O
)	O
,	O
D	O
(	O
k-1	O
,	O
j-2	O
)	O
,	O
D	O
(	O
k-1	O
,	O
j-3	O
)	O
!	O
(	O
6	O
)	O
With	O
the	O
above	O
constraints	O
,	O
the	O
value	O
of	O
D	O
(	O
0	O
,	O
0	O
)	O
must	O
equal	O
d	O
(	O
0	O
,	O
0	O
)	O
,	O
d	O
(	O
1	O
,	O
0	O
)	O
,	O
d	O
(	O
2	O
,	O
0	O
)	O
or	O
d	O
(	O
3	O
,	O
0	O
)	O
,	O
as	O
all	O
possible	O
paths	O
must	O
begin	O
at	O
one	O
of	O
these	O
points	O
.	O
Therefore	O
,	O
starting	O
from	O
one	O
of	O
the	O
starting	O
points	O
,	O
the	O
value	O
of	O
D	O
(	O
k	O
,	O
j	O
)	O
can	O
be	O
determined	O
via	O
a	O
recursive	O
processing	O
routine	O
.	O
When	O
the	O
routine	O
reaches	O
the	O
end	O
of	O
the	O
words	O
to	O
be	O
matched	O
,	O
the	O
minimum	O
cumulative	O
distance	O
calculated	O
by	O
the	O
DP	O
process	O
represents	O
the	O
score	O
for	O
the	O
best	O
way	O
of	O
matching	O
the	O
two	O
words	O
.	O
If	O
the	O
input	O
utterance	O
to	O
be	O
recognised	O
comprises	O
a	O
sequence	O
of	O
words	O
then	O
back-pointers	O
must	O
be	O
used	O
to	O
indicate	O
the	O
direction	O
that	O
has	O
been	O
taken	O
,	O
so	O
that	O
after	O
the	O
DP	O
process	O
identifies	O
the	O
end	O
of	O
the	O
optimum	O
path	O
,	O
it	O
is	O
possible	O
to	O
recognise	O
the	O
input	O
utterance	O
by	O
tracing	O
back	O
through	O
the	O
back-pointers	O
.	O

Although	O
the	O
DP	O
process	O
described	O
above	O
provides	O
a	O
large	O
computational	O
saving	O
compared	O
with	O
the	O
exhaustive	O
search	O
of	O
all	O
possible	O
paths	O
,	O
the	O
remaining	O
computation	O
can	O
be	O
substantial	O
,	O
particularly	O
if	O
each	O
incoming	O
word	O
has	O
to	O
be	O
compared	O
with	O
a	O
large	O
number	O
of	O
word	O
models	O
for	O
matching	O
.	O
Any	O
possible	O
saving	O
in	O
computation	O
which	O
does	O
not	O
significantly	O
affect	O
the	O
accuracy	O
of	O
the	O
recognition	O
result	O
is	O
therefore	O
desirable	O
.	O
One	O
possible	O
computational	O
saving	O
is	O
to	O
prevent	O
paths	O
that	O
are	O
scoring	O
badly	O
from	O
propagating	O
further	O
.	O
This	O
is	O
sometimes	O
known	O
as	O
pruning	O
because	O
the	O
growing	O
paths	O
are	O
like	O
branches	O
of	O
a	O
tree	O
.	O
By	O
pruning	O
the	O
paths	O
in	O
this	O
way	O
,	O
only	O
a	O
narrow	O
band	O
of	O
possible	O
paths	O
are	O
considered	O
which	O
lie	O
on	O
either	O
side	O
of	O
the	O
best	O
path	O
.	O
It	O
will	O
be	O
appreciated	O
that	O
where	O
such	O
pruning	O
is	O
used	O
it	O
can	O
no	O
longer	O
be	O
guaranteed	O
that	O
the	O
dynamic	O
programming	O
process	O
will	O
find	O
the	O
optimum	O
path	O
.	O
However	O
,	O
with	O
a	O
pruning	O
threshold	O
that	O
reduces	O
the	O
average	O
amount	O
of	O
computation	O
by	O
,	O
for	O
example	O
a	O
factor	O
of	O
5	O
to	O
10	O
,	O
the	O
right	O
path	O
will	O
almost	O
always	O
be	O
obtained	O
where	O
the	O
words	O
are	O
fairly	O
similar	O
.	O

In	O
this	O
embodiment	O
,	O
the	O
recognition	O
block	O
17	O
shown	O
in	O
FIG	O
.	O
2	O
uses	O
a	O
dynamic	O
programming	O
matching	O
process	O
similar	O
to	O
the	O
one	O
described	O
above	O
,	O
for	O
matching	O
the	O
sequence	O
of	O
parameter	O
frames	O
for	O
the	O
utterance	O
to	O
be	O
recognised	O
with	O
the	O
word	O
models	O
19	O
and	O
noise	O
model	O
23	O
.	O

Recognition	O
Search	O
Another	O
feature	O
of	O
the	O
speech	O
recognition	O
system	O
according	O
to	O
this	O
embodiment	O
is	O
the	O
manner	O
in	O
which	O
the	O
dynamic	O
programming	O
process	O
is	O
implemented	O
.	O
In	O
particular	O
,	O
this	O
embodiment	O
makes	O
use	O
of	O
the	O
fact	O
that	O
the	O
minimum	O
calculation	O
performed	O
in	O
equation	O
(	O
6	O
)	O
above	O
,	O
i	O
.	O
e	O
.	O

minD	O
(	O
k-1	O
,	O
j	O
)	O
,	O
D	O
(	O
k-1	O
,	O
j-1	O
)	O
,	O
D	O
(	O
k-1	O
,	O
j-2	O
)	O
,	O
D	O
(	O
k-2	O
,	O
j-3	O
)	O
!	O
(	O
7	O
)	O
does	O
not	O
depend	O
upon	O
the	O
current	O
frame	O
f	O
.	O
sub	O
.	O
k	O
being	O
processed	O
.	O
Therefore	O
,	O
this	O
part	O
of	O
equation	O
(	O
6	O
)	O
can	O
be	O
calculated	O
when	O
the	O
previous	O
frame	O
f	O
.	O
sub	O
.	O
k-1	O
is	O
being	O
processed	O
.	O

The	O
manner	O
in	O
which	O
the	O
dynamic	O
programming	O
process	O
is	O
implemented	O
will	O
now	O
be	O
explained	O
with	O
reference	O
to	O
FIGS	O
.	O
21	O
to	O
31	O
.	O

FIG	O
.	O
21	O
is	O
a	O
flow	O
chart	O
illustrating	O
the	O
processing	O
performed	O
in	O
the	O
recognition	O
block	O
17	O
when	O
an	O
input	O
utterance	O
is	O
to	O
be	O
recognised	O
.	O
The	O
system	O
processes	O
the	O
parameter	O
frames	O
of	O
the	O
input	O
utterance	O
in	O
the	O
sequence	O
that	O
they	O
are	O
generated	O
by	O
the	O
preprocessor	O
15	O
.	O
For	O
this	O
,	O
purpose	O
a	O
frame	O
counter	O
variable	O
k	O
is	O
provided	O
which	O
is	O
initialised	O
to	O
zero	O
in	O
step	O
S41	O
and	O
is	O
subsequently	O
incremented	O
after	O
each	O
frame	O
is	O
processed	O
in	O
step	O
S61	O
.	O
Each	O
frame	O
being	O
processed	O
is	O
used	O
in	O
step	O
S47	O
to	O
update	O
the	O
cumulative	O
distances	O
of	O
the	O
remaining	O
valid	O
paths	O
within	O
each	O
word	O
model	O
.	O
For	O
this	O
purpose	O
a	O
word	O
counter	O
w	O
is	O
provided	O
and	O
initialised	O
in	O
step	O
S43	O
and	O
incremented	O
after	O
step	O
S47	O
in	O
step	O
S49	O
.	O
In	O
step	O
S45	O
the	O
system	O
checks	O
to	O
see	O
if	O
all	O
the	O
word	O
models	O
have	O
been	O
processed	O
using	O
the	O
current	O
frame	O
,	O
i	O
.	O
e	O
.	O
it	O
checks	O
to	O
see	O
whether	O
the	O
word	O
counter	O
w	O
is	O
less	O
than	O
the	O
number	O
of	O
words	O
known	O
to	O
the	O
system	O
n	O
.	O
sub	O
.	O
w	O
.	O

Once	O
each	O
word	O
model	O
has	O
been	O
processed	O
using	O
the	O
current	O
frame	O
f	O
.	O
sub	O
.	O
k	O
the	O
processing	O
passes	O
to	O
step	O
S51	O
where	O
the	O
nodes	O
of	O
the	O
language	O
model	O
21	O
shown	O
in	O
FIG	O
.	O
17a	O
are	O
processed	O
using	O
the	O
current	O
frame	O
.	O
The	O
processing	O
performed	O
in	O
step	O
S51	O
takes	O
care	O
of	O
the	O
situation	O
where	O
the	O
current	O
parameter	O
frame	O
corresponds	O
to	O
silence	O
at	O
the	O
beginning	O
or	O
end	O
of	O
the	O
input	O
speech	O
or	O
between	O
allowed	O
sequences	O
of	O
words	O
in	O
the	O
input	O
speech	O
.	O
This	O
processing	O
also	O
ensures	O
that	O
the	O
valid	O
paths	O
can	O
only	O
propagate	O
through	O
allowed	O
sequences	O
of	O
words	O
.	O

After	O
the	O
nodes	O
have	O
been	O
processed	O
in	O
step	O
S51	O
,	O
the	O
cumulative	O
distances	O
for	O
the	O
valid	O
paths	O
which	O
end	O
at	O
one	O
of	O
the	O
beginning	O
or	O
"	O
entry	O
states	O
"	O
of	O
each	O
word	O
model	O
are	O
updated	O
in	O
step	O
S57	O
.	O
This	O
processing	O
is	O
to	O
cope	O
with	O
the	O
situation	O
where	O
the	O
next	O
parameter	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
is	O
matched	O
with	O
the	O
beginning	O
of	O
a	O
word	O
model	O
,	O
when	O
the	O
current	O
parameter	O
frame	O
f	O
.	O
sub	O
.	O
k	O
is	O
matched	O
with	O
the	O
end	O
of	O
another	O
word	O
model	O
.	O
To	O
achieve	O
this	O
,	O
the	O
word	O
counter	O
w	O
is	O
re-initialised	O
to	O
zero	O
in	O
step	O
S53	O
,	O
and	O
the	O
system	O
checks	O
,	O
in	O
step	O
S55	O
,	O
whether	O
all	O
the	O
word	O
models	O
have	O
been	O
processed	O
.	O
The	O
system	O
then	O
updates	O
,	O
in	O
step	O
S57	O
,	O
the	O
cumulative	O
distances	O
for	O
the	O
entry	O
states	O
of	O
the	O
current	O
word	O
model	O
,	O
and	O
the	O
word	O
count	O
w	O
is	O
incremented	O
in	O
step	O
S59	O
.	O
The	O
processing	O
then	O
returns	O
to	O
step	O
S55	O
.	O

After	O
all	O
the	O
word	O
models	O
have	O
been	O
processed	O
for	O
the	O
current	O
parameter	O
frame	O
f	O
.	O
sub	O
.	O
k	O
,	O
the	O
parameter	O
frame	O
counter	O
variable	O
k	O
is	O
incremented	O
in	O
step	O
S61	O
.	O
The	O
system	O
then	O
determines	O
,	O
in	O
step	O
S63	O
,	O
whether	O
there	O
are	O
any	O
more	O
parameter	O
frames	O
of	O
the	O
input	O
utterance	O
to	O
be	O
processed	O
.	O
This	O
is	O
done	O
by	O
comparing	O
k	O
with	O
the	O
system	O
limit	O
(	O
LIMIT	O
)	O
and	O
the	O
end	O
of	O
speech	O
identifier	O
(	O
EOS	O
)	O
in	O
step	O
S63	O
.	O
The	O
system	O
limit	O
is	O
defined	O
by	O
the	O
size	O
of	O
buffer	O
used	O
to	O
store	O
the	O
speech	O
samples	O
output	O
from	O
ADC	O
63	O
shown	O
in	O
FIG	O
.	O
3	O
.	O

If	O
all	O
the	O
parameter	O
frames	O
of	O
the	O
incoming	O
utterance	O
have	O
been	O
processed	O
,	O
then	O
the	O
DP	O
process	O
is	O
complete	O
and	O
a	O
backtracking	O
algorithm	O
is	O
used	O
to	O
determine	O
the	O
optimum	O
path	O
,	O
and	O
hence	O
the	O
recognition	O
result	O
.	O
If	O
on	O
the	O
other	O
hand	O
,	O
the	O
system	O
determines	O
,	O
at	O
step	O
S63	O
,	O
that	O
there	O
are	O
further	O
parameter	O
frames	O
to	O
be	O
processed	O
,	O
then	O
the	O
system	O
adjusts	O
the	O
pruning	O
threshold	O
in	O
step	O
S65	O
and	O
the	O
processing	O
returns	O
to	O
step	O
S43	O
.	O
The	O
pruning	O
threshold	O
Th	O
is	O
adjusted	O
in	O
step	O
S67	O
to	O
limit	O
the	O
number	O
of	O
valid	O
paths	O
that	O
will	O
be	O
processed	O
in	O
steps	O
S47	O
,	O
S51	O
and	O
S57	O
when	O
the	O
next	O
input	O
frame	O
is	O
being	O
processed	O
.	O

The	O
processing	O
performed	O
in	O
step	O
S47	O
of	O
FIG	O
.	O
21	O
will	O
now	O
be	O
described	O
in	O
more	O
detail	O
with	O
reference	O
to	O
FIGS	O
.	O
22	O
to	O
26	O
for	O
a	O
particular	O
example	O
of	O
a	O
word	O
model	O
.	O
In	O
particular	O
,	O
FIG	O
.	O
22	O
shows	O
an	O
example	O
word	O
model	O
201	O
which	O
comprises	O
a	O
sequence	O
of	O
states	O
S.	O
sub	O
.	O
0	O
to	O
S.	O
sub	O
.	O
9	O
derived	O
during	O
a	O
training	O
session	O
,	O
and	O
an	O
exit	O
state	O
S.	O
sub	O
.	O
D	O
at	O
the	O
end	O
of	O
the	O
word	O
model	O
201	O
,	O
the	O
purpose	O
of	O
which	O
will	O
be	O
described	O
below	O
.	O

Each	O
state	O
S	O
of	O
the	O
word	O
model	O
201	O
has	O
associated	O
therewith	O
a	O
cumulative	O
distance	O
store	O
DS	O
!	O
which	O
stores	O
the	O
cumulative	O
distance	O
of	O
a	O
valid	O
path	O
which	O
ends	O
at	O
that	O
state	O
.	O
In	O
this	O
embodiment	O
,	O
the	O
word	O
model	O
201	O
also	O
has	O
associated	O
therewith	O
a	O
current	O
active	O
list	O
203	O
for	O
the	O
current	O
frame	O
f	O
.	O
sub	O
.	O
k	O
which	O
lists	O
,	O
in	O
descending	O
order	O
,	O
the	O
states	O
in	O
the	O
word	O
model	O
that	O
are	O
at	O
the	O
end	O
of	O
a	O
valid	O
path	O
for	O
the	O
current	O
frame	O
f	O
.	O
sub	O
.	O
k	O
.	O
Therefore	O
,	O
each	O
state	O
in	O
the	O
current	O
active	O
list	O
203	O
will	O
store	O
the	O
cumulative	O
distance	O
of	O
the	O
valid	O
path	O
that	O
ends	O
at	O
that	O
state	O
.	O
In	O
this	O
particular	O
example	O
,	O
the	O
current	O
active	O
list	O
203	O
for	O
the	O
current	O
frame	O
f	O
.	O
sub	O
.	O
k	O
lists	O
states	O
S.	O
sub	O
.	O
7	O
,	O
S.	O
sub	O
.	O
5	O
,	O
S.	O
sub	O
.	O
4	O
,	O
S.	O
sub	O
.	O
3	O
,	O
S.	O
sub	O
.	O
2	O
,	O
S.	O
sub	O
.	O
1	O
and	O
S.	O
sub	O
.	O
0	O
.	O
The	O
states	O
on	O
the	O
current	O
active	O
list	O
203	O
will	O
be	O
referred	O
to	O
as	O
active	O
states	O
.	O
In	O
this	O
embodiment	O
,	O
the	O
word	O
model	O
201	O
also	O
has	O
associated	O
therewith	O
a	O
new	O
active	O
list	O
205	O
,	O
which	O
is	O
completed	O
during	O
the	O
processing	O
performed	O
in	O
step	O
S47	O
and	O
which	O
lists	O
the	O
states	O
in	O
the	O
word	O
model	O
201	O
that	O
will	O
be	O
at	O
the	O
end	O
of	O
a	O
valid	O
path	O
for	O
the	O
next	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
.	O

The	O
significance	O
of	O
the	O
current	O
active	O
list	O
203	O
and	O
the	O
new	O
active	O
list	O
205	O
will	O
now	O
be	O
explained	O
with	O
reference	O
to	O
FIG	O
.	O
23	O
.	O
In	O
particular	O
,	O
FIG	O
.	O
23	O
shows	O
seven	O
valid	O
paths	O
p1	O
to	O
p7	O
which	O
represent	O
seven	O
possible	O
matchings	O
between	O
the	O
incoming	O
word	O
and	O
the	O
word	O
model	O
201	O
up	O
to	O
the	O
current	O
frame	O
f	O
.	O
sub	O
.	O
k	O
.	O
As	O
shown	O
,	O
the	O
seven	O
valid	O
paths	O
p1	O
to	O
p7	O
end	O
at	O
word	O
model	O
201	O
states	O
S.	O
sub	O
.	O
7	O
,	O
S.	O
sub	O
.	O
5	O
,	O
S.	O
sub	O
.	O
4	O
,	O
S.	O
sub	O
.	O
3	O
,	O
S.	O
sub	O
.	O
2	O
,	O
S.	O
sub	O
.	O
1	O
and	O
S.	O
sub	O
.	O
0	O
respectively	O
,	O
and	O
it	O
is	O
these	O
end	O
states	O
of	O
the	O
valid	O
paths	O
that	O
are	O
listed	O
,	O
in	O
descending	O
order	O
,	O
in	O
the	O
current	O
active	O
list	O
203	O
.	O
To	O
determine	O
the	O
states	O
that	O
are	O
to	O
be	O
in	O
the	O
new	O
active	O
list	O
205	O
,	O
i	O
.	O
e	O
.	O
to	O
determine	O
the	O
paths	O
remaining	O
for	O
the	O
next	O
input	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
,	O
consideration	O
has	O
to	O
be	O
given	O
to	O
the	O
state	O
transitions	O
that	O
are	O
allowed	O
from	O
one	O
input	O
parameter	O
frame	O
to	O
the	O
next	O
.	O

The	O
maximum	O
amount	O
of	O
time	O
compression	O
of	O
the	O
reference	O
models	O
relative	O
to	O
the	O
incoming	O
utterance	O
is	O
determined	O
by	O
the	O
maximum	O
number	O
of	O
states	O
that	O
can	O
be	O
skipped	O
between	O
adjacent	O
frames	O
of	O
the	O
incoming	O
utterance	O
.	O
In	O
this	O
embodiment	O
,	O
this	O
is	O
set	O
to	O
two	O
,	O
i	O
.	O
e	O
.	O
the	O
DP	O
process	O
follows	O
the	O
state	O
transition	O
diagram	O
shown	O
in	O
FIG	O
.	O
19	O
.	O
The	O
maximum	O
amount	O
of	O
time	O
expansion	O
of	O
the	O
reference	O
models	O
relative	O
to	O
the	O
incoming	O
utterance	O
is	O
determined	O
by	O
the	O
maximum	O
number	O
of	O
consecutive	O
incoming	O
frames	O
which	O
can	O
be	O
matched	O
to	O
the	O
same	O
state	O
.	O
In	O
this	O
embodiment	O
,	O
only	O
three	O
consecutive	O
frames	O
can	O
be	O
matched	O
to	O
the	O
same	O
state	O
.	O
To	O
monitor	O
for	O
this	O
situation	O
,	O
each	O
state	O
S	O
has	O
associated	O
therewith	O
a	O
self-repetition	O
counter	O
,	O
SELF	O
,	O
which	O
is	O
incremented	O
whenever	O
the	O
same	O
valid	O
path	O
ends	O
at	O
that	O
state	O
from	O
one	O
input	O
frame	O
f	O
.	O
sub	O
.	O
k	O
to	O
the	O
next	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
.	O
Therefore	O
,	O
for	O
example	O
,	O
path	O
p5	O
may	O
propagate	O
along	O
one	O
or	O
all	O
of	O
the	O
dashed	O
paths	O
207	O
shown	O
in	O
FIG	O
.	O
23	O
.	O
The	O
other	O
paths	O
p1	O
to	O
p4	O
and	O
p6	O
to	O
p7	O
shown	O
in	O
FIG	O
.	O
23	O
will	O
propagate	O
in	O
a	O
similar	O
manner	O
.	O
If	O
two	O
or	O
more	O
paths	O
meet	O
at	O
the	O
same	O
point	O
,	O
then	O
the	O
path	O
having	O
the	O
lowest	O
cumulative	O
distance	O
is	O
maintained	O
and	O
the	O
others	O
are	O
discarded	O
.	O
Further	O
,	O
if	O
the	O
cumulative	O
distance	O
of	O
a	O
path	O
is	O
greater	O
than	O
the	O
pruning	O
threshold	O
then	O
this	O
path	O
will	O
also	O
be	O
discarded	O
.	O
In	O
this	O
way	O
,	O
new	O
paths	O
are	O
continuously	O
being	O
created	O
whilst	O
others	O
are	O
discarded	O
.	O
The	O
aim	O
of	O
the	O
pruning	O
threshold	O
is	O
to	O
limit	O
the	O
number	O
of	O
valid	O
paths	O
that	O
are	O
processed	O
for	O
each	O
input	O
parameter	O
frame	O
,	O
thereby	O
placing	O
a	O
limit	O
on	O
the	O
amount	O
of	O
time	O
and	O
memory	O
required	O
for	O
the	O
algorithm	O
.	O

FIG	O
.	O
24	O
shows	O
in	O
more	O
detail	O
the	O
processing	O
steps	O
performed	O
in	O
step	O
S47	O
of	O
FIG	O
.	O
21	O
.	O
In	O
particular	O
,	O
in	O
step	O
S71	O
a	O
pointer	O
LA	O
is	O
initialised	O
and	O
the	O
cumulative	O
distance	O
stored	O
in	O
the	O
exit	O
state	O
,	O
i	O
.	O
e	O
.	O
DS	O
.	O
sub	O
.	O
D	O
!	O
,	O
of	O
word	O
model	O
201	O
is	O
set	O
to	O
a	O
very	O
large	O
value	O
,	O
HUGE	O
.	O
The	O
pointer	O
LA	O
is	O
used	O
to	O
point	O
to	O
the	O
last	O
active	O
state	O
that	O
has	O
been	O
placed	O
in	O
the	O
new	O
active	O
list	O
205	O
.	O
Initially	O
,	O
there	O
are	O
no	O
active	O
states	O
in	O
the	O
new	O
active	O
list	O
205	O
and	O
so	O
pointer	O
LA	O
is	O
set	O
to	O
point	O
to	O
the	O
exit	O
state	O
S.	O
sub	O
.	O
D.	O
In	O
step	O
S73	O
the	O
system	O
then	O
checks	O
to	O
see	O
if	O
there	O
are	O
any	O
active	O
states	O
in	O
the	O
current	O
active	O
list	O
203	O
.	O
In	O
other	O
words	O
,	O
a	O
check	O
is	O
made	O
to	O
see	O
if	O
there	O
are	O
any	O
valid	O
paths	O
ending	O
in	O
the	O
current	O
word	O
for	O
the	O
current	O
frame	O
f	O
.	O
sub	O
.	O
k	O
.	O
In	O
the	O
present	O
example	O
there	O
are	O
seven	O
active	O
states	O
in	O
the	O
current	O
active	O
list	O
203	O
and	O
the	O
system	O
processes	O
each	O
in	O
turn	O
.	O
A	O
count	O
variable	O
i	O
is	O
provided	O
,	O
which	O
is	O
used	O
to	O
count	O
through	O
the	O
active	O
states	O
on	O
the	O
current	O
active	O
list	O
203	O
,	O
and	O
which	O
is	O
set	O
to	O
zero	O
in	O
step	O
S75	O
and	O
incremented	O
in	O
step	O
S79	O
until	O
all	O
the	O
active	O
states	O
in	O
the	O
current	O
active	O
list	O
203	O
have	O
been	O
processed	O
.	O
The	O
system	O
determines	O
whether	O
all	O
the	O
active	O
states	O
have	O
been	O
processed	O
by	O
comparing	O
,	O
in	O
step	O
S81	O
,	O
the	O
value	O
of	O
the	O
count	O
variable	O
i	O
with	O
the	O
number	O
n	O
.	O
sub	O
.	O
a	O
of	O
active	O
states	O
in	O
the	O
current	O
active	O
list	O
203	O
.	O

Once	O
all	O
the	O
active	O
states	O
on	O
the	O
current	O
active	O
list	O
203	O
have	O
been	O
processed	O
,	O
the	O
new	O
active	O
list	O
205	O
generated	O
during	O
the	O
processing	O
in	O
step	O
S77	O
is	O
changed	O
,	O
in	O
step	O
S83	O
,	O
to	O
be	O
the	O
current	O
active	O
list	O
203	O
for	O
the	O
next	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
of	O
the	O
input	O
utterance	O
to	O
be	O
processed	O
.	O
In	O
practice	O
this	O
is	O
achieved	O
by	O
swapping	O
the	O
pointers	O
that	O
are	O
used	O
to	O
point	O
to	O
the	O
two	O
active	O
lists	O
.	O
The	O
old	O
current	O
active	O
list	O
then	O
being	O
overwritten	O
during	O
the	O
processing	O
of	O
the	O
next	O
input	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
.	O
Finally	O
in	O
step	O
S85	O
the	O
last	O
state	O
that	O
was	O
activated	O
and	O
put	O
on	O
the	O
new	O
active	O
list	O
205	O
,	O
indicated	O
by	O
pointer	O
LA	O
,	O
is	O
stored	O
for	O
use	O
in	O
step	O
S57	O
shown	O
in	O
FIG	O
.	O
21	O
.	O

An	O
overview	O
of	O
the	O
processing	O
performed	O
in	O
step	O
S77	O
will	O
now	O
be	O
given	O
by	O
taking	O
as	O
examples	O
,	O
active	O
states	O
S.	O
sub	O
.	O
7	O
and	O
S.	O
sub	O
.	O
5	O
,	O
which	O
are	O
at	O
the	O
ends	O
of	O
paths	O
p1	O
and	O
p2	O
respectively	O
,	O
as	O
shown	O
in	O
FIG	O
.	O
23	O
.	O
FIG	O
.	O
25	O
shows	O
part	O
of	O
the	O
two	O
valid	O
paths	O
p1	O
and	O
p2	O
that	O
end	O
at	O
states	O
S.	O
sub	O
.	O
7	O
and	O
S.	O
sub	O
.	O
5	O
respectively	O
at	O
the	O
current	O
frame	O
f	O
.	O
sub	O
.	O
k	O
.	O
The	O
dashed	O
lines	O
in	O
FIG	O
.	O
25	O
show	O
the	O
ways	O
in	O
which	O
each	O
of	O
the	O
two	O
paths	O
p1	O
and	O
p2	O
may	O
propagate	O
at	O
the	O
next	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
.	O
As	O
indicated	O
by	O
dashed	O
line	O
213	O
it	O
is	O
possible	O
for	O
path	O
p1	O
to	O
extend	O
into	O
another	O
word	O
at	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
.	O
Therefore	O
,	O
the	O
cumulative	O
distance	O
of	O
path	O
p1	O
(	O
which	O
is	O
stored	O
in	O
active	O
state	O
S.	O
sub	O
.	O
7	O
)	O
is	O
copied	O
into	O
the	O
exit	O
state	O
S.	O
sub	O
.	O
D.	O
As	O
indicated	O
by	O
dashed	O
lines	O
215	O
,	O
217	O
and	O
219	O
path	O
p1	O
can	O
also	O
propagate	O
to	O
state	O
S.	O
sub	O
.	O
9	O
,	O
state	O
S.	O
sub	O
.	O
8	O
and	O
state	O
S.	O
sub	O
.	O
7	O
respectively	O
.	O
Therefore	O
,	O
the	O
cumulative	O
distance	O
of	O
path	O
p1	O
is	O
also	O
copied	O
into	O
these	O
states	O
.	O
States	O
S.	O
sub	O
.	O
9	O
,	O
S.	O
sub	O
.	O
8	O
and	O
S.	O
sub	O
.	O
7	O
are	O
then	O
added	O
,	O
in	O
descending	O
order	O
,	O
to	O
the	O
new	O
active	O
list	O
205	O
(	O
but	O
not	O
the	O
exit	O
state	O
which	O
is	O
never	O
actually	O
compared	O
with	O
the	O
incoming	O
frames	O
,	O
and	O
is	O
only	O
used	O
to	O
store	O
the	O
minimum	O
cumulative	O
distance	O
of	O
all	O
the	O
paths	O
that	O
leave	O
the	O
word	O
)	O
and	O
the	O
last	O
active	O
pointer	O
LA	O
is	O
set	O
to	O
point	O
to	O
the	O
last	O
state	O
added	O
(	O
i	O
.	O
e	O
.	O
state	O
S.	O
sub	O
.	O
7	O
)	O
.	O

Referring	O
to	O
FIG	O
.	O
26a	O
,	O
the	O
new	O
active	O
list	O
205	O
is	O
shown	O
after	O
the	O
first	O
state	O
S.	O
sub	O
.	O
7	O
on	O
the	O
current	O
active	O
list	O
203	O
has	O
been	O
processed	O
.	O
As	O
shown	O
,	O
state	O
S.	O
sub	O
.	O
9	O
,	O
state	O
S.	O
sub	O
.	O
8	O
and	O
state	O
S.	O
sub	O
.	O
7	O
are	O
in	O
the	O
first	O
three	O
elements	O
of	O
the	O
new	O
active	O
list	O
205	O
respectively	O
,	O
and	O
the	O
last	O
active	O
pointer	O
LA	O
points	O
to	O
state	O
S.	O
sub	O
.	O
7	O
.	O

Referring	O
back	O
to	O
FIG	O
.	O
25	O
,	O
as	O
indicated	O
by	O
dashed	O
lines	O
221	O
,	O
223	O
,	O
225	O
and	O
227	O
path	O
p2	O
can	O
propagate	O
to	O
state	O
S.	O
sub	O
.	O
8	O
,	O
state	O
S.	O
sub	O
.	O
7	O
,	O
state	O
S.	O
sub	O
.	O
6	O
and	O
state	O
S.	O
sub	O
.	O
5	O
respectively	O
.	O
However	O
,	O
the	O
cumulative	O
distance	O
for	O
path	O
p2	O
is	O
not	O
simply	O
copied	O
into	O
each	O
of	O
these	O
states	O
,	O
since	O
two	O
of	O
the	O
states	O
S.	O
sub	O
.	O
8	O
and	O
S.	O
sub	O
.	O
7	O
already	O
have	O
a	O
cumulative	O
distance	O
stored	O
therein	O
for	O
the	O
next	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
.	O
For	O
these	O
two	O
states	O
,	O
a	O
comparison	O
is	O
made	O
between	O
the	O
cumulative	O
distances	O
already	O
stored	O
therein	O
and	O
the	O
cumulative	O
distances	O
associated	O
with	O
path	O
p2	O
,	O
and	O
the	O
smallest	O
is	O
copied	O
into	O
those	O
two	O
states	O
.	O
In	O
other	O
words	O
the	O
cumulative	O
distance	O
stored	O
in	O
S.	O
sub	O
.	O
8	O
and	O
S.	O
sub	O
.	O
7	O
for	O
the	O
paths	O
shown	O
in	O
FIG	O
.	O
23	O
and	O
after	O
processing	O
active	O
state	O
S.	O
sub	O
.	O
5	O
is	O
given	O
by	O
min	O
(	O
DS	O
.	O
sub	O
.	O
7	O
!	O
,	O
DS	O
.	O
sub	O
.	O
5	O
!	O
)	O
.	O
On	O
the	O
other	O
hand	O
,	O
the	O
cumulative	O
distance	O
stored	O
in	O
active	O
state	O
S.	O
sub	O
.	O
5	O
can	O
be	O
copied	O
directly	O
into	O
state	O
S.	O
sub	O
.	O
6	O
since	O
a	O
cumulative	O
distance	O
for	O
the	O
next	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
has	O
not	O
previously	O
been	O
stored	O
therein	O
.	O
The	O
two	O
states	O
S.	O
sub	O
.	O
6	O
and	O
S.	O
sub	O
.	O
5	O
(	O
since	O
state	O
S.	O
sub	O
.	O
5	O
has	O
not	O
repeated	O
twice	O
)	O
are	O
then	O
added	O
to	O
the	O
new	O
active	O
list	O
205	O
and	O
the	O
last	O
active	O
pointer	O
LA	O
is	O
set	O
to	O
point	O
to	O
state	O
S.	O
sub	O
.	O
5	O
.	O

Referring	O
now	O
to	O
FIG	O
.	O
26b	O
,	O
the	O
new	O
active	O
list	O
205	O
is	O
shown	O
after	O
the	O
second	O
active	O
state	O
S.	O
sub	O
.	O
5	O
on	O
the	O
current	O
active	O
list	O
203	O
has	O
been	O
processed	O
.	O
As	O
shown	O
,	O
states	O
S.	O
sub	O
.	O
9	O
,	O
S.	O
sub	O
.	O
8	O
,	O
S.	O
sub	O
.	O
7	O
,	O
S.	O
sub	O
.	O
6	O
and	O
S.	O
sub	O
.	O
5	O
are	O
in	O
the	O
first	O
five	O
elements	O
of	O
the	O
new	O
active	O
list	O
205	O
respectively	O
,	O
and	O
the	O
last	O
active	O
pointer	O
LA	O
points	O
to	O
state	O
S.	O
sub	O
.	O
5	O
.	O
The	O
remaining	O
active	O
states	O
on	O
the	O
current	O
active	O
list	O
203	O
are	O
processed	O
in	O
an	O
identical	O
manner	O
and	O
then	O
the	O
processing	O
proceeds	O
to	O
step	O
S49	O
shown	O
in	O
FIG	O
.	O
21	O
,	O
where	O
the	O
word	O
count	O
is	O
incremented	O
.	O

The	O
last	O
active	O
pointer	O
LA	O
is	O
provided	O
so	O
that	O
the	O
system	O
does	O
not	O
have	O
to	O
look	O
at	O
the	O
new	O
active	O
list	O
205	O
to	O
identify	O
those	O
states	O
which	O
require	O
a	O
comparison	O
and	O
those	O
that	O
do	O
not	O
.	O
If	O
the	O
state	O
is	O
equal	O
to	O
or	O
beyond	O
the	O
state	O
indicated	O
by	O
the	O
last	O
active	O
pointer	O
LA	O
then	O
a	O
comparison	O
is	O
required	O
,	O
otherwise	O
the	O
cumulative	O
distance	O
can	O
simply	O
be	O
copied	O
into	O
the	O
state	O
.	O

The	O
processing	O
performed	O
in	O
step	O
S77	O
shown	O
in	O
FIG	O
.	O
24	O
will	O
now	O
be	O
described	O
in	O
more	O
detail	O
with	O
reference	O
to	O
FIGS	O
.	O
27a	O
and	O
27b	O
,	O
for	O
the	O
example	O
of	O
the	O
word	O
model	O
201	O
shown	O
in	O
FIG	O
.	O
22	O
.	O
The	O
first	O
active	O
state	O
S	O
to	O
be	O
processed	O
corresponding	O
to	O
i	O
=	O
0	O
in	O
step	O
S77	O
is	O
state	O
S.	O
sub	O
.	O
7	O
.	O
Therefore	O
,	O
in	O
step	O
S91	O
of	O
FIG	O
.	O
27a	O
the	O
system	O
checks	O
to	O
see	O
whether	O
the	O
cumulative	O
distance	O
for	O
the	O
valid	O
path	O
ending	O
at	O
state	O
S.	O
sub	O
.	O
7	O
is	O
less	O
than	O
the	O
pruning	O
threshold	O
Th	O
,	O
i	O
.	O
e	O
.	O
DS	O
.	O
sub	O
.	O
7	O
!	O
is	O
compared	O
with	O
Th	O
.	O
If	O
DS	O
.	O
sub	O
.	O
7	O
!	O
is	O
greater	O
than	O
the	O
pruning	O
threshold	O
Th	O
,	O
then	O
this	O
path	O
is	O
discarded	O
and	O
the	O
processing	O
returns	O
to	O
step	O
S79	O
shown	O
in	O
FIG	O
.	O
24	O
.	O
If	O
DS	O
.	O
sub	O
.	O
7	O
!	O
is	O
less	O
than	O
the	O
pruning	O
threshold	O
Th	O
then	O
the	O
processing	O
proceeds	O
to	O
step	O
S92	O
where	O
the	O
variable	O
ACOUNT	O
,	O
which	O
is	O
used	O
to	O
keep	O
count	O
of	O
the	O
total	O
number	O
of	O
active	O
states	O
processed	O
for	O
the	O
current	O
frame	O
f	O
.	O
sub	O
.	O
k	O
,	O
is	O
incremented	O
.	O
Then	O
the	O
system	O
calculates	O
,	O
in	O
step	O
S93	O
,	O
the	O
local	O
distance	O
between	O
the	O
current	O
active	O
state	O
S.	O
sub	O
.	O
7	O
being	O
processed	O
and	O
the	O
current	O
frame	O
f	O
.	O
sub	O
.	O
k	O
being	O
processed	O
and	O
adds	O
this	O
to	O
the	O
cumulative	O
distance	O
DS	O
.	O
sub	O
.	O
7	O
!	O
.	O

In	O
the	O
present	O
embodiment	O
,	O
the	O
following	O
Euclidean	O
distance	O
equation	O
is	O
used	O
to	O
derive	O
a	O
measure	O
of	O
the	O
local	O
distance	O
between	O
the	O
current	O
frame	O
f	O
.	O
sub	O
.	O
k	O
and	O
the	O
current	O
active	O
state	O
S	O
:	O
d	O
(	O
S	O
,	O
f	O
.	O
sub	O
.	O
k	O
)	O
=.parallel.S-f.sub.k	O
.parallel..sup.2	O
(	O
8	O
)	O
After	O
the	O
cumulative	O
distance	O
DS	O
.	O
sub	O
.	O
7	O
!	O
has	O
been	O
updated	O
in	O
step	O
S93	O
,	O
the	O
system	O
checks	O
to	O
see	O
,	O
in	O
step	O
S95	O
,	O
if	O
the	O
valid	O
path	O
which	O
ends	O
at	O
the	O
current	O
active	O
state	O
S.	O
sub	O
.	O
7	O
can	O
leave	O
the	O
current	O
word	O
at	O
the	O
next	O
input	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
.	O
With	O
the	O
above	O
DP	O
constraints	O
this	O
implies	O
determining	O
whether	O
the	O
state	O
three	O
states	O
beyond	O
the	O
current	O
active	O
state	O
S	O
being	O
processed	O
,	O
will	O
be	O
beyond	O
the	O
last	O
state	O
in	O
the	O
word	O
model	O
201	O
.	O
As	O
the	O
state	O
three	O
states	O
beyond	O
the	O
current	O
active	O
state	O
S.	O
sub	O
.	O
7	O
is	O
past	O
the	O
last	O
state	O
S.	O
sub	O
.	O
9	O
,	O
a	O
pointer	O
j	O
is	O
set	O
to	O
point	O
to	O
the	O
exit	O
state	O
S.	O
sub	O
.	O
D	O
at	O
the	O
end	O
of	O
word	O
model	O
201	O
in	O
step	O
S97	O
.	O
In	O
step	O
S101	O
the	O
state	O
indicated	O
by	O
pointer	O
j	O
is	O
compared	O
with	O
the	O
state	O
indicated	O
by	O
the	O
last	O
active	O
pointer	O
LA	O
.	O
Since	O
this	O
is	O
the	O
first	O
active	O
state	O
in	O
the	O
current	O
active	O
list	O
203	O
to	O
be	O
processed	O
,	O
the	O
last	O
active	O
pointer	O
LA	O
will	O
be	O
pointing	O
to	O
the	O
exit	O
state	O
S.	O
sub	O
.	O
D	O
(	O
see	O
step	O
S71	O
shown	O
in	O
FIG	O
.	O
24	O
)	O
.	O
Therefore	O
the	O
processing	O
proceeds	O
to	O
step	O
S103	O
where	O
the	O
cumulative	O
distance	O
stored	O
in	O
the	O
state	O
pointed	O
to	O
by	O
pointer	O
j	O
,	O
i	O
.	O
e	O
.	O
the	O
exit	O
state	O
S.	O
sub	O
.	O
D	O
,	O
is	O
compared	O
with	O
the	O
cumulative	O
distance	O
for	O
the	O
valid	O
path	O
p1	O
ending	O
at	O
the	O
current	O
active	O
state	O
S.	O
sub	O
.	O
7	O
being	O
processed	O
.	O

The	O
cumulative	O
distance	O
stored	O
in	O
the	O
exit	O
state	O
,	O
i	O
.	O
e	O
.	O
DS	O
.	O
sub	O
.	O
D	O
!	O
,	O
has	O
just	O
been	O
set	O
to	O
the	O
large	O
value	O
,	O
HUGE	O
,	O
in	O
step	O
S71	O
shown	O
in	O
FIG	O
.	O
24	O
,	O
and	O
will	O
therefore	O
be	O
larger	O
than	O
the	O
cumulative	O
distance	O
stored	O
in	O
the	O
current	O
active	O
state	O
S.	O
sub	O
.	O
7	O
being	O
processed	O
.	O
Consequently	O
,	O
the	O
processing	O
proceeds	O
to	O
step	O
S105	O
where	O
DS	O
.	O
sub	O
.	O
7	O
!	O
is	O
copied	O
into	O
DS	O
.	O
sub	O
.	O
D	O
!	O
.	O
Next	O
in	O
step	O
S107	O
the	O
self-repetition	O
count	O
for	O
the	O
state	O
indicated	O
by	O
pointer	O
j	O
,	O
i	O
.	O
e	O
.	O
the	O
exit	O
state	O
S.	O
sub	O
.	O
D	O
,	O
is	O
set	O
to	O
zero	O
.	O
Then	O
in	O
step	O
S109	O
the	O
pointer	O
j	O
is	O
decremented	O
and	O
now	O
points	O
to	O
state	O
S.	O
sub	O
.	O
9	O
,	O
and	O
the	O
processing	O
returns	O
to	O
step	O
S101	O
.	O

This	O
time	O
the	O
state	O
indicated	O
by	O
pointer	O
j	O
(	O
state	O
S.	O
sub	O
.	O
9	O
)	O
is	O
before	O
the	O
state	O
indicated	O
by	O
the	O
last	O
active	O
pointer	O
LA	O
(	O
state	O
S.	O
sub	O
.	O
D	O
)	O
and	O
therefore	O
the	O
processing	O
proceeds	O
to	O
step	O
S111	O
shown	O
in	O
FIG	O
.	O
27b	O
.	O
In	O
step	O
S111	O
the	O
system	O
checks	O
to	O
see	O
if	O
the	O
state	O
pointed	O
to	O
by	O
pointer	O
j	O
,	O
i	O
.	O
e	O
.	O
state	O
S.	O
sub	O
.	O
9	O
,	O
is	O
equal	O
to	O
the	O
current	O
active	O
state	O
S.	O
sub	O
.	O
7	O
being	O
processed	O
.	O
It	O
is	O
not	O
,	O
therefore	O
,	O
the	O
processing	O
proceeds	O
to	O
step	O
S113	O
where	O
the	O
cumulative	O
distance	O
stored	O
in	O
state	O
S.	O
sub	O
.	O
9	O
is	O
made	O
equal	O
to	O
the	O
cumulative	O
distance	O
stored	O
in	O
the	O
current	O
active	O
state	O
S.	O
sub	O
.	O
7	O
.	O
In	O
other	O
words	O
,	O
the	O
cumulative	O
distance	O
of	O
path	O
p1	O
is	O
copied	O
into	O
state	O
S.	O
sub	O
.	O
9	O
.	O
Then	O
in	O
step	O
S115	O
state	O
S.	O
sub	O
.	O
9	O
is	O
added	O
to	O
the	O
new	O
active	O
list	O
205	O
shown	O
in	O
FIG	O
.	O
22	O
.	O
In	O
step	O
S117	O
the	O
self-repetition	O
counter	O
associated	O
with	O
state	O
S.	O
sub	O
.	O
9	O
is	O
reset	O
to	O
zero	O
,	O
and	O
in	O
step	O
S119	O
the	O
pointer	O
j	O
is	O
decremented	O
and	O
now	O
points	O
to	O
state	O
S.	O
sub	O
.	O
8	O
.	O
The	O
processing	O
then	O
returns	O
to	O
step	O
S111	O
and	O
state	O
S.	O
sub	O
.	O
8	O
is	O
processed	O
in	O
a	O
similar	O
manner	O
.	O
After	O
state	O
S.	O
sub	O
.	O
8	O
has	O
been	O
processed	O
in	O
steps	O
S113	O
,	O
S115	O
and	O
S117	O
,	O
j	O
is	O
decremented	O
in	O
step	O
S119	O
and	O
now	O
points	O
to	O
state	O
S.	O
sub	O
.	O
7	O
which	O
is	O
also	O
the	O
current	O
active	O
state	O
being	O
processed	O
.	O
Therefore	O
at	O
this	O
point	O
,	O
the	O
processing	O
proceeds	O
to	O
step	O
S121	O
where	O
the	O
self-repetition	O
count	O
associated	O
with	O
state	O
S.	O
sub	O
.	O
7	O
is	O
checked	O
to	O
see	O
if	O
the	O
valid	O
path	O
ending	O
at	O
state	O
S.	O
sub	O
.	O
7	O
has	O
ended	O
there	O
for	O
the	O
past	O
two	O
frames	O
of	O
the	O
input	O
utterance	O
.	O
If	O
the	O
self-repetition	O
count	O
associated	O
with	O
state	O
S.	O
sub	O
.	O
7	O
is	O
equal	O
to	O
two	O
,	O
then	O
state	O
S.	O
sub	O
.	O
7	O
is	O
not	O
added	O
to	O
the	O
new	O
active	O
list	O
205	O
and	O
the	O
processing	O
proceeds	O
to	O
step	O
S123	O
where	O
the	O
last	O
active	O
pointer	O
LA	O
is	O
set	O
to	O
point	O
to	O
the	O
current	O
active	O
state	O
plus	O
one	O
,	O
i	O
.	O
e	O
.	O
to	O
state	O
S.	O
sub	O
.	O
8	O
.	O
This	O
routine	O
ensures	O
that	O
if	O
the	O
self-repetition	O
count	O
associated	O
with	O
the	O
current	O
active	O
state	O
is	O
equal	O
to	O
two	O
,	O
then	O
the	O
valid	O
path	O
which	O
ends	O
at	O
the	O
current	O
active	O
state	O
is	O
prevented	O
from	O
propagating	O
to	O
the	O
same	O
state	O
at	O
the	O
next	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
.	O
In	O
the	O
example	O
of	O
the	O
paths	O
shown	O
in	O
FIG	O
.	O
23	O
,	O
path	O
p1	O
ending	O
at	O
state	O
S.	O
sub	O
.	O
7	O
for	O
the	O
current	O
frame	O
f	O
.	O
sub	O
.	O
k	O
came	O
from	O
state	O
S.	O
sub	O
.	O
6	O
and	O
therefore	O
the	O
self-repetition	O
count	O
will	O
be	O
equal	O
to	O
zero	O
.	O
Consequently	O
,	O
state	O
S.	O
sub	O
.	O
7	O
is	O
added	O
to	O
the	O
new	O
active	O
list	O
205	O
in	O
step	O
S125	O
.	O
The	O
self-repetition	O
count	O
for	O
state	O
S.	O
sub	O
.	O
7	O
is	O
then	O
incremented	O
in	O
step	O
S127	O
,	O
and	O
the	O
last	O
active	O
pointer	O
LA	O
is	O
set	O
to	O
point	O
to	O
the	O
current	O
active	O
state	O
,	O
i	O
.	O
e	O
.	O
state	O
S.	O
sub	O
.	O
7	O
,	O
in	O
step	O
S129	O
.	O

After	O
step	O
S129	O
or	O
step	O
S123	O
the	O
processing	O
proceeds	O
to	O
step	O
S131	O
where	O
the	O
cumulative	O
distance	O
stored	O
in	O
the	O
current	O
active	O
state	O
S.	O
sub	O
.	O
7	O
is	O
compared	O
with	O
the	O
minimum	O
cumulative	O
distance	O
MINSCORE	O
for	O
all	O
of	O
the	O
valid	O
paths	O
,	O
in	O
all	O
the	O
words	O
,	O
that	O
have	O
been	O
processed	O
for	O
the	O
current	O
frame	O
f	O
.	O
sub	O
.	O
k	O
.	O
If	O
the	O
cumulative	O
distance	O
stored	O
in	O
state	O
S.	O
sub	O
.	O
7	O
is	O
less	O
than	O
MINSCORE	O
then	O
MINSCORE	O
is	O
replaced	O
by	O
the	O
cumulative	O
distance	O
stored	O
in	O
state	O
S.	O
sub	O
.	O
7	O
in	O
step	O
S133	O
,	O
and	O
the	O
processing	O
returns	O
to	O
step	O
S79	O
shown	O
in	O
FIG	O
.	O
24	O
.	O
If	O
the	O
cumulative	O
distance	O
stored	O
in	O
MINSCORE	O
is	O
smaller	O
than	O
the	O
cumulative	O
distance	O
associated	O
with	O
the	O
current	O
state	O
S.	O
sub	O
.	O
7	O
,	O
then	O
the	O
processing	O
returns	O
to	O
step	O
S79	O
shown	O
in	O
FIG	O
.	O
24	O
.	O
Upon	O
returning	O
to	O
step	O
S79	O
the	O
count	O
variable	O
i	O
is	O
incremented	O
and	O
the	O
next	O
active	O
state	O
in	O
the	O
current	O
active	O
list	O
203	O
,	O
i	O
.	O
e	O
.	O
state	O
S.	O
sub	O
.	O
5	O
is	O
processed	O
in	O
step	O
S77	O
.	O

Active	O
state	O
S.	O
sub	O
.	O
5	O
is	O
processed	O
in	O
a	O
similar	O
manner	O
to	O
active	O
state	O
S.	O
sub	O
.	O
7	O
described	O
above	O
.	O
In	O
particular	O
,	O
provided	O
the	O
cumulative	O
distance	O
of	O
the	O
valid	O
path	O
ending	O
at	O
state	O
S.	O
sub	O
.	O
5	O
is	O
less	O
than	O
the	O
pruning	O
threshold	O
Th	O
,	O
then	O
in	O
step	O
S93	O
,	O
the	O
system	O
calculates	O
the	O
local	O
distance	O
between	O
the	O
current	O
active	O
state	O
S.	O
sub	O
.	O
5	O
and	O
the	O
current	O
frame	O
f	O
.	O
sub	O
.	O
k	O
being	O
processed	O
and	O
adds	O
this	O
to	O
the	O
cumulative	O
distance	O
stored	O
in	O
the	O
current	O
active	O
state	O
S.	O
sub	O
.	O
5	O
.	O
Then	O
in	O
step	O
S95	O
the	O
system	O
determines	O
that	O
the	O
path	O
p2	O
ending	O
at	O
the	O
current	O
active	O
state	O
S.	O
sub	O
.	O
5	O
cannot	O
extend	O
into	O
another	O
word	O
at	O
the	O
next	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
due	O
to	O
the	O
above	O
DP	O
constraints	O
.	O
In	O
other	O
words	O
three	O
states	O
beyond	O
state	O
S.	O
sub	O
.	O
5	O
is	O
not	O
equal	O
to	O
or	O
beyond	O
state	O
S.	O
sub	O
.	O
D	O
,	O
and	O
therefore	O
the	O
processing	O
proceeds	O
to	O
step	O
S99	O
where	O
the	O
pointer	O
j	O
is	O
set	O
to	O
point	O
to	O
state	O
S.	O
sub	O
.	O
5	O
plus	O
three	O
,	O
i	O
.	O
e	O
.	O
state	O
S.	O
sub	O
.	O
8	O
.	O
The	O
state	O
indicated	O
by	O
pointer	O
j	O
is	O
then	O
compared	O
with	O
the	O
state	O
pointed	O
to	O
by	O
the	O
last	O
active	O
pointer	O
LA	O
in	O
step	O
S101	O
.	O

Last	O
active	O
pointer	O
LA	O
points	O
to	O
state	O
S.	O
sub	O
.	O
7	O
and	O
pointer	O
j	O
points	O
to	O
state	O
S.	O
sub	O
.	O
8	O
.	O
Therefore	O
,	O
the	O
processing	O
proceeds	O
to	O
step	O
S103	O
where	O
the	O
cumulative	O
distance	O
already	O
stored	O
in	O
state	O
S.	O
sub	O
.	O
8	O
(	O
as	O
a	O
result	O
of	O
the	O
processing	O
of	O
active	O
state	O
S.	O
sub	O
.	O
7	O
)	O
is	O
compared	O
with	O
the	O
cumulative	O
distance	O
stored	O
in	O
active	O
state	O
S.	O
sub	O
.	O
5	O
.	O
If	O
the	O
cumulative	O
distance	O
stored	O
in	O
S.	O
sub	O
.	O
8	O
is	O
greater	O
than	O
the	O
cumulative	O
distance	O
stored	O
in	O
active	O
state	O
S.	O
sub	O
.	O
5	O
then	O
it	O
is	O
replaced	O
by	O
the	O
cumulative	O
distance	O
stored	O
in	O
active	O
state	O
S.	O
sub	O
.	O
5	O
.	O
Then	O
the	O
self-repetition	O
counter	O
associated	O
with	O
state	O
S.	O
sub	O
.	O
8	O
is	O
reset	O
to	O
zero	O
in	O
step	O
S107	O
and	O
the	O
pointer	O
j	O
is	O
decremented	O
in	O
step	O
S109	O
so	O
that	O
it	O
now	O
points	O
to	O
state	O
S.	O
sub	O
.	O
7	O
.	O
The	O
processing	O
then	O
returns	O
to	O
step	O
S101	O
where	O
a	O
similar	O
processing	O
is	O
performed	O
.	O

This	O
recursive	O
processing	O
routine	O
is	O
performed	O
on	O
all	O
the	O
current	O
active	O
states	O
in	O
all	O
the	O
reference	O
words	O
known	O
to	O
the	O
system	O
.	O

After	O
processing	O
each	O
word	O
in	O
the	O
above	O
manner	O
for	O
the	O
current	O
frame	O
f	O
.	O
sub	O
.	O
k	O
,	O
each	O
node	O
in	O
the	O
language	O
model	O
21	O
is	O
processed	O
in	O
turn	O
.	O
As	O
described	O
above	O
the	O
language	O
model	O
21	O
determines	O
the	O
sequences	O
of	O
words	O
that	O
are	O
allowable	O
.	O
This	O
information	O
is	O
defined	O
by	O
the	O
nodes	O
and	O
in	O
particular	O
by	O
the	O
words	O
that	O
are	O
connected	O
to	O
the	O
input	O
and	O
output	O
thereof	O
.	O
The	O
processing	O
of	O
the	O
nodes	O
in	O
step	O
S51	O
of	O
FIG	O
.	O
21	O
ensures	O
that	O
valid	O
paths	O
only	O
propagate	O
through	O
allowed	O
sequences	O
of	O
words	O
.	O
The	O
processing	O
performed	O
in	O
step	O
S51	O
will	O
now	O
be	O
described	O
in	O
more	O
detail	O
with	O
reference	O
to	O
FIG	O
.	O
28	O
.	O

Initially	O
,	O
prior	O
to	O
processing	O
any	O
of	O
the	O
nodes	O
the	O
local	O
distance	O
between	O
the	O
frame	O
representative	O
of	O
background	O
noise	O
and	O
the	O
current	O
frame	O
f	O
.	O
sub	O
.	O
k	O
(	O
i	O
.	O
e	O
.	O
d	O
(	O
noise,f.sub.k	O
)	O
)	O
is	O
calculated	O
in	O
step	O
S151	O
.	O
Then	O
in	O
step	O
S153	O
a	O
node	O
pointer	O
v	O
is	O
initialised	O
to	O
point	O
to	O
the	O
start	O
node	O
N.	O
sub	O
.	O
0	O
.	O
Then	O
in	O
step	O
S155	O
the	O
cumulative	O
distance	O
stored	O
in	O
the	O
node	O
pointed	O
to	O
by	O
the	O
node	O
pointer	O
v	O
,	O
i	O
.	O
e	O
.	O
Dv	O
!	O
,	O
is	O
compared	O
with	O
the	O
pruning	O
threshold	O
Th	O
.	O
If	O
Dv	O
!	O
is	O
less	O
than	O
the	O
pruning	O
threshold	O
Th	O
then	O
the	O
processing	O
proceeds	O
to	O
step	O
S157	O
where	O
d	O
(	O
noise,f.sub.k	O
)	O
is	O
added	O
to	O
the	O
cumulative	O
distance	O
stored	O
in	O
the	O
current	O
node	O
v	O
being	O
processed	O
.	O
Then	O
in	O
step	O
S159	O
the	O
system	O
compares	O
Dv	O
!	O
with	O
the	O
value	O
stored	O
in	O
the	O
minimum	O
value	O
store	O
MINSCORE	O
,	O
and	O
copies	O
it	O
into	O
MINSCORE	O
in	O
step	O
S161	O
if	O
it	O
is	O
smaller	O
.	O
Then	O
the	O
count	O
ACOUNT	O
(	O
which	O
indicates	O
the	O
number	O
of	O
active	O
states	O
and	O
nodes	O
that	O
have	O
been	O
processed	O
for	O
the	O
current	O
frame	O
)	O
is	O
incremented	O
in	O
step	O
S163	O
and	O
the	O
processing	O
proceeds	O
to	O
step	O
S165	O
.	O
Returning	O
to	O
step	O
S155	O
,	O
if	O
Dv	O
!	O
is	O
greater	O
than	O
the	O
pruning	O
threshold	O
Th	O
then	O
it	O
is	O
set	O
to	O
the	O
large	O
value	O
HUGE	O
in	O
step	O
S167	O
and	O
the	O
processing	O
proceeds	O
to	O
step	O
S165	O
.	O

The	O
processing	O
performed	O
in	O
step	O
S165	O
and	O
step	O
S168	O
will	O
be	O
explained	O
for	O
the	O
example	O
node	O
N	O
shown	O
in	O
FIG	O
.	O
29	O
,	O
which	O
has	O
the	O
three	O
words	O
"	O
get	O
"	O
,	O
"	O
save	O
"	O
and	O
"	O
load	O
"	O
connected	O
to	O
its	O
input	O
and	O
the	O
words	O
"	O
an	O
"	O
and	O
"	O
the	O
"	O
connected	O
to	O
its	O
output	O
.	O
Although	O
the	O
generation	O
of	O
such	O
a	O
node	O
is	O
not	O
possible	O
using	O
the	O
procedure	O
shown	O
in	O
FIG	O
.	O
17b	O
,	O
this	O
example	O
is	O
chosen	O
to	O
illustrate	O
that	O
the	O
dynamic	O
programming	O
process	O
will	O
work	O
for	O
more	O
complex	O
language	O
models	O
.	O
In	O
particular	O
,	O
finite	O
state	O
grammars	O
where	O
nodes	O
like	O
the	O
one	O
shown	O
in	O
FIG	O
.	O
29	O
are	O
commonplace	O
.	O

In	O
step	O
S165	O
the	O
system	O
determines	O
the	O
minimum	O
of	O
all	O
the	O
cumulative	O
distances	O
stored	O
in	O
the	O
exit	O
states	O
for	O
the	O
words	O
connected	O
to	O
the	O
input	O
of	O
node	O
N	O
,	O
i	O
.	O
e	O
.	O
the	O
exit	O
states	O
of	O
words	O
"	O
get	O
"	O
,	O
"	O
save	O
"	O
and	O
"	O
load	O
"	O
.	O
For	O
the	O
general	O
case	O
,	O
this	O
calculation	O
is	O
represented	O
by	O
:	O
#	O
#	O
EQU3	O
#	O
#	O
where	O
I.	O
sub	O
.	O
w	O
V	O
!	O
represents	O
all	O
the	O
words	O
connected	O
to	O
the	O
input	O
of	O
node	O
v	O
.	O
After	O
the	O
system	O
has	O
determined	O
this	O
minimum	O
cumulative	O
distance	O
for	O
node	O
N	O
,	O
it	O
is	O
copied	O
into	O
the	O
cumulative	O
distance	O
DN	O
!	O
stored	O
in	O
node	O
N	O
if	O
it	O
is	O
smaller	O
than	O
the	O
cumulative	O
distance	O
already	O
stored	O
there	O
.	O
In	O
effect	O
,	O
this	O
is	O
a	O
determination	O
of	O
whether	O
there	O
is	O
a	O
valid	O
path	O
coming	O
from	O
one	O
of	O
the	O
words	O
connected	O
to	O
the	O
input	O
of	O
the	O
node	O
which	O
has	O
a	O
smaller	O
cumulative	O
distance	O
than	O
the	O
cumulative	O
distance	O
of	O
the	O
path	O
which	O
is	O
still	O
propagating	O
in	O
the	O
node	O
.	O

It	O
is	O
possible	O
for	O
valid	O
paths	O
to	O
propagate	O
within	O
the	O
node	O
because	O
it	O
is	O
possible	O
that	O
there	O
are	O
gaps	O
before	O
,	O
between	O
and	O
at	O
the	O
end	O
of	O
the	O
words	O
in	O
the	O
phrase	O
which	O
match	O
with	O
the	O
background	O
noise	O
frame	O
.	O
This	O
possibility	O
of	O
a	O
valid	O
path	O
remaining	O
within	O
a	O
node	O
from	O
one	O
input	O
frame	O
to	O
the	O
next	O
is	O
represented	O
by	O
the	O
arrow	O
231	O
shown	O
in	O
FIG	O
.	O
29	O
,	O
which	O
leaves	O
and	O
returns	O
to	O
node	O
N.	O
Unlike	O
the	O
states	O
of	O
the	O
word	O
models	O
,	O
a	O
path	O
may	O
remain	O
within	O
a	O
node	O
for	O
any	O
number	O
of	O
consecutive	O
input	O
frames	O
.	O
After	O
the	O
system	O
has	O
performed	O
the	O
processing	O
of	O
step	O
S165	O
the	O
cumulative	O
distance	O
stored	O
in	O
node	O
N	O
is	O
copied	O
,	O
in	O
step	O
S168	O
,	O
into	O
the	O
temporary	O
store	O
INSCORE	O
represented	O
by	O
boxes	O
233	O
and	O
235	O
for	O
words	O
"	O
an	O
"	O
and	O
"	O
the	O
"	O
respectively	O
,	O
if	O
it	O
is	O
smaller	O
than	O
the	O
value	O
already	O
stored	O
there	O
.	O
A	O
comparison	O
must	O
be	O
made	O
since	O
it	O
is	O
possible	O
that	O
a	O
word	O
may	O
be	O
connected	O
to	O
the	O
output	O
of	O
more	O
than	O
one	O
node	O
,	O
and	O
it	O
is	O
only	O
the	O
path	O
having	O
the	O
minimum	O
cumulative	O
distance	O
that	O
is	O
propagated	O
into	O
the	O
connecting	O
word	O
.	O
The	O
cumulative	O
distance	O
stored	O
in	O
the	O
temporary	O
store	O
INSCORE	O
of	O
a	O
word	O
is	O
used	O
to	O
update	O
the	O
entry	O
states	O
of	O
that	O
word	O
during	O
the	O
processing	O
in	O
step	O
S57	O
shown	O
in	O
FIG	O
.	O
21	O
.	O

The	O
system	O
then	O
checks	O
,	O
in	O
step	O
S169	O
,	O
whether	O
Dv	O
!	O
equals	O
the	O
large	O
value	O
HUGE	O
.	O
If	O
it	O
does	O
,	O
then	O
this	O
indicates	O
that	O
no	O
valid	O
paths	O
will	O
end	O
or	O
pass	O
through	O
the	O
current	O
node	O
v	O
into	O
a	O
word	O
connected	O
to	O
it	O
at	O
the	O
next	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
.	O
If	O
Dv	O
!	O
is	O
less	O
than	O
the	O
large	O
value	O
HUGE	O
,	O
then	O
a	O
valid	O
path	O
will	O
either	O
end	O
at	O
the	O
node	O
v	O
or	O
passes	O
through	O
it	O
into	O
a	O
word	O
connected	O
to	O
it	O
,	O
at	O
the	O
next	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
.	O
Therefore	O
,	O
the	O
counter	O
PACOUNT	O
,	O
which	O
represents	O
the	O
number	O
of	O
potentially	O
active	O
states	O
(	O
and	O
nodes	O
)	O
at	O
the	O
next	O
input	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
,	O
is	O
incremented	O
in	O
step	O
S171	O
since	O
the	O
silence	O
state	O
associated	O
with	O
that	O
node	O
may	O
be	O
active	O
at	O
the	O
next	O
input	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
.	O
The	O
node	O
pointer	O
v	O
is	O
then	O
incremented	O
in	O
step	O
S173	O
and	O
will	O
now	O
point	O
to	O
the	O
next	O
node	O
in	O
the	O
language	O
model	O
21	O
.	O
The	O
system	O
then	O
checks	O
to	O
see	O
if	O
all	O
the	O
nodes	O
in	O
the	O
language	O
model	O
21	O
have	O
been	O
processed	O
in	O
step	O
S175	O
,	O
by	O
checking	O
to	O
see	O
if	O
the	O
node	O
pointer	O
v	O
indicates	O
a	O
node	O
which	O
is	O
beyond	O
the	O
end	O
node	O
N.	O
sub	O
.	O
n	O
in	O
the	O
language	O
model	O
21	O
.	O
If	O
the	O
system	O
has	O
not	O
finished	O
processing	O
all	O
the	O
nodes	O
,	O
then	O
the	O
processing	O
returns	O
to	O
step	O
S155	O
,	O
whereas	O
if	O
all	O
the	O
nodes	O
have	O
been	O
processed	O
then	O
the	O
processing	O
returns	O
to	O
step	O
S53	O
shown	O
in	O
FIG	O
.	O
21	O
.	O

The	O
processing	O
performed	O
in	O
step	O
S57	O
shown	O
in	O
FIG	O
.	O
21	O
will	O
now	O
be	O
described	O
in	O
more	O
detail	O
with	O
reference	O
to	O
FIGS	O
.	O
30	O
and	O
31	O
,	O
for	O
the	O
word	O
model	O
201	O
shown	O
in	O
FIG	O
.	O
22	O
.	O
Referring	O
to	O
FIG	O
.	O
30	O
,	O
in	O
step	O
S181	O
the	O
system	O
checks	O
to	O
see	O
if	O
the	O
cumulative	O
distance	O
stored	O
in	O
INSCORE	O
equals	O
the	O
large	O
value	O
HUGE	O
.	O
If	O
it	O
does	O
then	O
this	O
means	O
that	O
no	O
valid	O
paths	O
will	O
be	O
entering	O
this	O
word	O
at	O
the	O
next	O
time	O
point	O
.	O
Therefore	O
,	O
this	O
word	O
does	O
not	O
need	O
to	O
be	O
processed	O
again	O
,	O
so	O
the	O
processing	O
proceeds	O
to	O
step	O
S207	O
where	O
the	O
number	O
of	O
active	O
states	O
for	O
the	O
next	O
input	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
(	O
which	O
are	O
now	O
stored	O
in	O
the	O
current	O
active	O
list	O
203	O
due	O
to	O
step	O
S83	O
shown	O
in	O
FIG	O
.	O
24	O
)	O
,	O
is	O
added	O
to	O
the	O
count	O
PACOUNT	O
.	O
The	O
processing	O
then	O
returns	O
to	O
step	O
S59	O
shown	O
in	O
FIG	O
.	O
21	O
where	O
the	O
word	O
count	O
is	O
incremented	O
so	O
that	O
the	O
next	O
word	O
model	O
can	O
be	O
processed	O
.	O

If	O
on	O
the	O
other	O
hand	O
,	O
INSCORE	O
is	O
not	O
equal	O
to	O
the	O
large	O
value	O
HUGE	O
,	O
then	O
this	O
means	O
that	O
a	O
valid	O
path	O
has	O
left	O
a	O
preceding	O
word	O
and	O
may	O
enter	O
the	O
current	O
word	O
being	O
processed	O
.	O
Therefore	O
,	O
the	O
states	O
of	O
the	O
current	O
word	O
model	O
which	O
can	O
be	O
reached	O
by	O
a	O
path	O
extending	O
from	O
another	O
word	O
model	O
(	O
which	O
will	O
be	O
referred	O
to	O
as	O
the	O
entry	O
states	O
)	O
must	O
be	O
updated	O
using	O
the	O
cumulative	O
distance	O
stored	O
in	O
INSCORE	O
.	O
In	O
the	O
present	O
embodiment	O
with	O
the	O
above	O
DP	O
constraints	O
the	O
entry	O
states	O
are	O
states	O
.	O
S.	O
sub	O
.	O
0	O
,	O
S.	O
sub	O
.	O
1	O
and	O
S.	O
sub	O
.	O
2	O
.	O
This	O
updating	O
procedure	O
is	O
achieved	O
in	O
the	O
following	O
manner	O
.	O
Firstly	O
in	O
step	O
S183	O
the	O
system	O
checks	O
to	O
see	O
if	O
the	O
word	O
model	O
representative	O
of	O
the	O
current	O
word	O
being	O
processed	O
contains	O
more	O
than	O
three	O
states	O
(	O
not	O
including	O
the	O
exit	O
state	O
)	O
.	O
If	O
there	O
are	O
more	O
than	O
three	O
states	O
,	O
then	O
the	O
state	O
pointer	O
j	O
is	O
set	O
to	O
point	O
to	O
state	O
S.	O
sub	O
.	O
2	O
in	O
step	O
S185	O
.	O
If	O
on	O
there	O
other	O
hand	O
there	O
are	O
less	O
than	O
three	O
states	O
in	O
the	O
current	O
word	O
,	O
then	O
the	O
state	O
pointer	O
j	O
is	O
set	O
,	O
in	O
step	O
S187	O
,	O
to	O
point	O
to	O
the	O
exit	O
state	O
S.	O
sub	O
.	O
D	O
at	O
the	O
end	O
of	O
the	O
word	O
being	O
processed	O
.	O
After	O
the	O
state	O
pointer	O
j	O
has	O
been	O
set	O
to	O
point	O
to	O
either	O
state	O
S.	O
sub	O
.	O
D	O
or	O
state	O
S.	O
sub	O
.	O
2	O
in	O
steps	O
S187	O
or	O
S185	O
respectively	O
,	O
the	O
processing	O
proceeds	O
to	O
step	O
S189	O
where	O
the	O
state	O
indicated	O
by	O
pointer	O
j	O
is	O
compared	O
with	O
the	O
state	O
indicated	O
by	O
the	O
last	O
active	O
pointer	O
LA	O
.	O

As	O
with	O
the	O
processing	O
performed	O
in	O
the	O
sequence	O
of	O
steps	O
shown	O
in	O
FIGS	O
.	O
27a	O
and	O
27b	O
,	O
if	O
the	O
state	O
indicated	O
by	O
pointer	O
j	O
is	O
beyond	O
the	O
state	O
indicated	O
by	O
the	O
last	O
active	O
pointer	O
LA	O
,	O
then	O
a	O
comparison	O
has	O
to	O
be	O
made	O
between	O
the	O
cumulative	O
distance	O
already	O
stored	O
in	O
that	O
state	O
and	O
the	O
cumulative	O
distance	O
stored	O
in	O
INSCORE	O
.	O

For	O
the	O
example	O
DP	O
paths	O
shown	O
in	O
FIG	O
.	O
23	O
,	O
path	O
p7	O
can	O
propagate	O
to	O
states	O
S.	O
sub	O
.	O
1	O
,	O
S.	O
sub	O
.	O
2	O
and	O
S.	O
sub	O
.	O
3	O
at	O
the	O
next	O
frame	O
f	O
.	O
sub	O
.	O
k	O
+	O
1	O
but	O
not	O
to	O
state	O
S.	O
sub	O
.	O
0	O
,	O
since	O
path	O
p7	O
has	O
ended	O
at	O
state	O
S.	O
sub	O
.	O
0	O
for	O
the	O
preceding	O
two	O
frames	O
.	O
Therefore	O
,	O
the	O
last	O
active	O
pointer	O
LA	O
will	O
point	O
to	O
state	O
S.	O
sub	O
.	O
1	O
.	O

FIG	O
.	O
31	O
shows	O
the	O
entry	O
states	O
(	O
i	O
.	O
e	O
.	O
the	O
first	O
three	O
states	O
)	O
of	O
the	O
word	O
model	O
201	O
shown	O
in	O
FIG	O
.	O
22	O
.	O
As	O
shown	O
,	O
the	O
last	O
active	O
pointer	O
LA	O
points	O
to	O
state	O
S.	O
sub	O
.	O
1	O
.	O
Since	O
there	O
are	O
more	O
than	O
three	O
states	O
in	O
the	O
word	O
model	O
201	O
the	O
state	O
pointer	O
j	O
will	O
point	O
to	O
state	O
S.	O
sub	O
.	O
2	O
.	O
Therefore	O
,	O
the	O
system	O
will	O
determine	O
,	O
in	O
step	O
S189	O
,	O
that	O
the	O
state	O
indicated	O
by	O
pointer	O
j	O
is	O
beyond	O
the	O
state	O
indicated	O
by	O
the	O
last	O
active	O
pointer	O
LA	O
,	O
i	O
.	O
e	O
.	O
state	O
S.	O
sub	O
.	O
1	O
,	O
and	O
therefore	O
,	O
the	O
processing	O
proceeds	O
to	O
step	O
S191	O
.	O
In	O
step	O
S191	O
the	O
system	O
compares	O
the	O
cumulative	O
distance	O
stored	O
in	O
state	O
S.	O
sub	O
.	O
2	O
with	O
the	O
cumulative	O
distance	O
stored	O
in	O
the	O
temporary	O
store	O
INSCORE	O
associated	O
with	O
word	O
model	O
201	O
.	O
The	O
store	O
INSCORE	O
,	O
for	O
word	O
model	O
201	O
,	O
is	O
represented	O
by	O
rectangular	O
box	O
241	O
shown	O
in	O
FIG	O
.	O
31	O
.	O
If	O
the	O
cumulative	O
distance	O
stored	O
in	O
INSCORE	O
is	O
smaller	O
than	O
the	O
cumulative	O
distance	O
stored	O
in	O
state	O
S.	O
sub	O
.	O
2	O
,	O
then	O
it	O
is	O
copied	O
into	O
state	O
S.	O
sub	O
.	O
2	O
in	O
step	O
S193	O
.	O
Then	O
in	O
step	O
S195	O
the	O
self-repetition	O
count	O
for	O
state	O
S.	O
sub	O
.	O
2	O
is	O
reset	O
to	O
zero	O
and	O
the	O
processing	O
proceeds	O
to	O
step	O
S197	O
.	O
If	O
the	O
cumulative	O
distance	O
stored	O
in	O
INSCORE	O
is	O
greater	O
than	O
the	O
cumulative	O
distance	O
stored	O
in	O
state	O
S.	O
sub	O
.	O
2	O
,	O
then	O
the	O
cumulative	O
distance	O
stored	O
in	O
state	O
S.	O
sub	O
.	O
2	O
is	O
unchanged	O
and	O
the	O
processing	O
proceeds	O
to	O
step	O
S197	O
where	O
the	O
pointer	O
j	O
is	O
decremented	O
so	O
that	O
it	O
now	O
points	O
to	O
state	O
S.	O
sub	O
.	O
1	O
.	O
The	O
processing	O
then	O
returns	O
to	O
step	O
S189	O
and	O
the	O
same	O
processing	O
is	O
performed	O
to	O
state	O
S.	O
sub	O
.	O
1	O
.	O

After	O
processing	O
state	O
S.	O
sub	O
.	O
1	O
the	O
pointer	O
j	O
is	O
decremented	O
again	O
in	O
step	O
S197	O
,	O
and	O
will	O
now	O
point	O
to	O
state	O
S.	O
sub	O
.	O
0	O
.	O
Therefore	O
,	O
the	O
processing	O
will	O
proceed	O
to	O
step	O
S198	O
after	O
step	O
S189	O
,	O
where	O
the	O
system	O
checks	O
to	O
see	O
if	O
there	O
are	O
any	O
more	O
states	O
to	O
be	O
processed	O
.	O
Since	O
state	O
S.	O
sub	O
.	O
0	O
is	O
still	O
to	O
be	O
processed	O
,	O
the	O
system	O
proceeds	O
to	O
step	O
S199	O
where	O
the	O
cumulative	O
distance	O
stored	O
in	O
INSCORE	O
is	O
copied	O
into	O
state	O
S.	O
sub	O
.	O
0	O
.	O
No	O
comparison	O
of	O
cumulative	O
distances	O
has	O
to	O
be	O
performed	O
for	O
state	O
S.	O
sub	O
.	O
0	O
as	O
this	O
state	O
is	O
before	O
the	O
last	O
active	O
state	O
pointed	O
to	O
by	O
the	O
last	O
active	O
pointer	O
.	O
The	O
system	O
then	O
adds	O
,	O
in	O
step	O
S201	O
state	O
S.	O
sub	O
.	O
0	O
to	O
the	O
current	O
active	O
list	O
(	O
which	O
was	O
the	O
new	O
active	O
list	O
205	O
prior	O
to	O
step	O
S83	O
in	O
FIG	O
.	O
24	O
)	O
and	O
decrements	O
the	O
pointer	O
j	O
so	O
that	O
it	O
now	O
points	O
to	O
state	O
S.	O
sub	O
.	O
-	O
1	O
.	O
The	O
processing	O
then	O
returns	O
to	O
step	O
S198	O
where	O
the	O
system	O
determines	O
that	O
there	O
are	O
no	O
more	O
entry	O
states	O
in	O
the	O
current	O
word	O
to	O
be	O
processed	O
.	O
The	O
processing	O
then	O
proceeds	O
to	O
step	O
S205	O
where	O
the	O
cumulative	O
distance	O
stored	O
in	O
the	O
corresponding	O
temporary	O
store	O
INSCORE	O
is	O
reset	O
to	O
the	O
large	O
value	O
HUGE	O
.	O
The	O
number	O
of	O
states	O
on	O
the	O
current	O
active	O
list	O
is	O
then	O
added	O
,	O
in	O
step	O
S207	O
to	O
the	O
count	O
PACOUNT	O
and	O
the	O
processing	O
returns	O
to	O
step	O
S59	O
shown	O
in	O
FIG	O
.	O
21	O
.	O

Pruning	O
Referring	O
to	O
FIG	O
.	O
21	O
,	O
if	O
in	O
step	O
S63	O
the	O
system	O
determines	O
that	O
there	O
are	O
more	O
input	O
frames	O
to	O
be	O
processed	O
,	O
then	O
the	O
processing	O
proceeds	O
to	O
step	O
S65	O
where	O
the	O
pruning	O
threshold	O
Th	O
is	O
adjusted	O
.	O
The	O
aim	O
of	O
using	O
pruning	O
is	O
to	O
limit	O
the	O
number	O
of	O
DP	O
paths	O
that	O
propagate	O
from	O
one	O
time	O
point	O
to	O
the	O
next	O
.	O
In	O
particular	O
,	O
the	O
present	O
embodiment	O
aims	O
to	O
adjust	O
the	O
pruning	O
threshold	O
so	O
that	O
the	O
number	O
of	O
active	O
states	O
that	O
are	O
actually	O
processed	O
remains	O
essentially	O
bounded	O
within	O
predefined	O
limits	O
,	O
which	O
are	O
dictated	O
by	O
the	O
amount	O
of	O
working	O
memory	O
and	O
processing	O
time	O
available	O
.	O
Furthermore	O
,	O
the	O
present	O
embodiment	O
also	O
aims	O
to	O
achieve	O
this	O
without	O
the	O
need	O
for	O
expensive	O
computational	O
overheads	O
.	O
In	O
this	O
embodiment	O
,	O
the	O
pruning	O
threshold	O
is	O
determined	O
by	O
adding	O
a	O
variable	O
differential	O
value	O
(	O
PRUNING	O
)	O
to	O
the	O
overall	O
minimum	O
cumulative	O
score	O
MINSCORE	O
determined	O
for	O
the	O
input	O
frame	O
just	O
processed	O
,	O
i	O
.	O
e	O
.	O
the	O
pruning	O
threshold	O
is	O
given	O
by	O
:	O
Th=MINSCORE+PRUNING	O
(	O
10	O
)	O
One	O
way	O
of	O
ensuring	O
that	O
only	O
a	O
set	O
number	O
of	O
active	O
states	O
are	O
processed	O
for	O
each	O
input	O
frame	O
is	O
to	O
sort	O
the	O
active	O
states	O
that	O
are	O
on	O
all	O
the	O
active	O
lists	O
for	O
the	O
input	O
frame	O
about	O
to	O
be	O
processed	O
in	O
order	O
of	O
increasing	O
cumulative	O
distances	O
stored	O
therein	O
,	O
and	O
then	O
only	O
processing	O
the	O
desired	O
number	O
beginning	O
with	O
the	O
one	O
with	O
the	O
lowest	O
cumulative	O
distance	O
.	O
However	O
,	O
this	O
technique	O
requires	O
a	O
large	O
amount	O
of	O
computational	O
time	O
to	O
sort	O
out	O
the	O
active	O
states	O
.	O
Rather	O
than	O
performing	O
this	O
computationally	O
expensive	O
sorting	O
,	O
the	O
technique	O
employed	O
in	O
the	O
present	O
embodiment	O
makes	O
use	O
of	O
the	O
information	O
available	O
after	O
processing	O
the	O
last	O
input	O
frame	O
.	O
In	O
particular	O
,	O
in	O
this	O
embodiment	O
a	O
differential	O
value	O
(	O
PRUNING	O
)	O
is	O
varied	O
in	O
dependence	O
upon	O
the	O
number	O
of	O
states	O
that	O
are	O
potentially	O
active	O
(	O
which	O
is	O
stored	O
in	O
PACOUNT	O
)	O
for	O
the	O
next	O
input	O
frame	O
to	O
be	O
processed	O
,	O
in	O
order	O
to	O
maintain	O
the	O
number	O
of	O
states	O
that	O
will	O
actually	O
be	O
processed	O
,	O
to	O
be	O
between	O
two	O
thresholds	O
.	O
The	O
manner	O
in	O
which	O
the	O
pruning	O
threshold	O
Th	O
is	O
adjusted	O
will	O
now	O
be	O
described	O
in	O
more	O
detail	O
with	O
reference	O
to	O
FIG	O
.	O
32	O
.	O

In	O
step	O
S211	O
the	O
system	O
compares	O
the	O
number	O
of	O
states	O
that	O
are	O
potentially	O
active	O
for	O
the	O
next	O
frame	O
to	O
be	O
processed	O
(	O
which	O
is	O
stored	O
in	O
PACOUNT	O
)	O
with	O
a	O
state	O
threshold	O
(	O
STATETH	O
)	O
,	O
which	O
is	O
set	O
to	O
be	O
less	O
than	O
but	O
close	O
to	O
an	O
absolute	O
maximum	O
state	O
threshold	O
determined	O
by	O
the	O
amount	O
of	O
working	O
memory	O
available	O
.	O
If	O
the	O
value	O
stored	O
in	O
PACOUNT	O
is	O
less	O
than	O
STATETH	O
then	O
this	O
means	O
that	O
all	O
the	O
potentially	O
active	O
states	O
can	O
be	O
processed	O
,	O
and	O
therefore	O
,	O
the	O
differential	O
value	O
PRUNING	O
used	O
at	O
the	O
last	O
time	O
point	O
can	O
be	O
increased	O
.	O
Therefore	O
,	O
in	O
step	O
S213	O
an	O
adjustment	O
constant	O
dp1	O
is	O
added	O
to	O
the	O
existing	O
differential	O
value	O
,	O
PRUNING	O
.	O
The	O
value	O
of	O
dP1	O
is	O
set	O
to	O
be	O
larger	O
than	O
any	O
reasonable	O
local	O
distance	O
,	O
so	O
that	O
most	O
,	O
if	O
not	O
all	O
,	O
of	O
the	O
potentially	O
active	O
states	O
will	O
be	O
processed	O
.	O

The	O
value	O
stored	O
in	O
PRUNING	O
is	O
then	O
compared	O
with	O
a	O
high	O
pruning	O
threshold	O
,	O
HIGHPRTH	O
in	O
step	O
S215	O
.	O
An	O
upper	O
limit	O
is	O
placed	O
on	O
the	O
differential	O
value	O
PRUNING	O
as	O
it	O
is	O
assumed	O
that	O
there	O
is	O
a	O
maximum	O
differential	O
value	O
above	O
which	O
there	O
is	O
never	O
any	O
need	O
to	O
go	O
.	O
If	O
the	O
value	O
stored	O
in	O
PRUNING	O
is	O
less	O
than	O
HIGHPRTH	O
then	O
the	O
processing	O
proceeds	O
to	O
step	O
S219	O
.	O
If	O
the	O
value	O
stored	O
in	O
PRUNING	O
is	O
greater	O
than	O
HIGHPRTH	O
then	O
PRUNING	O
is	O
set	O
to	O
equal	O
HIGHPRTH	O
in	O
step	O
S217	O
.	O
After	O
step	O
S215	O
or	O
step	O
S217	O
the	O
system	O
sets	O
the	O
pruning	O
threshold	O
Th	O
to	O
equal	O
the	O
minimum	O
cumulative	O
distance	O
of	O
all	O
the	O
remaining	O
valid	O
paths	O
,	O
i	O
.	O
e	O
.	O
MINSCORE	O
,	O
plus	O
the	O
differential	O
value	O
PRUNING	O
.	O
The	O
processing	O
then	O
returns	O
to	O
step	O
S43	O
shown	O
in	O
FIG	O
.	O
21	O
.	O

If	O
at	O
step	O
S211	O
the	O
system	O
determines	O
that	O
the	O
number	O
of	O
potentially	O
active	O
states	O
,	O
PACOUNT	O
,	O
for	O
the	O
next	O
frame	O
is	O
greater	O
than	O
STATETH	O
,	O
then	O
the	O
system	O
compares	O
,	O
in	O
step	O
S221	O
,	O
the	O
number	O
of	O
states	O
that	O
were	O
active	O
and	O
processed	O
during	O
the	O
processing	O
of	O
the	O
last	O
input	O
frame	O
(	O
which	O
is	O
stored	O
in	O
ACOUNT	O
)	O
with	O
a	O
low	O
state	O
threshold	O
,	O
LOWSTTH	O
.	O
The	O
value	O
of	O
LOWSTTH	O
is	O
set	O
to	O
try	O
and	O
ensure	O
that	O
if	O
ACOUNT	O
is	O
less	O
than	O
LOWSTTH	O
,	O
then	O
it	O
will	O
be	O
possible	O
to	O
process	O
all	O
the	O
potentially	O
active	O
states	O
for	O
the	O
next	O
input	O
frame	O
without	O
taking	O
too	O
much	O
time	O
or	O
memory	O
.	O
Therefore	O
,	O
if	O
ACOUNT	O
is	O
less	O
than	O
LOWSTTH	O
,	O
then	O
the	O
processing	O
passes	O
from	O
step	O
S221	O
to	O
step	O
S213	O
where	O
the	O
differential	O
value	O
PRUNING	O
is	O
adjusted	O
and	O
the	O
processing	O
proceeds	O
as	O
described	O
above	O
.	O
If	O
,	O
on	O
the	O
other	O
hand	O
,	O
ACOUNT	O
is	O
greater	O
than	O
LOWSTTH	O
then	O
there	O
is	O
no	O
guarantee	O
that	O
if	O
all	O
the	O
potentially	O
active	O
states	O
are	O
processed	O
then	O
this	O
will	O
not	O
take	O
too	O
much	O
time	O
or	O
memory	O
to	O
process	O
.	O
Therefore	O
,	O
it	O
may	O
be	O
necessary	O
to	O
reduce	O
the	O
differential	O
value	O
PRUNING	O
.	O

In	O
order	O
to	O
determine	O
whether	O
the	O
differential	O
value	O
PRUNING	O
needs	O
to	O
be	O
reduced	O
,	O
the	O
system	O
compares	O
ACOUNT	O
with	O
STATETH	O
in	O
step	O
S223	O
.	O
If	O
ACOUNT	O
is	O
less	O
than	O
STATETH	O
then	O
the	O
system	O
checks	O
to	O
see	O
if	O
the	O
differential	O
value	O
PRUNING	O
is	O
equal	O
to	O
HIGHPRTH	O
.	O
If	O
it	O
does	O
equal	O
HIGHPRTH	O
then	O
this	O
indicates	O
that	O
the	O
system	O
has	O
been	O
trying	O
to	O
process	O
all	O
the	O
active	O
states	O
,	O
and	O
that	O
therefore	O
,	O
it	O
is	O
unlikely	O
that	O
the	O
number	O
of	O
active	O
states	O
that	O
will	O
be	O
processed	O
for	O
the	O
next	O
input	O
frame	O
will	O
result	O
in	O
the	O
process	O
taking	O
too	O
long	O
or	O
too	O
much	O
memory	O
.	O
Therefore	O
,	O
the	O
differential	O
value	O
PRUNING	O
is	O
not	O
changed	O
and	O
the	O
processing	O
passes	O
to	O
step	O
S219	O
where	O
the	O
pruning	O
threshold	O
is	O
set	O
to	O
equal	O
MINSCORE	O
plus	O
the	O
differential	O
value	O
PRUNING	O
.	O
If	O
on	O
the	O
other	O
hand	O
,	O
the	O
differential	O
value	O
PRUNING	O
is	O
not	O
equal	O
to	O
HIGHPRTH	O
(	O
in	O
which	O
case	O
it	O
must	O
be	O
less	O
than	O
it	O
)	O
,	O
then	O
it	O
is	O
possible	O
that	O
the	O
number	O
of	O
active	O
states	O
that	O
will	O
be	O
processed	O
for	O
the	O
next	O
input	O
frame	O
will	O
take	O
too	O
long	O
or	O
too	O
much	O
memory	O
.	O
Therefore	O
,	O
the	O
actual	O
number	O
of	O
active	O
states	O
that	O
will	O
be	O
processed	O
must	O
be	O
calculated	O
.	O
This	O
is	O
performed	O
in	O
step	O
S233	O
using	O
the	O
pruning	O
threshold	O
set	O
in	O
step	O
S231	O
which	O
uses	O
an	O
unchanged	O
differential	O
value	O
PRUNING	O
.	O

Returning	O
to	O
step	O
S223	O
,	O
if	O
the	O
system	O
determines	O
that	O
ACOUNT	O
is	O
greater	O
than	O
STATETH	O
then	O
the	O
differential	O
value	O
PRUNING	O
is	O
reduced	O
by	O
the	O
adjustment	O
constant	O
dp1	O
in	O
step	O
S225	O
.	O
After	O
the	O
differential	O
value	O
PRUNING	O
has	O
been	O
decreased	O
in	O
step	O
S225	O
,	O
the	O
system	O
determines	O
in	O
step	O
S227	O
whether	O
the	O
differential	O
value	O
PRUNING	O
is	O
less	O
than	O
a	O
low	O
pruning	O
threshold	O
,	O
LOWPRTH	O
.	O
A	O
low	O
pruning	O
threshold	O
is	O
used	O
to	O
ensure	O
that	O
the	O
number	O
of	O
active	O
states	O
that	O
will	O
be	O
processed	O
for	O
the	O
next	O
input	O
frame	O
,	O
will	O
be	O
greater	O
than	O
a	O
set	O
emergency	O
state	O
threshold	O
,	O
EMGSTTH	O
.	O
The	O
reason	O
for	O
this	O
is	O
that	O
it	O
has	O
been	O
found	O
that	O
the	O
dynamic	O
programming	O
process	O
fails	O
if	O
it	O
is	O
pruned	O
too	O
heavily	O
.	O
If	O
the	O
differential	O
value	O
PRUNING	O
is	O
less	O
than	O
the	O
low	O
pruning	O
threshold	O
LOWPRTH	O
,	O
then	O
it	O
is	O
made	O
equal	O
to	O
LOWPRTH	O
in	O
step	O
S229	O
,	O
and	O
the	O
pruning	O
threshold	O
Th	O
is	O
set	O
,	O
in	O
step	O
S231	O
,	O
to	O
equal	O
MINSCORE	O
plus	O
the	O
adjusted	O
differential	O
value	O
PRUNING	O
.	O
Subsequently	O
,	O
in	O
step	O
S233	O
the	O
system	O
counts	O
the	O
number	O
of	O
active	O
states	O
that	O
will	O
be	O
processed	O
for	O
the	O
next	O
input	O
frame	O
.	O
This	O
is	O
achieved	O
by	O
comparing	O
the	O
cumulative	O
distances	O
stored	O
in	O
all	O
the	O
active	O
states	O
and	O
the	O
cumulative	O
distances	O
stored	O
in	O
all	O
the	O
nodes	O
with	O
the	O
newly	O
determined	O
pruning	O
threshold	O
Th	O
.	O

This	O
total	O
number	O
(	O
n	O
.	O
sub	O
.	O
sa	O
)	O
represents	O
the	O
total	O
number	O
of	O
active	O
states	O
and	O
nodes	O
that	O
will	O
be	O
processed	O
for	O
the	O
next	O
input	O
frame	O
.	O
If	O
this	O
total	O
number	O
n	O
.	O
sub	O
.	O
sa	O
is	O
less	O
than	O
the	O
emergency	O
state	O
threshold	O
,	O
EMGSTTH	O
,	O
then	O
the	O
pruning	O
threshold	O
has	O
been	O
set	O
too	O
low	O
and	O
the	O
processing	O
returns	O
to	O
step	O
S213	O
where	O
the	O
differential	O
value	O
PRUNING	O
is	O
increased	O
and	O
the	O
pruning	O
threshold	O
Th	O
is	O
reset	O
.	O
If	O
n	O
.	O
sub	O
.	O
sa	O
is	O
not	O
less	O
than	O
EMGSTTH	O
then	O
it	O
is	O
compared	O
with	O
LOWSTTH	O
in	O
step	O
S237	O
.	O
If	O
n	O
.	O
sub	O
.	O
sa	O
is	O
greater	O
than	O
LOWSTTH	O
then	O
this	O
implies	O
that	O
the	O
pruning	O
threshold	O
Th	O
set	O
in	O
step	O
S231	O
is	O
acceptable	O
and	O
the	O
processing	O
returns	O
to	O
step	O
S43	O
shown	O
in	O
FIG	O
.	O
21	O
.	O
If	O
on	O
the	O
other	O
hand	O
,	O
n	O
.	O
sub	O
.	O
sa	O
is	O
less	O
than	O
LOWSTTH	O
,	O
then	O
the	O
pruning	O
threshold	O
can	O
be	O
increased	O
,	O
and	O
so	O
a	O
second	O
adjustment	O
constant	O
dp2	O
is	O
added	O
to	O
the	O
differential	O
value	O
PRUNING	O
in	O
step	O
S239	O
,	O
prior	O
to	O
the	O
pruning	O
threshold	O
Th	O
being	O
reset	O
in	O
step	O
S219	O
.	O
In	O
this	O
embodiment	O
the	O
second	O
adjustment	O
constant	O
dp2	O
is	O
set	O
to	O
equal	O
half	O
the	O
adjustment	O
constant	O
dp1	O
.	O

As	O
those	O
skilled	O
in	O
the	O
art	O
will	O
realise	O
,	O
the	O
above	O
method	O
of	O
varying	O
the	O
pruning	O
threshold	O
is	O
not	O
computationally	O
expensive	O
,	O
yet	O
it	O
allows	O
the	O
pruning	O
threshold	O
to	O
be	O
adjusted	O
in	O
such	O
a	O
manner	O
that	O
the	O
number	O
of	O
active	O
states	O
that	O
are	O
processed	O
at	O
each	O
time	O
point	O
is	O
bounded	O
,	O
so	O
that	O
the	O
allocated	O
processing	O
time	O
and	O
memory	O
are	O
not	O
exceeded	O
.	O

After	O
all	O
the	O
frames	O
in	O
the	O
input	O
sequence	O
have	O
been	O
processed	O
using	O
the	O
sequence	O
of	O
processing	O
steps	O
illustrated	O
in	O
FIG	O
.	O
21	O
a	O
backtracking	O
routine	O
is	O
required	O
to	O
determine	O
the	O
exact	O
path	O
taken	O
by	O
the	O
optimum	O
path	O
determined	O
by	O
the	O
dynamic	O
programming	O
process	O
.	O
In	O
this	O
embodiment	O
the	O
backtracking	O
routine	O
traces	O
through	O
backpointers	O
which	O
indicate	O
the	O
sequence	O
of	O
words	O
through	O
which	O
each	O
path	O
propagates	O
.	O
The	O
details	O
of	O
the	O
way	O
in	O
which	O
the	O
backtracking	O
routine	O
is	O
performed	O
,	O
and	O
the	O
way	O
in	O
which	O
the	O
pointers	O
are	O
generated	O
are	O
well	O
known	O
to	O
those	O
skilled	O
in	O
the	O
art	O
of	O
speech	O
processing	O
,	O
and	O
will	O
not	O
be	O
described	O
further	O
.	O

Initialisation	O
Before	O
the	O
system	O
attempts	O
to	O
recognise	O
an	O
input	O
utterance	O
,	O
the	O
system	O
thresholds	O
and	O
variables	O
which	O
are	O
used	O
during	O
the	O
recognition	O
process	O
must	O
be	O
initialised	O
.	O
This	O
is	O
achieved	O
in	O
the	O
following	O
manner	O
.	O
Firstly	O
the	O
cumulative	O
distance	O
stored	O
in	O
the	O
start	O
node	O
N.	O
sub	O
.	O
0	O
is	O
set	O
to	O
zero	O
and	O
the	O
cumulative	O
distance	O
stored	O
in	O
all	O
the	O
other	O
nodes	O
is	O
set	O
to	O
equal	O
the	O
large	O
value	O
,	O
HUGE	O
.	O
Then	O
the	O
counter	O
which	O
counts	O
the	O
number	O
of	O
potentially	O
active	O
states	O
,	O
PACOUNT	O
,	O
associated	O
with	O
each	O
word	O
model	O
is	O
set	O
to	O
zero	O
;	O
the	O
last	O
active	O
pointer	O
associated	O
with	O
each	O
word	O
model	O
is	O
set	O
to	O
point	O
to	O
the	O
end	O
state	O
S.	O
sub	O
.	O
D	O
of	O
that	O
model	O
;	O
and	O
the	O
temporary	O
store	O
INSCORE	O
associated	O
with	O
each	O
word	O
model	O
is	O
set	O
to	O
the	O
large	O
value	O
,	O
HUGE	O
.	O
All	O
the	O
nodes	O
are	O
then	O
processed	O
so	O
that	O
the	O
minimum	O
of	O
the	O
cumulative	O
distances	O
of	O
all	O
the	O
nodes	O
connected	O
to	O
the	O
input	O
of	O
a	O
word	O
is	O
,	O
copied	O
into	O
the	O
temporary	O
store	O
INSCORE	O
associated	O
with	O
that	O
word	O
.	O
This	O
ensures	O
that	O
the	O
temporary	O
store	O
INSCORE	O
of	O
each	O
word	O
connected	O
to	O
the	O
start	O
node	O
N.	O
sub	O
.	O
0	O
is	O
set	O
to	O
zero	O
.	O
Finally	O
,	O
the	O
value	O
stored	O
in	O
INSCORE	O
of	O
each	O
word	O
is	O
used	O
to	O
activate	O
and	O
initialise	O
the	O
entry	O
states	O
of	O
each	O
word	O
model	O
.	O
The	O
processing	O
steps	O
to	O
initialise	O
the	O
entry	O
states	O
of	O
each	O
word	O
model	O
are	O
identical	O
to	O
the	O
processing	O
steps	O
used	O
to	O
update	O
the	O
entry	O
states	O
described	O
above	O
with	O
reference	O
to	O
FIG	O
.	O
30	O
.	O
The	O
pruning	O
threshold	O
and	O
the	O
differential	O
value	O
PRUNING	O
are	O
also	O
initialised	O
prior	O
to	O
the	O
processing	O
of	O
the	O
first	O
input	O
frame	O
.	O
In	O
particular	O
,	O
the	O
pruning	O
threshold	O
Th	O
is	O
set	O
to	O
the	O
large	O
value	O
,	O
HUGE	O
,	O
and	O
the	O
differential	O
value	O
PRUNING	O
is	O
set	O
to	O
equal	O
the	O
high	O
pruning	O
threshold	O
,	O
HIGHPRTH	O
.	O

Flexible	O
dynamic	O
programming	O
alignment	O
A	O
brief	O
description	O
is	O
given	O
above	O
with	O
reference	O
to	O
FIGS	O
.	O
13	O
to	O
16	O
,	O
of	O
the	O
way	O
in	O
which	O
the	O
word	O
models	O
are	O
generated	O
in	O
this	O
embodiment	O
.	O
In	O
particular	O
,	O
isolated	O
word	O
models	O
are	O
first	O
generated	O
for	O
the	O
words	O
contained	O
in	O
a	O
phrase	O
by	O
aligning	O
the	O
sequence	O
of	O
parameter	O
frames	O
corresponding	O
to	O
the	O
phrase	O
with	O
the	O
sequences	O
of	O
parameter	O
frames	O
corresponding	O
to	O
the	O
words	O
when	O
spoken	O
in	O
isolation	O
contained	O
within	O
the	O
phrase	O
,	O
using	O
a	O
flexible	O
dynamic	O
programming	O
alignment	O
process	O
.	O
This	O
flexible	O
alignment	O
process	O
will	O
now	O
be	O
described	O
in	O
more	O
detail	O
for	O
the	O
training	O
phrase	O
"	O
get	O
an	O
image	O
"	O
,	O
when	O
no	O
word	O
model	O
for	O
the	O
words	O
in	O
the	O
phrase	O
exists	O
yet	O
.	O

FIG	O
.	O
33	O
shows	O
the	O
sequence	O
of	O
parameter	O
frames	O
152	O
which	O
corresponds	O
to	O
the	O
utterance	O
of	O
the	O
phrase	O
"	O
get	O
an	O
image	O
"	O
and	O
the	O
sequences	O
of	O
parameter	O
frames	O
158	O
,	O
160	O
and	O
162	O
corresponding	O
to	O
the	O
utterances	O
of	O
the	O
isolated	O
words	O
"	O
get	O
"	O
,	O
"	O
an	O
"	O
and	O
"	O
image	O
"	O
respectively	O
.	O
Since	O
some	O
of	O
the	O
parameter	O
frames	O
in	O
the	O
sequence	O
of	O
parameter	O
frames	O
152	O
will	O
correspond	O
to	O
background	O
noise	O
or	O
silence	O
,	O
nodes	O
251	O
,	O
253	O
,	O
255	O
,	O
257	O
are	O
provided	O
between	O
the	O
isolated	O
words	O
and	O
at	O
the	O
beginning	O
of	O
the	O
first	O
word	O
and	O
at	O
the	O
end	O
of	O
the	O
last	O
word	O
contained	O
in	O
the	O
phrase	O
.	O
These	O
nodes	O
act	O
in	O
a	O
similar	O
manner	O
to	O
the	O
nodes	O
in	O
the	O
language	O
model	O
shown	O
in	O
FIG	O
.	O
17a	O
,	O
and	O
take	O
care	O
of	O
the	O
situation	O
where	O
a	O
current	O
parameter	O
frame	O
of	O
the	O
sequence	O
of	O
parameter	O
frames	O
152	O
being	O
processed	O
,	O
corresponds	O
to	O
silence	O
or	O
background	O
noise	O
.	O
This	O
possibility	O
is	O
illustrated	O
in	O
FIG	O
.	O
33	O
by	O
the	O
silence	O
frame	O
f	O
.	O
sup	O
.	O
sil	O
(	O
which	O
is	O
the	O
noise	O
model	O
23	O
shown	O
in	O
FIG	O
.	O
10	O
)	O
at	O
nodes	O
251	O
,	O
253	O
,	O
255	O
and	O
257	O
.	O

Although	O
some	O
of	O
the	O
frames	O
at	O
the	O
beginning	O
and	O
at	O
the	O
end	O
of	O
the	O
sequences	O
of	O
parameters	O
frames	O
158	O
,	O
160	O
and	O
162	O
will	O
correspond	O
to	O
silence	O
or	O
background	O
noise	O
,	O
the	O
parameter	O
frames	O
in	O
the	O
sequence	O
of	O
parameter	O
frames	O
152	O
which	O
correspond	O
to	O
silence	O
or	O
background	O
noise	O
should	O
match	O
better	O
with	O
the	O
silence	O
frame	O
f	O
.	O
sup	O
.	O
sil	O
stored	O
in	O
the	O
nodes	O
251	O
,	O
252	O
,	O
255	O
and	O
257	O
than	O
the	O
frames	O
corresponding	O
to	O
silence	O
in	O
sequences	O
158	O
,	O
160	O
and	O
162	O
.	O
This	O
is	O
because	O
the	O
silence	O
frame	O
f	O
.	O
sup	O
.	O
sil	O
represents	O
an	O
average	O
of	O
all	O
silence	O
frames	O
,	O
and	O
therefore	O
on	O
average	O
,	O
the	O
variation	O
between	O
the	O
frames	O
in	O
sequence	O
152	O
corresponding	O
to	O
silence	O
and	O
the	O
silence	O
frame	O
f	O
.	O
sup	O
.	O
sil	O
should	O
be	O
less	O
than	O
the	O
variation	O
between	O
the	O
frames	O
corresponding	O
to	O
silence	O
in	O
sequence	O
152	O
and	O
those	O
corresponding	O
to	O
silence	O
in	O
sequences	O
158	O
,	O
160	O
and	O
162	O
.	O

The	O
way	O
in	O
which	O
the	O
flexible	O
alignment	O
process	O
is	O
carried	O
out	O
is	O
similar	O
to	O
the	O
way	O
in	O
which	O
the	O
input	O
speech	O
is	O
aligned	O
with	O
the	O
stored	O
reference	O
models	O
,	O
as	O
described	O
above	O
with	O
reference	O
to	O
FIGS	O
.	O
18	O
to	O
32	O
.	O
In	O
particular	O
,	O
the	O
general	O
processing	O
steps	O
of	O
the	O
flexible	O
alignment	O
process	O
follow	O
those	O
shown	O
in	O
FIG	O
.	O
21	O
,	O
using	O
the	O
sequences	O
of	O
parameter	O
frames	O
158	O
,	O
160	O
and	O
162	O
as	O
reference	O
models	O
,	O
the	O
nodes	O
251	O
,	O
253	O
,	O
255	O
and	O
257	O
and	O
the	O
frames	O
of	O
sequence	O
152	O
as	O
input	O
frames	O
.	O
In	O
order	O
to	O
avoid	O
confusion	O
,	O
the	O
parameter	O
frames	O
of	O
the	O
sequences	O
158	O
,	O
160	O
and	O
162	O
representing	O
the	O
words	O
when	O
spoken	O
in	O
isolation	O
will	O
be	O
referred	O
to	O
as	O
states	O
.	O
Like	O
the	O
states	O
of	O
the	O
reference	O
models	O
used	O
during	O
recognition	O
of	O
an	O
unknown	O
input	O
utterance	O
,	O
these	O
states	O
have	O
an	O
associated	O
cumulative	O
distance	O
store	O
for	O
storing	O
the	O
cumulative	O
distance	O
of	O
the	O
dynamic	O
programming	O
path	O
which	O
ends	O
at	O
that	O
state	O
for	O
the	O
current	O
frame	O
of	O
the	O
sequence	O
152	O
being	O
processed	O
.	O

The	O
main	O
difference	O
between	O
the	O
flexible	O
alignment	O
process	O
and	O
the	O
alignment	O
process	O
used	O
during	O
recognition	O
of	O
an	O
unknown	O
input	O
utterance	O
is	O
that	O
with	O
the	O
flexible	O
alignment	O
:	O
(	O
i	O
)	O
each	O
dynamic	O
programming	O
path	O
can	O
enter	O
a	O
word	O
at	O
any	O
position	O
(	O
and	O
not	O
only	O
in	O
one	O
of	O
the	O
entry	O
states	O
)	O
;	O
and	O
(	O
ii	O
)	O
each	O
dynamic	O
programming	O
path	O
can	O
exit	O
a	O
word	O
from	O
any	O
state	O
therein	O
.	O

The	O
way	O
in	O
which	O
the	O
flexible	O
alignment	O
process	O
operates	O
for	O
the	O
above	O
example	O
will	O
now	O
be	O
explained	O
by	O
considering	O
the	O
first	O
few	O
parameter	O
frames	O
of	O
the	O
sequence	O
of	O
parameter	O
frames	O
152	O
.	O
Before	O
processing	O
the	O
first	O
frame	O
,	O
however	O
,	O
the	O
cumulative	O
distance	O
scores	O
associated	O
with	O
the	O
nodes	O
and	O
the	O
states	O
in	O
the	O
word	O
models	O
are	O
initialised	O
.	O
This	O
initialisation	O
procedure	O
is	O
similar	O
to	O
the	O
initialisation	O
procedure	O
performed	O
prior	O
to	O
attempting	O
to	O
recognise	O
an	O
unknown	O
input	O
utterance	O
,	O
as	O
described	O
above	O
.	O
In	O
particular	O
,	O
the	O
cumulative	O
distance	O
stored	O
in	O
the	O
start	O
node	O
,	O
ie	O
.	O
node	O
151	O
,	O
is	O
set	O
to	O
zero	O
and	O
the	O
cumulative	O
distance	O
stored	O
in	O
all	O
the	O
other	O
nodes	O
is	O
set	O
equal	O
the	O
large	O
value	O
,	O
HUGE	O
.	O
The	O
cumulative	O
distance	O
scores	O
of	O
the	O
states	O
in	O
words	O
W1	O
,	O
W2	O
and	O
W3	O
are	O
then	O
updated	O
using	O
the	O
cumulative	O
distance	O
scores	O
stored	O
in	O
the	O
nodes	O
connected	O
to	O
the	O
input	O
of	O
the	O
words	O
.	O
This	O
will	O
ensure	O
that	O
a	O
dynamic	O
programming	O
path	O
can	O
be	O
started	O
at	O
each	O
state	O
of	O
the	O
first	O
word	O
W1	O
and	O
at	O
the	O
first	O
node	O
151	O
when	O
the	O
frame	O
f.sub.0.sup.P1	O
is	O
processed	O
.	O

After	O
initialisation	O
,	O
the	O
first	O
frame	O
f.sub.0.sup.P1	O
is	O
processed	O
with	O
respect	O
to	O
each	O
word	O
W1	O
,	O
W2	O
and	O
W3	O
in	O
turn	O
.	O

However	O
,	O
since	O
the	O
cumulative	O
distance	O
associated	O
with	O
the	O
states	O
in	O
words	O
W2	O
and	O
W3	O
will	O
have	O
the	O
value	O
,	O
HUGE	O
,	O
the	O
first	O
frame	O
will	O
only	O
be	O
processed	O
with	O
respect	O
to	O
the	O
states	O
in	O
the	O
first	O
word	O
W1	O
.	O
When	O
processing	O
the	O
first	O
frame	O
with	O
respect	O
to	O
word	O
W1	O
,	O
the	O
distance	O
between	O
frame	O
f.sub.0.sup.P1	O
and	O
each	O
state	O
in	O
word	O
W1	O
is	O
stored	O
in	O
the	O
respective	O
cumulative	O
distance	O
store	O
associated	O
with	O
that	O
state	O
.	O
The	O
flexible	O
alignment	O
process	O
then	O
processes	O
the	O
nodes	O
251	O
,	O
253	O
,	O
255	O
and	O
257	O
in	O
turn	O
,	O
using	O
the	O
processing	O
steps	O
shown	O
in	O
FIG	O
.	O
28	O
.	O
Finally	O
,	O
the	O
processing	O
of	O
the	O
first	O
frame	O
f.sub.0.sup.P1	O
is	O
completed	O
by	O
updating	O
the	O
cumulative	O
distance	O
scores	O
of	O
the	O
states	O
in	O
words	O
W1	O
,	O
W2	O
and	O
W3	O
using	O
the	O
results	O
of	O
the	O
node	O
processing	O
.	O
The	O
updating	O
procedure	O
is	O
similar	O
to	O
that	O
shown	O
in	O
FIG	O
.	O
30	O
except	O
all	O
the	O
states	O
in	O
the	O
words	O
are	O
updated	O
and	O
not	O
just	O
the	O
entry	O
states	O
(	O
ie	O
.	O
the	O
first	O
three	O
states	O
)	O
.	O

Once	O
the	O
first	O
parameter	O
frame	O
of	O
sequence	O
152	O
has	O
been	O
processed	O
,	O
the	O
second	O
parameter	O
frame	O
f.sub.1.sup.P1	O
is	O
processed	O
in	O
order	O
to	O
propagate	O
the	O
dynamic	O
programming	O
paths	O
started	O
by	O
the	O
processing	O
of	O
the	O
first	O
parameter	O
frame	O
f.sub.0.sup.P1	O
.	O
As	O
with	O
the	O
dynamic	O
programming	O
method	O
used	O
during	O
recognition	O
of	O
an	O
input	O
utterance	O
,	O
the	O
states	O
in	O
each	O
word	O
W1	O
,	O
W2	O
and	O
W3	O
are	O
processed	O
in	O
reverse	O
sequential	O
order	O
,	O
using	O
in	O
this	O
embodiment	O
similar	O
propagation	O
constraints	O
as	O
those	O
described	O
with	O
reference	O
to	O
FIGS	O
.	O
19	O
and	O
20	O
.	O
The	O
only	O
difference	O
is	O
that	O
each	O
dynamic	O
programming	O
path	O
is	O
also	O
allowed	O
to	O
exit	O
a	O
current	O
word	O
from	O
any	O
of	O
its	O
states	O
,	O
and	O
not	O
just	O
from	O
the	O
last	O
three	O
states	O
as	O
is	O
the	O
case	O
during	O
recognition	O
of	O
an	O
unknown	O
input	O
utterance	O
.	O
Once	O
the	O
words	O
W1	O
,	O
W2	O
and	O
W3	O
have	O
been	O
processed	O
using	O
the	O
second	O
parameter	O
frame	O
f.sub.1.sup.P1	O
,	O
the	O
nodes	O
251	O
,	O
253	O
,	O
255	O
and	O
257	O
are	O
processed	O
in	O
order	O
to	O
update	O
the	O
dynamic	O
programming	O
path	O
which	O
is	O
currently	O
propagating	O
within	O
each	O
node	O
.	O
Once	O
this	O
had	O
been	O
done	O
,	O
each	O
of	O
the	O
words	O
W1	O
,	O
W2	O
and	O
W3	O
is	O
processed	O
again	O
in	O
order	O
to	O
update	O
the	O
dynamic	O
programming	O
paths	O
in	O
order	O
to	O
take	O
into	O
account	O
the	O
results	O
of	O
the	O
node	O
processing	O
.	O

The	O
remaining	O
parameter	O
frames	O
in	O
the	O
sequence	O
of	O
parameter	O
frames	O
152	O
are	O
then	O
processed	O
in	O
turn	O
in	O
a	O
similar	O
manner	O
.	O
Once	O
all	O
the	O
parameter	O
frames	O
in	O
the	O
sequence	O
152	O
have	O
been	O
processed	O
,	O
the	O
dynamic	O
programming	O
path	O
with	O
the	O
lowest	O
cumulative	O
score	O
is	O
determined	O
.	O
In	O
order	O
to	O
identify	O
the	O
beginning	O
and	O
end	O
frames	O
within	O
the	O
sequences	O
of	O
parameter	O
frames	O
158	O
,	O
160	O
and	O
162	O
which	O
bound	O
those	O
parameter	O
frames	O
which	O
represent	O
the	O
corresponding	O
words	O
(	O
and	O
not	O
silence	O
)	O
,	O
a	O
record	O
is	O
made	O
of	O
the	O
progress	O
of	O
each	O
dynamic	O
programming	O
path	O
during	O
the	O
flexible	O
alignment	O
process	O
.	O

In	O
particular	O
,	O
whenever	O
a	O
dynamic	O
programming	O
path	O
enters	O
a	O
word	O
,	O
either	O
from	O
a	O
preceding	O
word	O
or	O
from	O
the	O
node	O
in	O
front	O
of	O
the	O
word	O
,	O
the	O
state	O
into	O
which	O
that	O
dynamic	O
programming	O
path	O
enters	O
is	O
recorded	O
and	O
associated	O
with	O
that	O
path	O
.	O
Similarly	O
,	O
when	O
a	O
dynamic	O
programming	O
path	O
exits	O
a	O
word	O
then	O
the	O
state	O
from	O
which	O
it	O
exits	O
is	O
recorded	O
,	O
provided	O
the	O
score	O
associated	O
with	O
that	O
path	O
is	O
lower	O
than	O
the	O
score	O
associated	O
with	O
all	O
previous	O
dynamic	O
programming	O
paths	O
which	O
have	O
exited	O
from	O
that	O
word	O
.	O
Therefore	O
,	O
once	O
the	O
last	O
parameter	O
frame	O
in	O
the	O
sequence	O
of	O
parameter	O
frames	O
152	O
has	O
been	O
processed	O
and	O
the	O
dynamic	O
programming	O
path	O
having	O
the	O
best	O
score	O
is	O
identified	O
,	O
approximate	O
beginning	O
and	O
end	O
points	O
of	O
the	O
words	O
within	O
the	O
sequence	O
of	O
parameter	O
frames	O
158	O
,	O
160	O
and	O
162	O
can	O
be	O
identified	O
by	O
looking	O
at	O
the	O
record	O
associated	O
with	O
the	O
identified	O
dynamic	O
programming	O
path	O
.	O

As	O
those	O
skilled	O
in	O
the	O
art	O
will	O
appreciate	O
,	O
the	O
above	O
description	O
of	O
the	O
flexible	O
alignment	O
process	O
is	O
particular	O
to	O
the	O
situation	O
where	O
no	O
word	O
model	O
exists	O
for	O
each	O
word	O
contained	O
in	O
the	O
input	O
phrase	O
.	O
However	O
,	O
since	O
the	O
training	O
of	O
the	O
reference	O
models	O
is	O
designed	O
to	O
be	O
incremental	O
in	O
nature	O
,	O
ie	O
.	O
such	O
that	O
the	O
user	O
can	O
train	O
the	O
system	O
at	O
his	O
convenience	O
,	O
the	O
situation	O
will	O
sometimes	O
arise	O
that	O
a	O
word	O
model	O
for	O
a	O
word	O
in	O
an	O
input	O
phrase	O
will	O
already	O
exist	O
.	O
In	O
this	O
case	O
,	O
during	O
the	O
alignment	O
between	O
the	O
phrase	O
and	O
the	O
individual	O
words	O
,	O
a	O
hybrid	O
type	O
dynamic	O
programming	O
alignment	O
process	O
is	O
employed	O
which	O
uses	O
a	O
standard	O
type	O
dynamic	O
programming	O
alignment	O
process	O
for	O
words	O
that	O
already	O
have	O
a	O
word	O
model	O
,	O
and	O
a	O
flexible	O
dynamic	O
programming	O
alignment	O
process	O
for	O
the	O
other	O
words	O
which	O
do	O
not	O
yet	O
have	O
a	O
word	O
model	O
.	O

As	O
mentioned	O
above	O
with	O
reference	O
to	O
steps	O
S25	O
and	O
S26	O
in	O
FIG	O
.	O
14	O
,	O
once	O
the	O
isolated	O
word	O
models	O
for	O
the	O
unknown	O
words	O
in	O
a	O
phrase	O
have	O
been	O
determined	O
,	O
they	O
are	O
aligned	O
with	O
the	O
sequence	O
of	O
parameter	O
frames	O
of	O
the	O
input	O
phrases	O
containing	O
that	O
word	O
,	O
and	O
word	O
models	O
are	O
generated	O
from	O
the	O
result	O
.	O

Word	O
Model	O
Adaptation	O
Another	O
feature	O
of	O
the	O
speech	O
recognition	O
system	O
according	O
to	O
this	O
embodiment	O
is	O
that	O
the	O
word	O
models	O
19	O
,	O
the	O
noise	O
model	O
23	O
and	O
the	O
language	O
model	O
21	O
shown	O
in	O
FIG	O
.	O
10	O
can	O
be	O
updated	O
and	O
even	O
modified	O
by	O
the	O
build/update	O
module	O
91	O
.	O
Therefore	O
,	O
the	O
stored	O
word	O
models	O
19	O
can	O
be	O
modified	O
or	O
adapted	O
by	O
the	O
input	O
speech	O
of	O
a	O
different	O
user	O
.	O

FIG	O
.	O
34	O
is	O
a	O
flow	O
chart	O
which	O
illustrates	O
one	O
method	O
of	O
how	O
the	O
stored	O
word	O
models	O
19	O
can	O
be	O
adapted	O
to	O
a	O
different	O
user	O
.	O
In	O
particular	O
,	O
in	O
step	O
S251	O
the	O
the	O
new	O
user	O
inputs	O
a	O
known	O
word	O
or	O
phrase	O
into	O
the	O
system	O
via	O
the	O
microphone	O
7	O
and	O
the	O
keyboard	O
3	O
.	O
The	O
build/update	O
module	O
91	O
therefore	O
has	O
the	O
sequence	O
of	O
parameter	O
frames	O
corresponding	O
to	O
the	O
utterance	O
from	O
the	O
new	O
user	O
and	O
the	O
corresponding	O
text	O
entered	O
via	O
the	O
keyboard	O
3	O
.	O
The	O
system	O
then	O
aligns	O
,	O
in	O
step	O
S253	O
,	O
the	O
input	O
utterance	O
with	O
the	O
existing	O
word	O
models	O
of	O
the	O
words	O
which	O
are	O
known	O
to	O
be	O
in	O
the	O
utterance	O
using	O
a	O
dynamic	O
programming	O
routine	O
.	O
The	O
dynamic	O
programming	O
routine	O
aligns	O
the	O
parameter	O
frames	O
of	O
the	O
input	O
utterance	O
with	O
the	O
states	O
of	O
the	O
appropriate	O
word	O
models	O
.	O
The	O
system	O
then	O
directly	O
replaces	O
,	O
in	O
step	O
S255	O
,	O
the	O
states	O
of	O
the	O
word	O
models	O
with	O
the	O
sequence	O
of	O
parameter	O
frames	O
which	O
are	O
aligned	O
therewith	O
.	O
If	O
the	O
new	O
user	O
then	O
decides	O
,	O
in	O
step	O
S257	O
,	O
to	O
input	O
another	O
phrase	O
,	O
then	O
the	O
processing	O
returns	O
to	O
step	O
S251	O
,	O
and	O
the	O
same	O
routine	O
is	O
performed	O
again	O
for	O
the	O
next	O
input	O
utterance	O
.	O
If	O
the	O
new	O
user	O
decides	O
at	O
step	O
S257	O
that	O
no	O
more	O
phrases	O
are	O
to	O
be	O
adapted	O
then	O
the	O
processing	O
ends	O
.	O

FIG	O
.	O
35	O
is	O
a	O
flow	O
chart	O
which	O
illustrates	O
a	O
second	O
method	O
of	O
how	O
the	O
stored	O
word	O
models	O
19	O
can	O
be	O
adapted	O
for	O
a	O
different	O
user	O
.	O
In	O
particular	O
,	O
in	O
step	O
S261	O
the	O
new	O
user	O
inputs	O
a	O
known	O
word	O
or	O
phrase	O
into	O
the	O
system	O
,	O
a	O
number	O
of	O
times	O
via	O
the	O
microphone	O
and	O
once	O
via	O
the	O
keyboard	O
.	O
The	O
build/update	O
module	O
91	O
therefore	O
has	O
a	O
plurality	O
of	O
sequences	O
of	O
parameter	O
frames	O
,	O
each	O
corresponding	O
to	O
the	O
utterance	O
of	O
the	O
known	O
word	O
or	O
phrase	O
by	O
the	O
new	O
user	O
,	O
and	O
the	O
corresponding	O
text	O
entered	O
via	O
the	O
keyboard	O
3	O
.	O
The	O
system	O
then	O
aligns	O
,	O
in	O
step	O
S263	O
,	O
each	O
input	O
utterance	O
with	O
the	O
existing	O
word	O
models	O
of	O
the	O
words	O
which	O
are	O
known	O
to	O
be	O
in	O
the	O
utterance	O
,	O
using	O
a	O
dynamic	O
programming	O
routine	O
.	O

The	O
dynamic	O
programming	O
routine	O
aligns	O
the	O
parameter	O
frames	O
of	O
each	O
input	O
utterance	O
with	O
the	O
states	O
of	O
the	O
appropriate	O
word	O
models	O
.	O
The	O
system	O
then	O
replaces	O
,	O
in	O
step	O
S265	O
,	O
the	O
states	O
of	O
the	O
word	O
models	O
with	O
the	O
average	O
of	O
the	O
parameter	O
frames	O
which	O
are	O
aligned	O
therewith	O
.	O
If	O
a	O
state	O
of	O
a	O
word	O
model	O
has	O
not	O
been	O
aligned	O
with	O
any	O
of	O
the	O
parameter	O
frames	O
of	O
the	O
utterances	O
then	O
,	O
in	O
this	O
embodiment	O
,	O
the	O
system	O
interpolates	O
between	O
or	O
extrapolates	O
from	O
neighbouring	O
replaced	O
states	O
.	O
If	O
the	O
new	O
user	O
decides	O
,	O
in	O
step	O
S267	O
,	O
to	O
adapt	O
another	O
phrase	O
,	O
then	O
the	O
processing	O
returns	O
to	O
step	O
S261	O
,	O
and	O
the	O
same	O
routine	O
is	O
performed	O
again	O
for	O
the	O
next	O
phrase	O
.	O
If	O
the	O
new	O
user	O
decides	O
at	O
step	O
S267	O
that	O
no	O
more	O
phrases	O
are	O
to	O
be	O
input	O
then	O
the	O
processing	O
ends	O
.	O
Therefore	O
,	O
as	O
will	O
be	O
apparent	O
to	O
those	O
skilled	O
in	O
the	O
art	O
,	O
the	O
new	O
user	O
can	O
adapt	O
the	O
existing	O
word	O
models	O
incrementally	O
at	O
his	O
convenience	O
.	O
Additionally	O
,	O
the	O
new	O
user	O
can	O
also	O
add	O
new	O
words	O
or	O
phrases	O
to	O
the	O
system	O
in	O
the	O
manner	O
described	O
above	O
.	O

Alternative	O
Embodiments	O
A	O
number	O
of	O
modifications	O
can	O
be	O
made	O
to	O
the	O
above	O
speech	O
recognition	O
system	O
without	O
departing	O
from	O
the	O
inventive	O
concept	O
of	O
the	O
present	O
invention	O
.	O
A	O
number	O
of	O
these	O
modifications	O
will	O
now	O
be	O
described	O
.	O

Although	O
in	O
the	O
above	O
embodiment	O
,	O
the	O
whole	O
utterance	O
is	O
received	O
before	O
it	O
is	O
processed	O
,	O
the	O
system	O
can	O
run	O
incrementally	O
whereby	O
as	O
the	O
speech	O
is	O
received	O
it	O
is	O
processed	O
.	O
In	O
such	O
an	O
embodiment	O
,	O
an	O
input	O
buffer	O
would	O
still	O
be	O
required	O
,	O
but	O
it	O
would	O
only	O
need	O
to	O
be	O
able	O
to	O
store	O
incoming	O
speech	O
corresponding	O
to	O
one	O
frame	O
,	O
i	O
.	O
e	O
.	O
20	O
milliseconds	O
of	O
speech	O
.	O
As	O
those	O
skilled	O
in	O
the	O
art	O
will	O
realise	O
,	O
in	O
order	O
for	O
this	O
system	O
to	O
work	O
,	O
the	O
entire	O
processing	O
of	O
the	O
frame	O
of	O
input	O
speech	O
(	O
by	O
the	O
preprocessor	O
and	O
the	O
recognition	O
block	O
)	O
,	O
must	O
be	O
finished	O
before	O
the	O
next	O
frame	O
of	O
input	O
speech	O
is	O
ready	O
to	O
be	O
processed	O
.	O
With	O
the	O
above	O
frame	O
rate	O
and	O
frame	O
duration	O
,	O
this	O
means	O
that	O
the	O
time	O
taken	O
to	O
process	O
a	O
frame	O
of	O
input	O
speech	O
must	O
be	O
less	O
than	O
ten	O
milliseconds	O
.	O
This	O
can	O
be	O
achieved	O
with	O
current	O
state	O
of	O
the	O
art	O
processors	O
.	O
In	O
addition	O
,	O
the	O
power	O
parameter	O
in	O
each	O
frame	O
of	O
the	O
input	O
utterance	O
would	O
have	O
to	O
be	O
normalised	O
in	O
a	O
different	O
manner	O
.	O
One	O
way	O
of	O
normalising	O
the	O
power	O
in	O
such	O
an	O
embodiment	O
would	O
be	O
to	O
use	O
an	O
adaptive	O
normalisation	O
factor	O
which	O
would	O
be	O
adapted	O
based	O
upon	O
the	O
power	O
of	O
the	O
input	O
speech	O
over	O
,	O
for	O
example	O
,	O
the	O
previous	O
twenty	O
input	O
frames	O
.	O

In	O
the	O
first	O
embodiment	O
,	O
the	O
states	O
of	O
the	O
word	O
models	O
which	O
were	O
at	O
the	O
end	O
of	O
a	O
dynamic	O
programming	O
path	O
were	O
listed	O
in	O
an	O
active	O
list	O
associated	O
with	O
that	O
word	O
model	O
.	O
In	O
an	O
alternative	O
embodiment	O
a	O
single	O
global	O
active	O
list	O
could	O
be	O
provided	O
in	O
which	O
all	O
the	O
active	O
states	O
of	O
all	O
the	O
word	O
models	O
would	O
be	O
listed	O
.	O
In	O
such	O
an	O
alternative	O
embodiment	O
,	O
information	O
would	O
have	O
to	O
be	O
stored	O
associated	O
with	O
the	O
global	O
active	O
list	O
,	O
for	O
identifying	O
which	O
word	O
models	O
the	O
particular	O
active	O
states	O
belong	O
to	O
.	O

In	O
the	O
first	O
embodiment	O
,	O
the	O
states	O
of	O
the	O
word	O
models	O
correspond	O
in	O
time	O
duration	O
to	O
the	O
frames	O
of	O
the	O
input	O
speech	O
to	O
be	O
recognised	O
.	O
In	O
an	O
alternative	O
embodiment	O
,	O
each	O
state	O
of	O
a	O
word	O
model	O
could	O
be	O
equivalent	O
in	O
time	O
duration	O
to	O
,	O
for	O
example	O
,	O
three	O
consecutive	O
frames	O
of	O
the	O
input	O
speech	O
.	O
In	O
such	O
an	O
alternative	O
embodiment	O
,	O
the	O
input	O
frames	O
would	O
be	O
averaged	O
in	O
groups	O
of	O
three	O
and	O
then	O
aligned	O
with	O
the	O
states	O
of	O
the	O
word	O
models	O
.	O

In	O
yet	O
another	O
alternative	O
embodiment	O
,	O
the	O
word	O
models	O
could	O
be	O
statistical	O
models	O
,	O
for	O
example	O
Hidden	O
Markov	O
models	O
,	O
well	O
known	O
to	O
those	O
skilled	O
in	O
the	O
art	O
of	O
speech	O
recognition	O
.	O
In	O
such	O
an	O
embodiment	O
,	O
rather	O
than	O
determining	O
the	O
minimum	O
cumulative	O
distance	O
between	O
the	O
input	O
utterance	O
and	O
the	O
sequences	O
of	O
word	O
models	O
,	O
the	O
maximum	O
probability	O
that	O
the	O
input	O
sequence	O
was	O
generated	O
by	O
a	O
particular	O
sequence	O
of	O
Hidden	O
Markov	O
models	O
would	O
be	O
determined	O
.	O
In	O
such	O
an	O
embodiment	O
,	O
the	O
Hidden	O
Markov	O
models	O
would	O
be	O
generated	O
in	O
a	O
similar	O
manner	O
to	O
the	O
continuous	O
reference	O
models	O
generated	O
in	O
the	O
first	O
embodiment	O
.	O
In	O
particular	O
,	O
an	O
isolated	O
reference	O
model	O
for	O
a	O
word	O
would	O
be	O
generated	O
by	O
comparing	O
an	O
utterance	O
of	O
the	O
word	O
with	O
one	O
or	O
more	O
utterances	O
of	O
phrases	O
containing	O
the	O
word	O
.	O
The	O
isolated	O
reference	O
model	O
would	O
then	O
be	O
used	O
with	O
a	O
plurality	O
of	O
example	O
phrases	O
,	O
which	O
contain	O
the	O
word	O
,	O
to	O
generate	O
the	O
mean	O
parameter	O
frames	O
and	O
the	O
covariance	O
matrices	O
of	O
the	O
states	O
of	O
the	O
Hidden	O
Markov	O
Model	O
,	O
and	O
to	O
generate	O
the	O
transition	O
probabilities	O
between	O
the	O
states	O
.	O
The	O
way	O
in	O
which	O
this	O
would	O
be	O
achieved	O
,	O
would	O
be	O
apparent	O
to	O
those	O
skilled	O
in	O
the	O
art	O
of	O
speech	O
recognition	O
.	O

In	O
the	O
first	O
embodiment	O
,	O
the	O
reference	O
models	O
used	O
corresponded	O
to	O
whole	O
words	O
.	O
As	O
those	O
skilled	O
in	O
the	O
art	O
will	O
realise	O
,	O
this	O
is	O
not	O
essential	O
.	O
The	O
reference	O
models	O
could	O
correspond	O
to	O
parts	O
of	O
words	O
,	O
e.g.	O
syllables	O
,	O
to	O
a	O
plurality	O
of	O
words	O
or	O
even	O
to	O
individual	O
phonemes	O
.	O
However	O
,	O
the	O
disadvantage	O
of	O
using	O
reference	O
models	O
which	O
correspond	O
to	O
phonemes	O
is	O
that	O
the	O
system	O
becomes	O
language	O
dependent	O
.	O
Further	O
,	O
reference	O
models	O
which	O
are	O
equivalent	O
to	O
whole	O
words	O
are	O
preferred	O
to	O
those	O
equivalent	O
to	O
whole	O
phrases	O
because	O
there	O
is	O
a	O
potential	O
for	O
time	O
and	O
computational	O
savings	O
.	O
In	O
particular	O
,	O
by	O
modelling	O
the	O
words	O
within	O
phrases	O
and	O
by	O
using	O
a	O
language	O
model	O
,	O
it	O
is	O
possible	O
to	O
teach	O
the	O
system	O
many	O
different	O
phrases	O
using	O
only	O
a	O
handful	O
of	O
words	O
.	O
If	O
on	O
the	O
other	O
hand	O
,	O
the	O
reference	O
models	O
corresponded	O
to	O
the	O
whole	O
phrases	O
,	O
then	O
a	O
reference	O
model	O
would	O
be	O
required	O
for	O
each	O
of	O
the	O
different	O
phrases	O
to	O
be	O
learnt	O
by	O
the	O
system	O
.	O
In	O
addition	O
to	O
this	O
advantage	O
,	O
the	O
use	O
of	O
reference	O
models	O
which	O
correspond	O
to	O
words	O
also	O
increases	O
the	O
system	O
's	O
flexibility	O
to	O
gaps	O
between	O
the	O
words	O
in	O
the	O
phrase	O
.	O
This	O
is	O
possible	O
because	O
of	O
the	O
environment	O
model	O
which	O
can	O
appear	O
at	O
the	O
beginning	O
or	O
end	O
of	O
the	O
phrase	O
and	O
also	O
between	O
the	O
words	O
in	O
the	O
phrase	O
.	O

In	O
yet	O
another	O
alternative	O
embodiment	O
,	O
the	O
reference	O
models	O
could	O
be	O
compressed	O
if	O
consecutive	O
frames	O
of	O
the	O
model	O
are	O
similar	O
.	O
If	O
this	O
situation	O
arises	O
then	O
the	O
consecutive	O
similar	O
frames	O
would	O
be	O
replaced	O
by	O
a	O
single	O
frame	O
.	O
In	O
such	O
an	O
embodiment	O
,	O
the	O
constraint	O
placed	O
on	O
the	O
dynamic	O
programming	O
process	O
,	O
that	O
consecutive	O
frames	O
of	O
the	O
input	O
utterance	O
cannot	O
be	O
aligned	O
with	O
the	O
same	O
state	O
of	O
a	O
word	O
model	O
more	O
than	O
twice	O
,	O
would	O
have	O
to	O
be	O
removed	O
.	O

In	O
the	O
language	O
model	O
shown	O
in	O
FIG	O
.	O
17	O
,	O
if	O
a	O
word	O
can	O
be	O
followed	O
by	O
two	O
different	O
words	O
,	O
then	O
no	O
preference	O
is	O
placed	O
on	O
which	O
of	O
the	O
two	O
words	O
will	O
follow	O
that	O
word	O
.	O
In	O
an	O
alternative	O
embodiment	O
,	O
it	O
would	O
be	O
possible	O
to	O
weigh	O
some	O
sequences	O
of	O
words	O
more	O
favourably	O
than	O
others	O
.	O
For	O
example	O
,	O
for	O
the	O
phrases	O
illustrated	O
in	O
FIG	O
.	O
17a	O
,	O
it	O
may	O
be	O
known	O
that	O
the	O
phrase	O
"	O
make	O
it	O
more	O
.	O
.	O
.	O
"	O
(	O
followed	O
by	O
a	O
colour	O
)	O
is	O
more	O
common	O
than	O
the	O
phrases	O
"	O
make	O
it	O
smaller	O
"	O
,	O
or	O
"	O
make	O
it	O
larger	O
"	O
or	O
"	O
make	O
it	O
brighter	O
"	O
.	O
Therefore	O
,	O
the	O
transition	O
from	O
node	O
N.	O
sub	O
.	O
7	O
to	O
node	O
N.	O
sub	O
.	O
8	O
is	O
made	O
stronger	O
compared	O
to	O
the	O
transition	O
from	O
node	O
N.	O
sub	O
.	O
7	O
to	O
the	O
end	O
node	O
N.	O
sub	O
.	O
n	O
.	O
This	O
can	O
be	O
achieved	O
by	O
using	O
weighing	O
factors	O
which	O
weigh	O
the	O
cumulative	O
distances	O
being	O
propagated	O
from	O
node	O
N.	O
sub	O
.	O
7	O
to	O
the	O
input	O
of	O
words	O
"	O
more	O
"	O
,	O
"	O
smaller	O
"	O
,	O
"	O
larger	O
"	O
and	O
"	O
brighter	O
"	O
.	O

As	O
those	O
skilled	O
in	O
the	O
art	O
will	O
realise	O
,	O
the	O
language	O
model	O
used	O
to	O
define	O
the	O
allowed	O
sequences	O
of	O
words	O
does	O
not	O
have	O
to	O
be	O
a	O
Bigram	O
model	O
,	O
but	O
could	O
be	O
any	O
known	O
type	O
of	O
language	O
model	O
,	O
for	O
example	O
a	O
finite	O
state	O
grammar	O
model	O
.	O
If	O
the	O
type	O
of	O
language	O
model	O
used	O
is	O
changed	O
,	O
then	O
some	O
modifications	O
would	O
have	O
to	O
be	O
made	O
to	O
the	O
dynamic	O
programming	O
matching	O
process	O
described	O
above	O
,	O
but	O
such	O
modifications	O
would	O
be	O
apparent	O
to	O
those	O
skilled	O
in	O
the	O
art	O
of	O
speech	O
recognition	O
.	O
However	O
,	O
the	O
essential	O
features	O
of	O
the	O
matching	O
process	O
would	O
remain	O
unchanged	O
,	O
as	O
these	O
are	O
designed	O
to	O
be	O
suitable	O
for	O
use	O
in	O
any	O
pattern	O
matching	O
process	O
.	O

In	O
the	O
first	O
embodiment	O
,	O
at	O
least	O
two	O
phrases	O
which	O
contain	O
a	O
word	O
had	O
to	O
be	O
input	O
into	O
the	O
system	O
before	O
a	O
reference	O
model	O
for	O
that	O
word	O
could	O
be	O
generated	O
.	O
This	O
is	O
a	O
preferred	O
mode	O
of	O
operation	O
,	O
and	O
word	O
models	O
could	O
be	O
generated	O
for	O
each	O
word	O
from	O
only	O
a	O
single	O
example	O
phrase	O
containing	O
that	O
word	O
.	O
However	O
,	O
in	O
such	O
an	O
embodiment	O
,	O
the	O
reference	O
models	O
will	O
be	O
less	O
representative	O
of	O
that	O
word	O
when	O
used	O
in	O
any	O
given	O
phrase	O
.	O
Additionally	O
,	O
in	O
the	O
training	O
method	O
used	O
in	O
the	O
first	O
embodiment	O
,	O
once	O
a	O
reference	O
word	O
model	O
is	O
determined	O
for	O
a	O
word	O
the	O
word	O
model	O
is	O
not	O
changed	O
regardless	O
of	O
whether	O
subsequent	O
input	O
training	O
phrases	O
contain	O
that	O
word	O
.	O
In	O
an	O
alternative	O
embodiment	O
,	O
it	O
would	O
be	O
possible	O
to	O
update	O
existing	O
word	O
models	O
during	O
the	O
training	O
session	O
,	O
using	O
input	O
phrases	O
which	O
contain	O
examples	O
of	O
the	O
words	O
for	O
which	O
there	O
are	O
already	O
word	O
models	O
.	O

When	O
the	O
user	O
is	O
training	O
the	O
speech	O
recognition	O
system	O
,	O
and	O
inputs	O
a	O
phrase	O
containing	O
a	O
number	O
of	O
words	O
which	O
have	O
already	O
been	O
input	O
in	O
isolation	O
,	O
the	O
system	O
does	O
not	O
prompt	O
the	O
user	O
to	O
input	O
those	O
words	O
in	O
isolation	O
again	O
.	O
In	O
an	O
alternative	O
embodiment	O
,	O
the	O
system	O
could	O
prompt	O
the	O
user	O
for	O
those	O
words	O
again	O
,	O
and	O
could	O
perform	O
a	O
consistency	O
check	O
to	O
ensure	O
that	O
the	O
two	O
utterances	O
of	O
the	O
word	O
do	O
not	O
significantly	O
differ	O
.	O

In	O
the	O
first	O
embodiment	O
,	O
when	O
the	O
reference	O
models	O
are	O
being	O
trained	O
or	O
adapted	O
,	O
the	O
user	O
has	O
to	O
input	O
the	O
text	O
and	O
then	O
input	O
the	O
corresponding	O
voice	O
command	O
.	O
As	O
those	O
skilled	O
in	O
the	O
art	O
of	O
speech	O
recognition	O
will	O
realise	O
,	O
this	O
is	O
not	O
essential	O
.	O
Instead	O
of	O
entering	O
text	O
,	O
the	O
user	O
could	O
simply	O
press	O
a	O
corresponding	O
key/combination	O
of	O
keys	O
on	O
the	O
keyboard	O
,	O
facsimile	O
machine	O
,	O
photocopier	O
etc	O
.	O
For	O
example	O
,	O
when	O
training	O
the	O
system	O
for	O
use	O
in	O
a	O
photocopier	O
,	O
when	O
entering	O
the	O
voice	O
command	O
"	O
copy	O
"	O
the	O
desired	O
machine	O
response	O
can	O
be	O
input	O
by	O
the	O
user	O
simply	O
pressing	O
the	O
copy	O
button	O
.	O

In	O
addition	O
,	O
it	O
will	O
be	O
apparent	O
to	O
those	O
skilled	O
in	O
the	O
art	O
of	O
pattern	O
matching	O
,	O
that	O
the	O
method	O
of	O
implementing	O
the	O
dynamic	O
programming	O
matching	O
process	O
and	O
the	O
reference	O
model	O
generation	O
and	O
adaptation	O
processes	O
described	O
above	O
,	O
could	O
also	O
be	O
used	O
for	O
matching	O
other	O
types	O
of	O
patterns	O
.	O
For	O
example	O
,	O
it	O
is	O
envisaged	O
that	O
the	O
above	O
described	O
pattern	O
matching	O
process	O
could	O
be	O
used	O
in	O
handwriting	O
recognition	O
or	O
other	O
pattern	O
matching	O
techniques	O
.	O

Although	O
a	O
continuous	O
word	O
speech	O
recognition	O
system	O
is	O
described	O
in	O
the	O
first	O
embodiment	O
described	O
above	O
,	O
it	O
will	O
be	O
apparent	O
to	O
those	O
skilled	O
in	O
the	O
art	O
that	O
many	O
features	O
of	O
the	O
system	O
described	O
could	O
equally	O
apply	O
to	O
other	O
kinds	O
of	O
speech	O
recognition	O
systems	O
.	O
For	O
example	O
,	O
the	O
way	O
of	O
determining	O
the	O
isolated	O
word	O
models	O
,	O
and	O
the	O
isolated	O
word	O
models	O
referred	O
to	O
above	O
,	O
could	O
be	O
used	O
in	O
an	O
isolated	O
word	O
speech	O
recognition	O
system	O
.	O
Similarly	O
,	O
many	O
features	O
of	O
the	O
way	O
in	O
which	O
the	O
dynamic	O
programming	O
process	O
is	O
carried	O
out	O
,	O
and	O
the	O
way	O
in	O
which	O
the	O
pruning	O
threshold	O
is	O
adjusted	O
,	O
could	O
be	O
used	O
in	O
any	O
speech	O
recognition	O
system	O
where	O
the	O
reference	O
models	O
correspond	O
to	O
any	O
part	O
of	O
speech	O
,	O
e.g.	O
phonemes	O
,	O
syllables	O
,	O
etc	O
.	O

The	O
speech	O
recognition	O
system	O
described	O
in	O
the	O
first	O
embodiment	O
can	O
be	O
used	O
in	O
conjunction	O
with	O
many	O
different	O
software	O
applications	O
,	O
for	O
example	O
,	O
a	O
spreadsheet	O
package	O
,	O
a	O
graphics	O
package	O
,	O
a	O
word	O
processor	O
package	O
etc	O
.	O
If	O
the	O
speech	O
recognition	O
system	O
is	O
to	O
be	O
used	O
with	O
a	O
plurality	O
of	O
such	O
software	O
applications	O
,	O
then	O
it	O
might	O
be	O
advantageous	O
to	O
have	O
separate	O
word	O
and	O
language	O
models	O
for	O
each	O
application	O
,	O
especially	O
if	O
the	O
phrases	O
used	O
in	O
each	O
application	O
are	O
different	O
.	O
The	O
reason	O
for	O
this	O
is	O
that	O
as	O
the	O
number	O
of	O
word	O
models	O
increases	O
and	O
as	O
the	O
language	O
model	O
increases	O
in	O
size	O
,	O
the	O
time	O
taken	O
for	O
the	O
system	O
to	O
recognise	O
an	O
input	O
utterance	O
increases	O
.	O
Therefore	O
,	O
by	O
having	O
separate	O
word	O
and	O
language	O
models	O
for	O
each	O
application	O
,	O
the	O
speed	O
of	O
the	O
speech	O
recognition	O
system	O
can	O
be	O
maintained	O
.	O
Additionally	O
,	O
several	O
word	O
and	O
language	O
models	O
could	O
be	O
used	O
for	O
each	O
application	O
.	O

Additionally	O
,	O
as	O
those	O
skilled	O
in	O
the	O
art	O
will	O
appreciate	O
,	O
the	O
above	O
speech	O
recognition	O
system	O
can	O
also	O
be	O
used	O
in	O
many	O
different	O
types	O
of	O
hardware	O
.	O
For	O
example	O
,	O
apart	O
from	O
the	O
obvious	O
use	O
in	O
a	O
personal	O
computer	O
or	O
the	O
like	O
,	O
the	O
speech	O
recognition	O
system	O
could	O
be	O
used	O
as	O
a	O
user	O
interface	O
to	O
a	O
facsimile	O
machine	O
,	O
telephone	O
,	O
printer	O
,	O
photocopier	O
or	O
any	O
machine	O
having	O
a	O
human/machine	O
interface	O
.	O

The	O
present	O
invention	O
is	O
not	O
intended	O
to	O
be	O
limited	O
by	O
the	O
exemplary	O
embodiments	O
described	O
above	O
,	O
and	O
various	O
other	O
modifications	O
and	O
embodiments	O
will	O
be	O
apparent	O
to	O
those	O
skilled	O
in	O
the	O
art	O
.	O

1	O
.	O
A	O
pattern	O
matching	O
method	O
for	O
matching	O
a	O
time	O
varying	O
input	O
signal	O
with	O
a	O
number	O
of	O
sequences	O
of	O
reference	O
patterns	O
,	O
each	O
sequence	O
being	O
representative	O
of	O
a	O
time	O
varying	O
reference	O
signal	O
,	O
the	O
method	O
comprising	O
the	O
steps	O
of	O
:	O
receiving	O
the	O
time	O
varying	O
input	O
signal	O
;	O
obtaining	O
a	O
sequence	O
of	O
input	O
patterns	O
representative	O
of	O
the	O
input	O
signal	O
,	O
each	O
pattern	O
representing	O
a	O
corresponding	O
time	O
portion	O
of	O
the	O
input	O
signal	O
;	O
matching	O
the	O
input	O
signal	O
with	O
each	O
reference	O
signal	O
using	O
a	O
dynamic	O
programming	O
matching	O
process	O
which	O
processes	O
each	O
pattern	O
of	O
said	O
input	O
signal	O
in	O
sequence	O
and	O
which	O
propagates	O
a	O
plurality	O
of	O
dynamic	O
programming	O
paths	O
using	O
predetermined	O
dynamic	O
programming	O
constraints	O
,	O
each	O
path	O
representing	O
a	O
possible	O
matching	O
between	O
a	O
sequence	O
of	O
reference	O
patterns	O
and	O
possible	O
matching	O
between	O
a	O
sequence	O
of	O
reference	O
patterns	O
and	O
a	O
sequence	O
of	O
patterns	O
of	O
the	O
input	O
signal	O
ending	O
at	O
a	O
current	O
pattern	O
being	O
processed	O
,	O
and	O
each	O
path	O
having	O
an	O
associated	O
cumulative	O
value	O
representative	O
of	O
a	O
score	O
for	O
the	O
possible	O
matching	O
;	O
controlling	O
said	O
matching	O
step	O
by	O
comparing	O
the	O
cumulative	O
value	O
associated	O
with	O
each	O
path	O
with	O
a	O
pruning	O
value	O
thereby	O
to	O
restrict	O
the	O
number	O
of	O
dynamic	O
programming	O
paths	O
that	O
were	O
propagated	O
from	O
a	O
preceding	O
time	O
point	O
,	O
when	O
the	O
preceding	O
input	O
pattern	O
was	O
being	O
processed	O
in	O
said	O
matching	O
step	O
,	O
from	O
being	O
propagated	O
further	O
during	O
the	O
processing	O
of	O
the	O
current	O
input	O
pattern	O
at	O
a	O
current	O
time	O
point	O
by	O
said	O
matching	O
step	O
;	O
determining	O
at	O
the	O
current	O
time	O
point	O
,	O
a	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
that	O
will	O
be	O
propagating	O
at	O
the	O
succeeding	O
time	O
point	O
,	O
prior	O
to	O
restriction	O
by	O
said	O
controlling	O
step	O
,	O
when	O
the	O
succeeding	O
input	O
pattern	O
will	O
be	O
processed	O
by	O
said	O
matching	O
step	O
;	O
and	O
altering	O
the	O
pruning	O
value	O
to	O
be	O
used	O
at	O
said	O
succeeding	O
time	O
point	O
in	O
dependence	O
upon	O
the	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
determined	O
by	O
said	O
determining	O
step	O
;	O
wherein	O
said	O
matching	O
step	O
comprising	O
the	O
steps	O
of	O
:	O
using	O
said	O
dynamic	O
programming	O
constraints	O
to	O
propagate	O
each	O
dynamic	O
programming	O
path	O
ending	O
at	O
the	O
current	O
input	O
pattern	O
to	O
the	O
succeeding	O
input	O
pattern	O
;	O
and	O
maintaining	O
the	O
dynamic	O
programming	O
path	O
having	O
the	O
best	O
cumulative	O
value	O
and	O
discarding	O
the	O
rest	O
,	O
in	O
the	O
case	O
where	O
a	O
plurality	O
of	O
dynamic	O
programming	O
paths	O
meet	O
at	O
the	O
succeeding	O
input	O
pattern	O
;	O
and	O
wherein	O
said	O
determining	O
step	O
comprises	O
the	O
step	O
of	O
counting	O
the	O
number	O
of	O
dynamic	O
programming	O
paths	O
which	O
have	O
been	O
propagated	O
to	O
the	O
succeeding	O
input	O
pattern	O
but	O
which	O
have	O
not	O
been	O
discarded	O
.	O

2	O
.	O
A	O
method	O
according	O
to	O
claim	O
1	O
,	O
wherein	O
said	O
input	O
signal	O
is	O
a	O
speech	O
signal	O
,	O
and	O
wherein	O
each	O
pattern	O
comprises	O
a	O
number	O
of	O
parameters	O
representative	O
of	O
the	O
acoustic	O
properties	O
of	O
the	O
input	O
speech	O
signal	O
during	O
the	O
corresponding	O
time	O
portion	O
.	O

3	O
.	O
A	O
method	O
according	O
to	O
claim	O
1	O
,	O
wherein	O
said	O
altering	O
step	O
is	O
arranged	O
to	O
alter	O
the	O
pruning	O
value	O
for	O
the	O
succeeding	O
time	O
point	O
to	O
equal	O
a	O
sum	O
of	O
a	O
minimum	O
cumulative	O
value	O
of	O
the	O
cumulative	O
values	O
determined	O
in	O
said	O
matching	O
step	O
at	O
the	O
current	O
time	O
point	O
and	O
a	O
variable	O
which	O
is	O
varied	O
in	O
dependence	O
upon	O
said	O
number	O
of	O
possible	O
matchings	O
determined	O
in	O
said	O
determining	O
step	O
.	O

4	O
.	O
A	O
method	O
according	O
to	O
claim	O
3	O
,	O
wherein	O
the	O
variable	O
is	O
increased	O
by	O
a	O
first	O
adjustment	O
constant	O
if	O
said	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
determined	O
in	O
said	O
determining	O
step	O
is	O
less	O
than	O
a	O
first	O
matching	O
threshold	O
.	O

5	O
.	O
A	O
method	O
according	O
to	O
claim	O
4	O
,	O
wherein	O
if	O
said	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
determined	O
in	O
said	O
determining	O
step	O
is	O
greater	O
than	O
said	O
first	O
matching	O
threshold	O
,	O
then	O
the	O
variable	O
is	O
varied	O
in	O
dependence	O
upon	O
the	O
number	O
of	O
cumulative	O
values	O
determined	O
in	O
said	O
matching	O
step	O
at	O
the	O
current	O
time	O
point	O
.	O

6	O
.	O
A	O
method	O
according	O
to	O
claim	O
5	O
,	O
wherein	O
the	O
variable	O
is	O
decreased	O
by	O
said	O
first	O
adjustment	O
constant	O
if	O
said	O
number	O
of	O
cumulative	O
values	O
determined	O
in	O
said	O
matching	O
step	O
at	O
the	O
current	O
time	O
point	O
,	O
is	O
greater	O
than	O
said	O
first	O
matching	O
threshold	O
.	O

7	O
.	O
A	O
method	O
according	O
to	O
claim	O
5	O
,	O
wherein	O
if	O
said	O
number	O
of	O
cumulative	O
values	O
determined	O
in	O
said	O
matching	O
step	O
for	O
the	O
current	O
time	O
point	O
exceeds	O
said	O
first	O
matching	O
threshold	O
,	O
then	O
said	O
altering	O
step	O
checks	O
whether	O
the	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
which	O
have	O
a	O
cumulative	O
value	O
less	O
than	O
a	O
determined	O
pruning	O
value	O
exceeds	O
an	O
emergency	O
threshold	O
,	O
and	O
wherein	O
said	O
altering	O
step	O
redetermined	O
the	O
pruning	O
value	O
for	O
the	O
succeeding	O
time	O
point	O
using	O
an	O
increased	O
value	O
of	O
the	O
variable	O
if	O
said	O
number	O
is	O
less	O
than	O
said	O
emergency	O
threshold	O
.	O

8	O
.	O
A	O
method	O
according	O
to	O
claim	O
7	O
,	O
wherein	O
the	O
variable	O
is	O
increased	O
by	O
a	O
second	O
smaller	O
adjustment	O
constant	O
,	O
if	O
said	O
number	O
determined	O
in	O
said	O
altering	O
step	O
is	O
greater	O
than	O
said	O
emergency	O
threshold	O
but	O
less	O
than	O
a	O
second	O
matching	O
threshold	O
,	O
which	O
is	O
less	O
than	O
the	O
first	O
matching	O
threshold	O
but	O
greater	O
than	O
said	O
emergency	O
threshold	O
.	O

9	O
.	O
A	O
method	O
according	O
to	O
claim	O
8	O
,	O
wherein	O
said	O
second	O
adjustment	O
constant	O
is	O
half	O
the	O
value	O
of	O
said	O
first	O
adjustment	O
constant	O
.	O

10	O
.	O
A	O
method	O
according	O
to	O
claim	O
3	O
,	O
wherein	O
said	O
altering	O
step	O
adjusts	O
the	O
value	O
of	O
the	O
variable	O
to	O
be	O
equal	O
to	O
a	O
set	O
maximum	O
value	O
if	O
the	O
variable	O
has	O
been	O
adjusted	O
to	O
be	O
greater	O
than	O
that	O
maximum	O
.	O

11	O
.	O
A	O
method	O
according	O
to	O
claim	O
3	O
,	O
wherein	O
said	O
altering	O
step	O
adjusts	O
the	O
value	O
of	O
the	O
variable	O
to	O
be	O
equal	O
to	O
a	O
set	O
minimum	O
value	O
if	O
the	O
variable	O
is	O
adjusted	O
to	O
be	O
less	O
than	O
that	O
minimum	O
value	O
.	O

12	O
.	O
A	O
method	O
according	O
to	O
claim	O
1	O
,	O
wherein	O
said	O
matching	O
step	O
further	O
comprises	O
the	O
step	O
of	O
defining	O
as	O
active	O
patterns	O
the	O
reference	O
patterns	O
of	O
a	O
current	O
reference	O
signal	O
which	O
are	O
at	O
the	O
end	O
of	O
a	O
dynamic	O
programming	O
path	O
for	O
a	O
current	O
input	O
pattern	O
being	O
processed	O
and	O
listing	O
the	O
active	O
patterns	O
for	O
the	O
current	O
input	O
pattern	O
in	O
a	O
current	O
active	O
list	O
.	O

13	O
.	O
A	O
method	O
according	O
to	O
claim	O
12	O
,	O
wherein	O
the	O
cumulative	O
value	O
associated	O
with	O
each	O
dynamic	O
programming	O
path	O
is	O
stored	O
in	O
a	O
store	O
associated	O
with	O
the	O
reference	O
pattern	O
defined	O
as	O
the	O
active	O
pattern	O
at	O
the	O
end	O
of	O
the	O
path	O
associated	O
with	O
the	O
cumulative	O
value	O
.	O

14	O
.	O
A	O
method	O
according	O
to	O
claim	O
12	O
,	O
wherein	O
said	O
matching	O
step	O
propagates	O
the	O
dynamic	O
programming	O
paths	O
by	O
processing	O
each	O
active	O
pattern	O
in	O
turn	O
and	O
listing	O
a	O
reference	O
pattern	O
of	O
the	O
current	O
reference	O
signal	O
for	O
which	O
it	O
is	O
determined	O
that	O
the	O
reference	O
pattern	O
of	O
the	O
current	O
reference	O
signal	O
may	O
be	O
located	O
at	O
the	O
end	O
of	O
a	O
dynamic	O
programming	O
path	O
for	O
the	O
succeeding	O
input	O
pattern	O
in	O
a	O
new	O
active	O
list	O
.	O

15	O
.	O
A	O
method	O
according	O
to	O
claim	O
14	O
,	O
wherein	O
said	O
counting	O
step	O
increments	O
a	O
count	O
each	O
time	O
a	O
reference	O
pattern	O
is	O
added	O
to	O
the	O
new	O
active	O
list	O
.	O

16	O
.	O
A	O
method	O
according	O
to	O
claim	O
15	O
,	O
wherein	O
once	O
all	O
the	O
active	O
patterns	O
have	O
been	O
processed	O
for	O
the	O
current	O
input	O
pattern	O
,	O
said	O
count	O
represents	O
the	O
number	O
of	O
dynamic	O
programming	O
paths	O
which	O
have	O
been	O
propagated	O
to	O
the	O
succeeding	O
time	O
point	O
but	O
which	O
have	O
not	O
been	O
discarded	O
.	O

17	O
.	O
A	O
method	O
according	O
to	O
claim	O
1	O
,	O
wherein	O
said	O
matching	O
step	O
is	O
operable	O
to	O
perform	O
said	O
matching	O
while	O
said	O
receiving	O
step	O
is	O
still	O
receiving	O
said	O
input	O
signal	O
.	O

18	O
.	O
A	O
method	O
according	O
to	O
claim	O
1	O
,	O
wherein	O
said	O
matching	O
step	O
updates	O
the	O
cumulative	O
value	O
associated	O
with	O
each	O
path	O
which	O
is	O
not	O
restricted	O
by	O
said	O
controlling	O
step	O
using	O
the	O
current	O
input	O
pattern	O
,	O
prior	O
to	O
propagating	O
those	O
paths	O
to	O
the	O
succeeding	O
input	O
pattern	O
.	O

19	O
.	O
A	O
pattern	O
matching	O
apparatus	O
for	O
matching	O
a	O
time	O
varying	O
input	O
signal	O
with	O
a	O
number	O
of	O
sequences	O
of	O
reference	O
patterns	O
,	O
each	O
sequence	O
being	O
representative	O
of	O
a	O
time	O
varying	O
reference	O
signal	O
,	O
the	O
apparatus	O
comprising	O
:	O
means	O
for	O
receiving	O
the	O
time	O
varying	O
input	O
signal	O
;	O
means	O
for	O
obtaining	O
a	O
sequence	O
of	O
input	O
patterns	O
representative	O
of	O
the	O
input	O
signal	O
,	O
each	O
pattern	O
representing	O
a	O
corresponding	O
time	O
portion	O
of	O
the	O
input	O
signal	O
;	O
means	O
for	O
matching	O
the	O
input	O
signal	O
with	O
each	O
reference	O
signal	O
using	O
a	O
dynamic	O
programming	O
matching	O
process	O
which	O
processes	O
each	O
pattern	O
of	O
said	O
input	O
signal	O
in	O
sequence	O
and	O
which	O
propagates	O
a	O
plurality	O
of	O
dynamic	O
programming	O
paths	O
using	O
predetermined	O
dynamic	O
programming	O
constraints	O
,	O
each	O
path	O
representing	O
a	O
possible	O
matching	O
between	O
a	O
sequence	O
of	O
reference	O
patterns	O
and	O
a	O
sequence	O
of	O
patterns	O
of	O
the	O
input	O
signal	O
ending	O
at	O
a	O
current	O
pattern	O
being	O
processed	O
,	O
and	O
each	O
path	O
having	O
an	O
associated	O
cumulative	O
value	O
representative	O
of	O
a	O
score	O
for	O
the	O
possible	O
matching	O
;	O
means	O
for	O
controlling	O
said	O
matching	O
means	O
by	O
comparing	O
the	O
cumulative	O
value	O
associated	O
with	O
each	O
path	O
with	O
a	O
pruning	O
value	O
thereby	O
to	O
restrict	O
the	O
number	O
of	O
dynamic	O
programming	O
paths	O
that	O
were	O
propagated	O
from	O
a	O
preceding	O
time	O
point	O
,	O
when	O
the	O
preceding	O
input	O
pattern	O
was	O
being	O
processed	O
by	O
said	O
matching	O
means	O
,	O
from	O
being	O
propagated	O
further	O
during	O
the	O
processing	O
of	O
the	O
current	O
input	O
pattern	O
at	O
a	O
current	O
time	O
point	O
by	O
said	O
matching	O
means	O
;	O
means	O
for	O
determining	O
at	O
the	O
current	O
time	O
point	O
,	O
a	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
that	O
will	O
be	O
propagating	O
at	O
a	O
succeeding	O
time	O
point	O
,	O
prior	O
to	O
restriction	O
by	O
said	O
controlling	O
step	O
,	O
when	O
the	O
succeeding	O
input	O
pattern	O
will	O
be	O
processed	O
by	O
said	O
matching	O
means	O
;	O
and	O
means	O
for	O
altering	O
the	O
pruning	O
value	O
to	O
be	O
used	O
at	O
said	O
succeeding	O
time	O
point	O
in	O
dependence	O
upon	O
the	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
determined	O
by	O
said	O
determining	O
means	O
;	O
wherein	O
said	O
matching	O
means	O
comprises	O
:	O
means	O
for	O
using	O
said	O
dynamic	O
programming	O
constraints	O
to	O
propagate	O
each	O
dynamic	O
programming	O
path	O
ending	O
at	O
the	O
current	O
input	O
pattern	O
to	O
the	O
succeeding	O
input	O
pattern	O
;	O
and	O
means	O
for	O
maintaining	O
the	O
dynamic	O
programming	O
path	O
having	O
the	O
best	O
cumulative	O
value	O
and	O
discarding	O
the	O
rest	O
,	O
in	O
the	O
case	O
where	O
a	O
plurality	O
of	O
dynamic	O
programming	O
paths	O
meet	O
at	O
the	O
succeeding	O
input	O
pattern	O
;	O
and	O
wherein	O
said	O
determining	O
means	O
comprises	O
means	O
for	O
counting	O
the	O
number	O
of	O
dynamic	O
programming	O
paths	O
which	O
have	O
been	O
propagated	O
to	O
the	O
succeeding	O
input	O
pattern	O
but	O
which	O
have	O
not	O
been	O
discarded	O
.	O

20	O
.	O
An	O
apparatus	O
according	O
to	O
claim	O
19	O
,	O
wherein	O
said	O
receiving	O
means	O
is	O
operable	O
for	O
receiving	O
an	O
input	O
speed	O
signal	O
,	O
and	O
wherein	O
each	O
pattern	O
comprises	O
a	O
number	O
of	O
parameters	O
representative	O
of	O
the	O
acoustic	O
properties	O
of	O
the	O
input	O
speech	O
signal	O
during	O
the	O
corresponding	O
time	O
portion	O
.	O

21	O
.	O
An	O
apparatus	O
according	O
to	O
claim	O
19	O
,	O
wherein	O
said	O
altering	O
means	O
is	O
adapted	O
to	O
alter	O
the	O
pruning	O
value	O
for	O
succeeding	O
time	O
point	O
to	O
equal	O
a	O
sum	O
of	O
a	O
minimum	O
cumulative	O
value	O
of	O
the	O
cumulative	O
values	O
determined	O
by	O
said	O
matching	O
means	O
at	O
the	O
current	O
time	O
point	O
and	O
a	O
variable	O
which	O
is	O
varied	O
in	O
dependence	O
upon	O
said	O
number	O
of	O
possible	O
matchings	O
determined	O
by	O
said	O
determining	O
means	O
.	O

22	O
.	O
An	O
apparatus	O
according	O
to	O
claim	O
21	O
,	O
wherein	O
said	O
altering	O
means	O
is	O
adapted	O
to	O
increase	O
the	O
variable	O
by	O
a	O
first	O
adjustment	O
constant	O
if	O
said	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
determined	O
by	O
said	O
determining	O
means	O
is	O
less	O
than	O
a	O
first	O
matching	O
threshold	O
.	O

23	O
.	O
An	O
apparatus	O
according	O
to	O
claim	O
22	O
,	O
wherein	O
if	O
said	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
determined	O
by	O
said	O
determining	O
means	O
is	O
greater	O
than	O
said	O
first	O
matching	O
threshold	O
,	O
then	O
said	O
altering	O
means	O
is	O
adapted	O
to	O
vary	O
the	O
variable	O
in	O
dependence	O
upon	O
the	O
number	O
of	O
cumulative	O
values	O
determined	O
by	O
said	O
matching	O
means	O
at	O
the	O
current	O
time	O
point	O
.	O

24	O
.	O
An	O
apparatus	O
according	O
to	O
claim	O
23	O
,	O
wherein	O
said	O
altering	O
means	O
is	O
adapted	O
to	O
decrease	O
the	O
variable	O
by	O
said	O
first	O
adjustment	O
constant	O
if	O
said	O
number	O
of	O
cumulative	O
values	O
determined	O
by	O
said	O
matching	O
means	O
at	O
the	O
current	O
time	O
point	O
,	O
is	O
greater	O
than	O
said	O
first	O
matching	O
threshold	O
.	O

25	O
.	O
An	O
apparatus	O
according	O
to	O
claim	O
23	O
,	O
wherein	O
if	O
said	O
number	O
of	O
cumulative	O
values	O
determined	O
by	O
said	O
matching	O
means	O
for	O
the	O
current	O
time	O
point	O
exceeds	O
said	O
first	O
matching	O
threshold	O
,	O
then	O
said	O
altering	O
means	O
is	O
adapted	O
to	O
check	O
whether	O
the	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
which	O
have	O
a	O
cumulative	O
value	O
less	O
than	O
a	O
determined	O
pruning	O
value	O
exceeds	O
an	O
emergency	O
threshold	O
,	O
and	O
wherein	O
said	O
altering	O
step	O
is	O
adapted	O
to	O
redetermine	O
the	O
pruning	O
value	O
for	O
the	O
succeeding	O
time	O
point	O
using	O
an	O
increased	O
value	O
of	O
the	O
variable	O
if	O
said	O
number	O
is	O
less	O
than	O
said	O
emergency	O
threshold	O
.	O

26	O
.	O
An	O
apparatus	O
according	O
to	O
claim	O
25	O
,	O
wherein	O
said	O
altering	O
means	O
is	O
adapted	O
to	O
increase	O
the	O
variable	O
by	O
a	O
second	O
smaller	O
adjustment	O
constant	O
,	O
if	O
said	O
number	O
determined	O
by	O
said	O
altering	O
means	O
is	O
greater	O
than	O
said	O
emergency	O
threshold	O
but	O
less	O
than	O
a	O
second	O
matching	O
threshold	O
,	O
which	O
is	O
less	O
than	O
the	O
first	O
matching	O
threshold	O
but	O
greater	O
than	O
said	O
emergency	O
threshold	O
.	O

27	O
.	O
An	O
apparatus	O
according	O
to	O
claim	O
26	O
,	O
wherein	O
said	O
second	O
adjustment	O
constant	O
is	O
half	O
the	O
value	O
of	O
said	O
first	O
adjustment	O
constant	O
.	O

28	O
.	O
An	O
apparatus	O
according	O
to	O
claim	O
21	O
,	O
wherein	O
said	O
altering	O
means	O
is	O
adapted	O
to	O
adjust	O
the	O
value	O
of	O
the	O
variable	O
to	O
be	O
equal	O
to	O
a	O
set	O
maximum	O
if	O
the	O
variable	O
has	O
been	O
adjusted	O
to	O
be	O
greater	O
than	O
that	O
maximum	O
.	O

29	O
.	O
An	O
apparatus	O
according	O
to	O
claim	O
19	O
,	O
wherein	O
said	O
altering	O
means	O
is	O
adapted	O
to	O
adjust	O
the	O
value	O
of	O
the	O
variable	O
to	O
be	O
equal	O
to	O
a	O
set	O
minimum	O
value	O
if	O
the	O
variable	O
is	O
adjusted	O
to	O
be	O
less	O
than	O
that	O
minimum	O
value	O
.	O

30	O
.	O
An	O
apparatus	O
according	O
to	O
claim	O
19	O
,	O
wherein	O
said	O
matching	O
means	O
further	O
comprises	O
means	O
for	O
defining	O
as	O
active	O
patterns	O
the	O
reference	O
patterns	O
of	O
a	O
current	O
reference	O
signal	O
which	O
are	O
at	O
the	O
end	O
of	O
a	O
dynamic	O
programming	O
path	O
for	O
a	O
current	O
input	O
pattern	O
being	O
processed	O
and	O
means	O
for	O
listing	O
the	O
active	O
patterns	O
for	O
the	O
current	O
input	O
pattern	O
in	O
a	O
current	O
active	O
list	O
.	O

31	O
.	O
An	O
apparatus	O
according	O
to	O
claim	O
30	O
,	O
wherein	O
the	O
cumulative	O
value	O
associated	O
with	O
each	O
dynamic	O
programming	O
path	O
is	O
stored	O
in	O
a	O
store	O
associated	O
with	O
the	O
reference	O
pattern	O
defined	O
as	O
the	O
active	O
pattern	O
at	O
the	O
end	O
of	O
the	O
path	O
associated	O
with	O
the	O
cumulative	O
value	O
.	O

32	O
.	O
An	O
apparatus	O
according	O
to	O
claim	O
19	O
,	O
wherein	O
said	O
matching	O
means	O
is	O
arranged	O
to	O
propagate	O
the	O
dynamic	O
programming	O
paths	O
by	O
processing	O
each	O
active	O
pattern	O
in	O
turn	O
and	O
listing	O
a	O
reference	O
pattern	O
of	O
the	O
current	O
reference	O
signal	O
for	O
which	O
it	O
is	O
determined	O
that	O
the	O
reference	O
pattern	O
of	O
the	O
current	O
reference	O
signal	O
may	O
be	O
located	O
at	O
the	O
end	O
of	O
a	O
dynamic	O
programming	O
path	O
for	O
the	O
succeeding	O
input	O
pattern	O
in	O
a	O
new	O
active	O
list	O
.	O

33	O
.	O
An	O
apparatus	O
according	O
to	O
claim	O
32	O
,	O
comprising	O
counting	O
means	O
which	O
is	O
arranged	O
to	O
increment	O
a	O
count	O
each	O
time	O
a	O
reference	O
pattern	O
is	O
added	O
to	O
the	O
new	O
active	O
list	O
.	O

34	O
.	O
An	O
apparatus	O
according	O
to	O
claim	O
33	O
,	O
wherein	O
once	O
all	O
the	O
active	O
patterns	O
have	O
been	O
processed	O
for	O
the	O
current	O
input	O
pattern	O
,	O
said	O
count	O
represents	O
the	O
number	O
of	O
dynamic	O
programming	O
paths	O
which	O
have	O
been	O
propagated	O
to	O
the	O
succeeding	O
time	O
point	O
but	O
which	O
have	O
not	O
been	O
discarded	O
.	O

35	O
.	O
An	O
apparatus	O
according	O
to	O
claim	O
19	O
,	O
wherein	O
said	O
matching	O
step	O
is	O
operable	O
to	O
perform	O
said	O
matching	O
while	O
said	O
receiving	O
step	O
is	O
still	O
receiving	O
said	O
input	O
signal	O
.	O

36	O
.	O
An	O
apparatus	O
according	O
to	O
claim	O
19	O
,	O
wherein	O
said	O
matching	O
means	O
is	O
operable	O
to	O
update	O
the	O
cumulative	O
value	O
of	O
the	O
dynamic	O
programming	O
paths	O
which	O
are	O
not	O
restricted	O
by	O
said	O
controlling	O
means	O
using	O
the	O
current	O
input	O
pattern	O
,	O
prior	O
to	O
the	O
propagation	O
of	O
said	O
paths	O
to	O
the	O
succeeding	O
input	O
pattern	O
.	O

37	O
.	O
A	O
pattern	O
matching	O
apparatus	O
for	O
matching	O
a	O
time	O
varying	O
input	O
signal	O
with	O
a	O
number	O
of	O
sequences	O
of	O
reference	O
patterns	O
,	O
each	O
sequence	O
being	O
representative	O
of	O
a	O
time	O
varying	O
reference	O
signal	O
,	O
the	O
apparatus	O
comprising	O
:	O
a	O
first	O
receiver	O
for	O
receiving	O
the	O
time	O
varying	O
input	O
signal	O
;	O
a	O
second	O
receiver	O
for	O
receiving	O
a	O
sequence	O
of	O
input	O
patterns	O
representative	O
of	O
the	O
input	O
signal	O
,	O
each	O
pattern	O
representing	O
a	O
corresponding	O
time	O
portion	O
of	O
the	O
input	O
signal	O
;	O
a	O
pattern	O
matching	O
for	O
matching	O
the	O
input	O
signal	O
with	O
each	O
reference	O
signal	O
using	O
a	O
dynamic	O
programming	O
matching	O
process	O
which	O
processes	O
each	O
pattern	O
of	O
said	O
input	O
signal	O
in	O
sequence	O
and	O
which	O
propagates	O
a	O
plurality	O
of	O
dynamic	O
programming	O
paths	O
using	O
predetermined	O
dynamic	O
programming	O
constraints	O
,	O
each	O
path	O
representing	O
a	O
possible	O
matching	O
between	O
a	O
sequence	O
of	O
reference	O
patterns	O
and	O
a	O
sequence	O
of	O
patterns	O
of	O
the	O
input	O
signal	O
ending	O
at	O
a	O
current	O
pattern	O
being	O
processed	O
,	O
and	O
each	O
path	O
having	O
an	O
associated	O
cumulative	O
value	O
representative	O
of	O
a	O
score	O
for	O
the	O
possible	O
matching	O
;	O
a	O
controller	O
for	O
controlling	O
said	O
pattern	O
matcher	O
by	O
comparing	O
the	O
cumulative	O
value	O
associated	O
with	O
each	O
path	O
with	O
a	O
pruning	O
value	O
thereby	O
to	O
restrict	O
the	O
number	O
of	O
dynamic	O
programming	O
paths	O
that	O
were	O
propagated	O
from	O
a	O
preceding	O
time	O
point	O
,	O
when	O
the	O
preceding	O
input	O
pattern	O
was	O
being	O
processed	O
by	O
said	O
pattern	O
matcher	O
,	O
from	O
being	O
propagated	O
further	O
during	O
the	O
processing	O
of	O
the	O
current	O
input	O
pattern	O
at	O
a	O
current	O
time	O
point	O
by	O
said	O
pattern	O
matcher	O
;	O
a	O
first	O
processor	O
for	O
determining	O
at	O
the	O
current	O
time	O
point	O
,	O
a	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
that	O
will	O
be	O
propagating	O
at	O
the	O
succeeding	O
time	O
point	O
,	O
prior	O
to	O
restriction	O
by	O
said	O
controlling	O
step	O
,	O
when	O
the	O
succeeding	O
input	O
pattern	O
will	O
be	O
processed	O
by	O
said	O
pattern	O
matcher	O
;	O
and	O
a	O
second	O
processor	O
for	O
altering	O
the	O
pruning	O
value	O
used	O
at	O
said	O
succeeding	O
time	O
point	O
in	O
dependence	O
upon	O
the	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
determined	O
by	O
said	O
first	O
processor	O
;	O
wherein	O
said	O
pattern	O
matcher	O
comprises	O
:	O
a	O
third	O
processor	O
for	O
using	O
said	O
dynamic	O
programming	O
constraints	O
to	O
propagate	O
each	O
dynamic	O
programming	O
path	O
ending	O
at	O
the	O
current	O
input	O
pattern	O
to	O
the	O
succeeding	O
input	O
pattern	O
;	O
and	O
a	O
fourth	O
processor	O
for	O
maintaining	O
the	O
dynamic	O
programming	O
path	O
having	O
the	O
best	O
cumulative	O
value	O
and	O
discarding	O
the	O
rest	O
,	O
in	O
the	O
case	O
where	O
a	O
plurality	O
of	O
dynamic	O
programming	O
paths	O
meet	O
at	O
the	O
succeeding	O
input	O
pattern	O
;	O
and	O
wherein	O
said	O
second	O
processor	O
comprises	O
a	O
counter	O
for	O
counting	O
the	O
number	O
of	O
dynamic	O
programming	O
paths	O
which	O
have	O
been	O
propagated	O
to	O
the	O
succeeding	O
input	O
pattern	O
but	O
which	O
have	O
not	O
been	O
discarded	O
.	O

38	O
.	O
A	O
computer	O
readable	O
medium	O
storing	O
computer	O
executable	O
process	O
steps	O
to	O
perform	O
a	O
pattern	O
matching	O
method	O
for	O
matching	O
a	O
time	O
varying	O
input	O
signal	O
with	O
a	O
number	O
of	O
sequences	O
of	O
reference	O
patterns	O
,	O
each	O
sequence	O
being	O
representative	O
of	O
a	O
time	O
varying	O
reference	O
signal	O
,	O
the	O
process	O
steps	O
comprising	O
:	O
a	O
receiving	O
step	O
to	O
receive	O
the	O
time	O
varying	O
input	O
signal	O
;	O
an	O
obtaining	O
step	O
to	O
obtain	O
a	O
sequence	O
of	O
input	O
patterns	O
representative	O
of	O
the	O
input	O
signal	O
,	O
each	O
pattern	O
representing	O
a	O
corresponding	O
time	O
portion	O
of	O
the	O
input	O
signal	O
;	O
a	O
matching	O
step	O
to	O
match	O
the	O
input	O
signal	O
with	O
each	O
reference	O
signal	O
using	O
a	O
dynamic	O
programming	O
matching	O
process	O
which	O
processes	O
each	O
pattern	O
of	O
said	O
input	O
signal	O
in	O
sequence	O
and	O
which	O
propagates	O
a	O
plurality	O
of	O
dynamic	O
programming	O
paths	O
using	O
predetermined	O
dynamic	O
programming	O
constraints	O
,	O
each	O
path	O
representing	O
a	O
possible	O
matching	O
between	O
a	O
sequence	O
of	O
reference	O
patterns	O
and	O
a	O
sequence	O
of	O
patterns	O
of	O
the	O
input	O
signal	O
ending	O
at	O
a	O
current	O
pattern	O
being	O
processed	O
,	O
and	O
each	O
path	O
having	O
an	O
associated	O
cumulative	O
value	O
representative	O
of	O
a	O
score	O
for	O
the	O
possible	O
matching	O
;	O
a	O
controlling	O
step	O
to	O
control	O
said	O
matching	O
step	O
by	O
comparing	O
the	O
cumulative	O
value	O
associated	O
with	O
each	O
path	O
with	O
a	O
pruning	O
value	O
thereby	O
to	O
restrict	O
the	O
number	O
of	O
dynamic	O
programming	O
paths	O
that	O
were	O
propagated	O
from	O
a	O
preceding	O
time	O
point	O
,	O
when	O
the	O
preceding	O
input	O
pattern	O
was	O
being	O
processed	O
in	O
said	O
matching	O
step	O
,	O
from	O
being	O
propagated	O
further	O
during	O
the	O
processing	O
of	O
the	O
current	O
input	O
pattern	O
by	O
said	O
matching	O
step	O
;	O
a	O
determining	O
step	O
to	O
determine	O
at	O
the	O
current	O
time	O
point	O
,	O
a	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
that	O
will	O
be	O
propagating	O
at	O
the	O
succeeding	O
time	O
point	O
,	O
prior	O
to	O
restriction	O
by	O
said	O
controlling	O
step	O
,	O
when	O
the	O
succeeding	O
input	O
pattern	O
will	O
be	O
processed	O
by	O
said	O
matching	O
step	O
;	O
and	O
an	O
altering	O
step	O
to	O
alter	O
the	O
pruning	O
value	O
used	O
at	O
said	O
succeeding	O
time	O
point	O
in	O
dependence	O
upon	O
the	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
determined	O
by	O
said	O
determining	O
step	O
;	O
wherein	O
said	O
matching	O
step	O
comprises	O
:	O
a	O
propagating	O
step	O
to	O
use	O
said	O
dynamic	O
programming	O
constraints	O
to	O
propagate	O
each	O
dynamic	O
programming	O
path	O
ending	O
at	O
the	O
current	O
input	O
pattern	O
to	O
the	O
succeeding	O
input	O
pattern	O
;	O
and	O
a	O
maintaining	O
step	O
to	O
maintain	O
the	O
dynamic	O
programming	O
path	O
having	O
the	O
best	O
cumulative	O
value	O
and	O
discarding	O
the	O
rest	O
,	O
in	O
the	O
case	O
where	O
a	O
plurality	O
of	O
dynamic	O
programming	O
paths	O
meet	O
at	O
the	O
succeeding	O
input	O
pattern	O
;	O
and	O
wherein	O
said	O
determining	O
step	O
comprises	O
a	O
counting	O
step	O
to	O
count	O
the	O
number	O
of	O
dynamic	O
programming	O
paths	O
which	O
have	O
been	O
propagated	O
to	O
the	O
succeeding	O
input	O
pattern	O
but	O
which	O
have	O
not	O
been	O
discarded	O
.	O

39	O
.	O
A	O
computer	O
readable	O
medium	O
according	O
to	O
claim	O
38	O
,	O
wherein	O
said	O
input	O
signal	O
is	O
a	O
speech	O
signal	O
,	O
and	O
wherein	O
each	O
pattern	O
comprises	O
a	O
number	O
of	O
parameters	O
representative	O
of	O
the	O
acoustic	O
properties	O
of	O
the	O
input	O
speed	O
signal	O
during	O
the	O
corresponding	O
time	O
portion	O
.	O

40	O
.	O
A	O
computer	O
readable	O
medium	O
according	O
to	O
claim	O
38	O
,	O
wherein	O
said	O
altering	O
step	O
is	O
arranged	O
to	O
alter	O
the	O
pruning	O
value	O
for	O
the	O
succeeding	O
time	O
point	O
to	O
equal	O
a	O
sum	O
of	O
a	O
minimum	O
cumulative	O
value	O
of	O
the	O
cumulative	O
values	O
determined	O
in	O
said	O
matching	O
step	O
at	O
the	O
current	O
time	O
point	O
and	O
a	O
variable	O
which	O
is	O
varied	O
in	O
dependence	O
upon	O
said	O
number	O
of	O
possible	O
matchings	O
determined	O
in	O
said	O
determining	O
step	O
.	O

41	O
.	O
A	O
computer	O
readable	O
medium	O
according	O
to	O
claim	O
40	O
,	O
wherein	O
the	O
variable	O
is	O
increased	O
by	O
a	O
first	O
adjustment	O
constant	O
if	O
said	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
determined	O
in	O
said	O
determining	O
step	O
is	O
less	O
than	O
a	O
first	O
matching	O
threshold	O
.	O

42	O
.	O
A	O
computer	O
readable	O
medium	O
according	O
to	O
claim	O
41	O
,	O
wherein	O
if	O
said	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
determined	O
in	O
said	O
determining	O
step	O
is	O
greater	O
than	O
said	O
first	O
matching	O
threshold	O
,	O
then	O
the	O
variable	O
is	O
varied	O
in	O
dependence	O
upon	O
the	O
number	O
of	O
cumulative	O
values	O
determined	O
in	O
said	O
matching	O
step	O
at	O
the	O
current	O
time	O
point	O
.	O

43	O
.	O
A	O
computer	O
readable	O
medium	O
according	O
to	O
claim	O
42	O
,	O
wherein	O
the	O
variable	O
is	O
decreased	O
by	O
said	O
first	O
adjustment	O
constant	O
if	O
said	O
number	O
of	O
cumulative	O
values	O
determined	O
in	O
said	O
matching	O
step	O
at	O
the	O
current	O
time	O
point	O
,	O
is	O
greater	O
than	O
said	O
first	O
matching	O
threshold	O
.	O

44	O
.	O
A	O
computer	O
readable	O
medium	O
according	O
to	O
claim	O
42	O
,	O
wherein	O
if	O
said	O
number	O
of	O
cumulative	O
values	O
determined	O
in	O
said	O
matching	O
step	O
for	O
the	O
current	O
time	O
point	O
exceeds	O
said	O
first	O
matching	O
threshold	O
,	O
then	O
said	O
altering	O
step	O
checks	O
whether	O
the	O
number	O
of	O
possible	O
dynamic	O
programming	O
paths	O
which	O
have	O
a	O
cumulative	O
value	O
less	O
than	O
a	O
determined	O
pruning	O
value	O
exceeds	O
an	O
emergency	O
threshold	O
,	O
and	O
wherein	O
said	O
altering	O
step	O
redetermines	O
the	O
pruning	O
value	O
for	O
the	O
succeeding	O
time	O
point	O
using	O
an	O
increased	O
value	O
of	O
the	O
variable	O
if	O
said	O
number	O
is	O
less	O
than	O
said	O
emergency	O
threshold	O
.	O

45	O
.	O
A	O
computer	O
readable	O
medium	O
according	O
to	O
claim	O
44	O
,	O
wherein	O
the	O
variable	O
is	O
increased	O
by	O
a	O
second	O
smaller	O
adjustment	O
constant	O
,	O
if	O
said	O
number	O
determined	O
in	O
said	O
altering	O
step	O
is	O
greater	O
than	O
said	O
emergency	O
threshold	O
but	O
less	O
than	O
a	O
second	O
matching	O
threshold	O
,	O
which	O
is	O
less	O
than	O
the	O
first	O
matching	O
threshold	O
but	O
greater	O
than	O
said	O
emergency	O
threshold	O
.	O

46	O
.	O
A	O
computer	O
readable	O
medium	O
according	O
to	O
claim	O
45	O
,	O
wherein	O
said	O
second	O
adjustment	O
constant	O
is	O
half	O
the	O
value	O
of	O
said	O
first	O
adjustment	O
constant	O
.	O

47	O
.	O
A	O
computer	O
readable	O
medium	O
according	O
to	O
claim	O
40	O
,	O
wherein	O
said	O
altering	O
step	O
adjusts	O
the	O
value	O
of	O
the	O
variable	O
to	O
be	O
equal	O
to	O
a	O
set	O
maximum	O
value	O
if	O
the	O
variable	O
has	O
been	O
adjusted	O
to	O
be	O
greater	O
than	O
that	O
maximum	O
.	O

48	O
.	O
A	O
computer	O
readable	O
medium	O
according	O
to	O
claim	O
40	O
,	O
wherein	O
said	O
altering	O
step	O
adjusts	O
the	O
value	O
of	O
the	O
variable	O
to	O
be	O
equal	O
to	O
a	O
set	O
minimum	O
value	O
if	O
the	O
variable	O
is	O
adjusted	O
to	O
be	O
less	O
than	O
that	O
minimum	O
value	O
.	O

49	O
.	O
A	O
computer	O
readable	O
medium	O
according	O
to	O
claim	O
38	O
,	O
wherein	O
said	O
matching	O
step	O
further	O
comprises	O
the	O
step	O
of	O
defining	O
as	O
active	O
patterns	O
the	O
reference	O
patterns	O
of	O
a	O
current	O
reference	O
signal	O
which	O
are	O
at	O
the	O
end	O
of	O
a	O
dynamic	O
programming	O
path	O
for	O
a	O
current	O
input	O
pattern	O
being	O
processed	O
and	O
listing	O
the	O
active	O
patterns	O
for	O
the	O
current	O
input	O
pattern	O
in	O
a	O
current	O
active	O
list	O
.	O

50	O
.	O
A	O
computer	O
readable	O
medium	O
according	O
to	O
claim	O
49	O
,	O
wherein	O
the	O
cumulative	O
value	O
associated	O
with	O
each	O
dynamic	O
programming	O
path	O
is	O
stored	O
in	O
a	O
store	O
associated	O
with	O
the	O
reference	O
pattern	O
defined	O
as	O
the	O
active	O
pattern	O
at	O
the	O
end	O
of	O
the	O
path	O
associated	O
with	O
the	O
cumulative	O
value	O
.	O

51	O
.	O
A	O
computer	O
readable	O
medium	O
according	O
to	O
claim	O
49	O
,	O
wherein	O
said	O
matching	O
step	O
propagates	O
the	O
dynamic	O
programming	O
paths	O
by	O
processing	O
each	O
active	O
pattern	O
in	O
turn	O
and	O
listing	O
a	O
reference	O
pattern	O
of	O
the	O
current	O
reference	O
signal	O
for	O
which	O
it	O
is	O
determined	O
that	O
the	O
reference	O
pattern	O
of	O
the	O
current	O
reference	O
signal	O
may	O
be	O
located	O
at	O
the	O
end	O
of	O
a	O
dynamic	O
programming	O
path	O
for	O
the	O
succeeding	O
input	O
pattern	O
in	O
a	O
new	O
active	O
list	O
.	O

52	O
.	O
A	O
computer	O
readable	O
medium	O
according	O
to	O
claim	O
51	O
,	O
wherein	O
a	O
count	O
is	O
incremented	O
each	O
time	O
a	O
reference	O
signal	O
is	O
added	O
to	O
the	O
new	O
active	O
list	O
.	O

53	O
.	O
A	O
computer	O
readable	O
medium	O
according	O
to	O
claim	O
52	O
,	O
wherein	O
once	O
all	O
the	O
active	O
patterns	O
have	O
been	O
processed	O
for	O
the	O
current	O
input	O
pattern	O
,	O
said	O
count	O
represents	O
the	O
number	O
of	O
dynamic	O
programming	O
paths	O
which	O
have	O
been	O
propagated	O
to	O
the	O
succeeding	O
time	O
point	O
but	O
which	O
have	O
not	O
been	O
discarded	O
.	O

54	O
.	O
A	O
computer	O
readable	O
medium	O
according	O
to	O
claim	O
38	O
,	O
wherein	O
said	O
matching	O
step	O
is	O
operable	O
to	O
perform	O
said	O
matching	O
while	O
said	O
receiving	O
step	O
is	O
still	O
receiving	O
said	O
input	O
signal	O
.	O

55	O
.	O
A	O
computer	O
readable	O
medium	O
according	O
to	O
claim	O
38	O
,	O
wherein	O
said	O
matching	O
step	O
updates	O
the	O
cumulative	O
values	O
of	O
the	O
dynamic	O
programming	O
paths	O
which	O
are	O
not	O
restricted	O
by	O
said	O
controlling	O
step	O
using	O
the	O
current	O
input	O
pattern	O
,	O
prior	O
to	O
propagating	O
those	O
paths	O
to	O
the	O
succeeding	O
input	O
pattern	O
.	O

